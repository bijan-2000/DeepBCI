{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42992946",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af32dba6-d557-4f5c-b2a9-6524cdd3636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from mne.decoding import CSP\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import copy\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f846914c-a116-4075-98d7-4e3fbe00ecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "# projects/def-b09sdp/bijan/Phase2/P16.fdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7bc34-24a6-4250-89bf-4bc9422e0af4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45befd64-9db2-4cf8-b119-eae966306003",
   "metadata": {},
   "source": [
    "Mode: 'binary', '3-class', '4-class', '5-class', '6-class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec218e4-dc89-43dd-9105-6875b25f7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrapper(data_epochs, data_labels, mode='binary'):\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        epochs = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            binary_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2)]\n",
    "            #class2_epochs = participant_epochs[participant_labels==2]\n",
    "            #bi_epochs = np.concatenate((class1_epochs, class2_epochs), axis=0)\n",
    "            epochs.append(binary_epochs)\n",
    "    \n",
    "            binary_labels = participant_labels[(participant_labels==1) | (participant_labels==2)]\n",
    "            #bi_labels = np.concatenate((class1_labels, class2_labels), axis=0)\n",
    "            labels.append(binary_labels)\n",
    "            \n",
    "    elif mode == '3_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            labels.append(multiclass_labels)\n",
    "            \n",
    "            \n",
    "    elif mode == '4_class_RS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "        \n",
    "    elif mode == '4_class_LS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    elif mode == '6_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c5154e2-0354-4913-a796-40e515129978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(y_data, method=OneHotEncoder):\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(y_data[0].reshape(-1, 1))\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        \n",
    "        a = encoder.transform(y_data[i].reshape(-1, 1))\n",
    "        y_data[i] = a.toarray()\n",
    "\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd5151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_csp(x_train, y_train, x_test):\n",
    "    \n",
    "        csp = CSP(number_of_components)\n",
    "        csp_fit = csp.fit(x_train, y_train)\n",
    "        train_feat = csp_fit.transform(x_train)\n",
    "        test_feat = csp_fit.transform(x_test)\n",
    "        return train_feat, test_feat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6adf2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(dataset, labels, number_of_bands, test_data):\n",
    "\n",
    "    low_cutoff = 0\n",
    "    \n",
    "    for b in range(number_of_bands):\n",
    "        low_cutoff += 4\n",
    "        data = dataset.copy()\n",
    "        data_test = test_data.copy()\n",
    "        filtered_data = mne.filter.filter_data(data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        filtered_data_test = mne.filter.filter_data(test_data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        [train_feats, test_feats] = calc_csp(filtered_data, labels[:,0], filtered_data_test)\n",
    "        if b == 0:\n",
    "            train_features = train_feats\n",
    "            test_features = test_feats\n",
    "        else:\n",
    "            train_features = np.concatenate((train_features, train_feats), axis = 1)\n",
    "            test_features = np.concatenate((test_features, test_feats), axis = 1)\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c55c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train_features, labels, number_of_selected_features):\n",
    "    X = pd.DataFrame(train_features)\n",
    "    y = pd.DataFrame(labels)\n",
    "    K = number_of_selected_features\n",
    "    \n",
    "    df = pd.concat([y,X], axis = 1)\n",
    "    df.columns = df.columns.astype(str)\n",
    "        \n",
    "    selected_features = list(map(int, pymrmr.mRMR(df, 'MID', K)))\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46e076",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Device (GPU\\CPU\\MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3963e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61c74e-3fdb-4e1a-b086-fc5180a12db4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data reading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c82e66a-6a62-4fc8-84b4-bd38d395c79e",
   "metadata": {},
   "source": [
    "\\\n",
    "\\\n",
    "Read all the data except participant 1 (P2 - P15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a012ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local ...\n",
      "Please make sure to change the data path!\n",
      "\n",
      "\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "7 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648774  =      0.000 ...  2595.096 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "6 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 600914  =      0.000 ...  2403.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660046  =      0.000 ...  2640.184 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 144 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 144 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_8928\\2188678550.py:43: RuntimeWarning: No matching events found for 9 (event id 9)\n",
      "  train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_8928\\2188678550.py:43: RuntimeWarning: No matching events found for 10 (event id 10)\n",
      "  train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_8928\\2188678550.py:44: RuntimeWarning: No matching events found for 9 (event id 9)\n",
      "  test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_8928\\2188678550.py:44: RuntimeWarning: No matching events found for 10 (event id 10)\n",
      "  test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 679862  =      0.000 ...  2719.448 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "3 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 666372  =      0.000 ...  2665.488 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "6 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673134  =      0.000 ...  2692.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "4 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 687791  =      0.000 ...  2751.164 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675097  =      0.000 ...  2700.388 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "if device == 'cuda':\n",
    "    print(\"Running on cloud ...\")\n",
    "    print(\"Please make sure to modify how you read the data according to your need!\\n\\n\")\n",
    "    raw_data_path = \"/home/bijan/projects/def-b09sdp/bijan/Phase2/\"\n",
    "    data_epochs = []\n",
    "    data_labels = []\n",
    "\n",
    "    for participant_id in range(1, 10):\n",
    "        participant = f\"P{participant_id}\"\n",
    "        file_path = f\"{raw_data_path}/{participant}.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(file_path)\n",
    "        data_epochs.append(epochs.get_data())\n",
    "        data_labels.append(epochs.events[:, -1])\n",
    "\n",
    "elif device == 'cpu':\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "    train_data_epochs = []\n",
    "    train_data_labels = []\n",
    "    test_data_epochs = []\n",
    "    test_data_labels = []\n",
    "    for participant_id in range(1, 10):\n",
    "        participant_E = f\"A0{participant_id}E\"\n",
    "        participant_T = f\"A0{participant_id}T\"\n",
    "        \n",
    "        file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "        file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "        \n",
    "        raw_train = mne.io.read_raw_gdf(file_path_T, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        raw_test = mne.io.read_raw_gdf(file_path_E, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        \n",
    "        raw_train.set_eeg_reference()\n",
    "        raw_test.set_eeg_reference()\n",
    "        \n",
    "        train_events = mne.events_from_annotations(raw_train)\n",
    "        test_events = mne.events_from_annotations(raw_test)\n",
    "        \n",
    "        tmin = 0.504\n",
    "        tmax = 2.5\n",
    "        \n",
    "        try:\n",
    "            train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
    "            test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
    "        except ValueError:\n",
    "            train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=(0, 0))\n",
    "            test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=(0, 0))\n",
    "        train_data_epochs.append(train_epochs.get_data())\n",
    "        test_data_epochs.append(test_epochs.get_data())\n",
    "        \n",
    "        train_data_labels.append(train_epochs.events[:, -1])\n",
    "        test_data_labels.append(test_epochs.events[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94598bfd-c790-48d8-9953-e3273ba37f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      5],\n",
       "       [     0,      0,      3],\n",
       "       [ 30878,      0,      5],\n",
       "       ...,\n",
       "       [669791,      0,      8],\n",
       "       [671350,      0,      6],\n",
       "       [671850,      0,      9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c32f89-e0fa-43a5-8424-8219f61c27cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1023': 1,\n",
       " '1072': 2,\n",
       " '276': 3,\n",
       " '277': 4,\n",
       " '32766': 5,\n",
       " '768': 6,\n",
       " '769': 7,\n",
       " '770': 8,\n",
       " '771': 9,\n",
       " '772': 10}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "358a89b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673328,), (1, 673328))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0][1].shape, raw_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "749df1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 train epochs:     (288, 22, 500)     Subject 1 train labels:     (288,)\n",
      "Subject 1 test epochs:      (288, 22, 500)     Subject 1 test labels:      (288,)\n",
      "Subject 2 train epochs:     (288, 22, 500)     Subject 2 train labels:     (288,)\n",
      "Subject 2 test epochs:      (281, 22, 500)     Subject 2 test labels:      (281,)\n",
      "Subject 3 train epochs:     (288, 22, 500)     Subject 3 train labels:     (288,)\n",
      "Subject 3 test epochs:      (282, 22, 500)     Subject 3 test labels:      (282,)\n",
      "Subject 4 train epochs:     (144, 22, 500)     Subject 4 train labels:     (144,)\n",
      "Subject 4 test epochs:      (144, 22, 500)     Subject 4 test labels:      (144,)\n",
      "Subject 5 train epochs:     (288, 22, 500)     Subject 5 train labels:     (288,)\n",
      "Subject 5 test epochs:      (285, 22, 500)     Subject 5 test labels:      (285,)\n",
      "Subject 6 train epochs:     (288, 22, 500)     Subject 6 train labels:     (288,)\n",
      "Subject 6 test epochs:      (282, 22, 500)     Subject 6 test labels:      (282,)\n",
      "Subject 7 train epochs:     (288, 22, 500)     Subject 7 train labels:     (288,)\n",
      "Subject 7 test epochs:      (284, 22, 500)     Subject 7 test labels:      (284,)\n",
      "Subject 8 train epochs:     (288, 22, 500)     Subject 8 train labels:     (288,)\n",
      "Subject 8 test epochs:      (288, 22, 500)     Subject 8 test labels:      (288,)\n",
      "Subject 9 train epochs:     (288, 22, 500)     Subject 9 train labels:     (288,)\n",
      "Subject 9 test epochs:      (288, 22, 500)     Subject 9 test labels:      (288,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(\"Subject {} train epochs:    \".format(i+1), train_data_epochs[i].shape, \"    Subject {} train labels:    \".format(i+1), train_data_labels[i].shape)\n",
    "    print(\"Subject {} test epochs:     \".format(i+1), test_data_epochs[i].shape, \"    Subject {} test labels:     \".format(i+1), test_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b05c2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_epochs = np.zeros(len(train_data_epochs)).tolist()\n",
    "all_data_labels = np.zeros(len(train_data_epochs)).tolist()\n",
    "\n",
    "for i in range(len(train_data_epochs)):\n",
    "    all_data_epochs[i] = np.concatenate((train_data_epochs[i], test_data_epochs[i]), axis=0)\n",
    "    all_data_labels[i] = np.concatenate((train_data_labels[i], test_data_labels[i]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "066b81d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific element in train and test sets:       -1.5491832386363597e-06 6.613991477272725e-06\n",
      "The same element in all data set combined:     -1.5491832386363597e-06 6.613991477272725e-06\n",
      "\n",
      "\n",
      "\n",
      "Checking the labels in train and test:         7 8\n",
      "The same element in all data set combined:     7 8\n"
     ]
    }
   ],
   "source": [
    "# Checking if the concatenation does not have a problem!\n",
    "\n",
    "print(\"Specific element in train and test sets:      \", train_data_epochs[i][10, 10, 10], test_data_epochs[i][100, 13, 14])\n",
    "print(\"The same element in all data set combined:    \", all_data_epochs[i][10, 10, 10], all_data_epochs[i][388, 13, 14])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Checking the labels in train and test:        \", train_data_labels[i][10], test_data_labels[i][100])\n",
    "print(\"The same element in all data set combined:    \", all_data_labels[i][10], all_data_labels[i][388])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c81038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data epoch shape (sub 0):     (576, 22, 500)     All label shape (sub 0):      (576,)\n",
      "All data epoch shape (sub 1):     (569, 22, 500)     All label shape (sub 1):      (569,)\n",
      "All data epoch shape (sub 2):     (570, 22, 500)     All label shape (sub 2):      (570,)\n",
      "All data epoch shape (sub 3):     (288, 22, 500)     All label shape (sub 3):      (288,)\n",
      "All data epoch shape (sub 4):     (573, 22, 500)     All label shape (sub 4):      (573,)\n",
      "All data epoch shape (sub 5):     (570, 22, 500)     All label shape (sub 5):      (570,)\n",
      "All data epoch shape (sub 6):     (572, 22, 500)     All label shape (sub 6):      (572,)\n",
      "All data epoch shape (sub 7):     (576, 22, 500)     All label shape (sub 7):      (576,)\n",
      "All data epoch shape (sub 8):     (576, 22, 500)     All label shape (sub 8):      (576,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data_epochs)):\n",
    "    print(\"All data epoch shape (sub {}):    \".format(i), all_data_epochs[i].shape, \"    All label shape (sub {}):     \".format(i), all_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d77c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41176b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_encode = copy.deepcopy(all_data_labels)\n",
    "encoded = encoder(all_data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4498eb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Length: 9\n",
      "labels Length: 9\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - Epochs[0] shape: (288,)\n",
      "Participant 16 - labels[0] shape: (288, 4)\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - labels[0]:\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Epochs Length:\", len(all_data_labels))\n",
    "print(\"labels Length:\", len(encoded))\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - Epochs[0] shape:\", no_encode[3].shape)\n",
    "print(\"Participant 16 - labels[0] shape:\", encoded[3].shape)\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - labels[0]:\")\n",
    "print(all_data_labels[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc6835",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Checking the criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d683208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24debe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dbccfbb-49ff-461f-b50f-0f7448e933ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Within Subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94d55a8f-6ef7-4d36-b1a9-cfb8c89122a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/500] - Avg Training Loss: 1.7928 Train Accuracy: 0.16 - Test Loss: 1.80 - Test Accuracy: 0.28\n",
      "Epoch [  6/500] - Avg Training Loss: 1.7879 Train Accuracy: 0.17 - Test Loss: 1.84 - Test Accuracy: 0.00\n",
      "Epoch [ 11/500] - Avg Training Loss: 1.7936 Train Accuracy: 0.18 - Test Loss: 1.85 - Test Accuracy: 0.00\n",
      "Epoch [ 16/500] - Avg Training Loss: 1.7871 Train Accuracy: 0.18 - Test Loss: 1.86 - Test Accuracy: 0.00\n",
      "Epoch [ 21/500] - Avg Training Loss: 1.7876 Train Accuracy: 0.21 - Test Loss: 1.84 - Test Accuracy: 0.00\n",
      "Epoch [ 26/500] - Avg Training Loss: 1.7900 Train Accuracy: 0.18 - Test Loss: 1.85 - Test Accuracy: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m train_inputs, train_labels \u001b[38;5;241m=\u001b[39m train_inputs\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device), train_labels\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 79\u001b[0m train_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(train_outputs, train_labels)\n\u001b[0;32m     81\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "participants = [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15]\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "max_epochs = 500\n",
    "learning_rate=0.0001\n",
    "weight_decay=0.25*learning_rate\n",
    "\n",
    "confusion_matrices = []\n",
    "\n",
    "\n",
    "for i in range(len(EEG_epochs)):\n",
    "\n",
    "    epoch_participant = EEG_epochs[i]\n",
    "    encoded_participant = encoded[i]\n",
    "    \n",
    "    split_index = 40 # The last n = split_index samples are in the test set\n",
    "    \n",
    "    train_epoch, test_epoch = epoch_participant[:-1*split_index], epoch_participant[-1*split_index:]\n",
    "    train_label, test_labels = encoded_participant[:-1*split_index], encoded_participant[-1*split_index:]\n",
    "    no_encode_train_label = no_encode[i][:-1*split_index]\n",
    "    no_encode_test_label = no_encode[i][-1*split_index:]\n",
    "    \n",
    "    # print(train_epoch.shape)\n",
    "    # print(train_label.shape)\n",
    "    # print(len(no_encode_train_label))\n",
    "    \n",
    "    batch_size = 12  # Set your batch size\n",
    "    fold_num = int(EEG_epochs[i].shape[0] // batch_size)\n",
    "    \n",
    "\n",
    "    \n",
    "    #model = Deep4Net(in_chans=64, n_classes=4, input_window_samples=1123, final_conv_length='auto')\n",
    "    \n",
    "    model = new_model\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    patience = 300\n",
    "    best_metric = float('inf')\n",
    "    counter = 1\n",
    "    best_model_state = model.state_dict()\n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    train_acc_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    test_acc_epochs = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        temp_train_pred = []\n",
    "        temp_train_true = []\n",
    "        \n",
    "        train_running_loss = 0\n",
    "        \n",
    "        stratified_kfold = StratifiedKFold(n_splits=fold_num, random_state=1, shuffle=True)\n",
    "        \n",
    "        for _, (_, train_batch_index) in enumerate(stratified_kfold.split(train_epoch, no_encode_train_label)):\n",
    "            \n",
    "            batch_epoch, batch_label = train_epoch[train_batch_index], train_label[train_batch_index]\n",
    "            \n",
    "            train_dataset = EEG_Dataset(batch_epoch, batch_label, transform=None)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_epoch.shape[0])\n",
    "        \n",
    "        \n",
    "            for train_inputs, train_labels in train_loader:\n",
    "                #print(train_labels)\n",
    "                train_inputs, train_labels = train_inputs.to(torch.float32).to(device), train_labels.to(torch.float32).to(device)\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "                train_outputs = model(train_inputs)\n",
    "                loss = criterion(train_outputs, train_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_running_loss += loss.item()\n",
    "                y_pred_train = torch.argmax(train_outputs, 1).tolist()\n",
    "                y_true_train = torch.argmax(train_labels, 1).tolist()\n",
    "                temp_train_pred.extend(y_pred_train)\n",
    "                temp_train_true.extend(y_true_train)\n",
    "                \n",
    "        test_dataset = EEG_Dataset(test_epoch, test_labels, transform=None)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=test_epoch.shape[0])\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for test_input, test_label in test_loader:\n",
    "                \n",
    "                test_input, test_label = test_input.to(torch.float32).to(device), test_label.to(torch.float32).to(device)\n",
    "                test_output = model(test_input)\n",
    "                test_loss = criterion(test_output, test_label).item()\n",
    "                y_pred_test = torch.argmax(test_output, 1).tolist()\n",
    "                y_true_test = torch.argmax(test_label, 1).tolist()\n",
    "                test_conf_mat = confusion_matrix(y_true_test, y_pred_test)\n",
    "                test_accuracy = np.trace(test_conf_mat) / test_conf_mat.sum()\n",
    "        \n",
    "        avg_train_loss = train_running_loss / fold_num\n",
    "        \n",
    "        train_loss_epochs.append(avg_train_loss)\n",
    "        test_loss_epochs.append(test_loss)\n",
    "        test_acc_epochs.append(test_accuracy)\n",
    "        train_conf_mat = confusion_matrix(temp_train_true, temp_train_pred)\n",
    "        train_accuracy = np.trace(train_conf_mat) / train_conf_mat.sum()\n",
    "        train_acc_epochs.append(train_accuracy)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch [{(epoch + 1): 3d}/{max_epochs}] - Avg Training Loss: {avg_train_loss:.4f} Train Accuracy: {train_accuracy:.2f} - Test Loss: {test_loss:.2f} - Test Accuracy: {test_accuracy:.2f}\")\n",
    "        \n",
    "        if test_loss < best_metric:\n",
    "            best_metric = test_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            counter = 1\n",
    "        \n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter > patience:\n",
    "            break\n",
    "        best_epoch = epoch-patience+2\n",
    "        epochs_range = np.arange(1, len(train_loss_epochs[:best_epoch])+1)\n",
    "        \n",
    "        \n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    \n",
    "                \n",
    "    test_input, test_labels = torch.tensor(test_epoch, dtype=torch.float32).to(device), torch.tensor(test_labels, dtype=torch.float32).to(device)\n",
    "    test_output = model(test_input)\n",
    "    y_pred_test = torch.argmax(test_output, 1).tolist()\n",
    "    y_true_test = torch.argmax(test_labels, 1).tolist()\n",
    "    all_tests_true.append(y_true_test)\n",
    "    all_tests_pred.append(y_pred_test)\n",
    "        \n",
    "    \n",
    "    \n",
    "    models.append(best_model_state)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(\"Participant {}\".format(participants[i]))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(epochs_range, train_loss_epochs[:best_epoch])\n",
    "    plt.plot(epochs_range, test_loss_epochs[:best_epoch])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(epochs_range, train_acc_epochs[:best_epoch])\n",
    "    plt.plot(epochs_range, test_acc_epochs[:best_epoch])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "    plt.savefig(\"P{}_within_subject.jpg\".format(participants[i]))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d3291b7-f6d9-45fb-a772-9660b71b43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tests_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "534ec3fc-0aa8-4f87-b5ab-30fc25f1369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(all_tests_pred[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c4ea157-3a96-4d27-ba8f-9605c2c75bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_tests_true)):\n",
    "   print(all_tests_true[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38ab53e9-c603-4f26-8365-d6ed4464cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "702c0285-fdf5-4b52-adfc-f4d4ae6986f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 3 1]\n",
      " [0 5 0 5]\n",
      " [2 3 5 0]\n",
      " [0 4 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ebdd581-553d-4aed-8587-6f272aae0b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "      <th>class 3 (Pred)</th>\n",
       "      <th>class 4 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3 (True)</th>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 4 (True)</th>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)  class 3 (Pred)  class 4 (Pred)\n",
       "class 1 (True)              73              18              28              11\n",
       "class 2 (True)              12              59              23              36\n",
       "class 3 (True)              27              19              68              16\n",
       "class 4 (True)              12              45              24              49"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)', 'class 4 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)', 'class 4 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b3bd396-0100-47f1-87bf-51160149d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "      <th>class 3 (Pred)</th>\n",
       "      <th>class 4 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 4 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)  class 3 (Pred)  class 4 (Pred)\n",
       "class 1 (True)        0.561538        0.000000        0.000000        0.000000\n",
       "class 2 (True)        0.000000        0.453846        0.000000        0.000000\n",
       "class 3 (True)        0.000000        0.000000        0.523077        0.000000\n",
       "class 4 (True)        0.000000        0.000000        0.000000        0.376923"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation * np.eye(4, 4) / 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "37da8839-f7ca-4302-b2cd-d39aecd2b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bijan/py3x/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4788461538461538"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(summation * np.eye(4, 4) / 130).sum() / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29cd52-5dcf-4ae1-bb58-79a1b5db4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = summation / len(confusion_matrices)\n",
    "mean_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70316f-470e-4a4a-bfd0-8fb6499bc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'mean_confusion_matrix' is the mean confusion matrix NumPy array\n",
    "mean_confusion_matrix = sum(confusion_matrices) / len(confusion_matrices)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d5222-55aa-4e69-aa7c-59f9a001736d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross-subjects (WO hyperparameter tuning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f678b-ce96-4788-a2d8-f90f4334dc63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 \n",
      "\n",
      "      Train epochs' shape:                                (4320, 62, 1000)\n",
      "      Test epochs' shape:                                 (360, 62, 1000)\n",
      "      Train index:                                       [1, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15]\n",
      "      Test index:                                        [6]\n",
      "\n",
      "\n",
      "\n",
      "Epoch [  1/500] - Avg Training Loss: 1.7934 Train Accuracy: 0.16 - Test Loss: 1.80 - Test Accuracy: 0.13\n",
      "Epoch [  6/500] - Avg Training Loss: 1.7929 Train Accuracy: 0.16 - Test Loss: 1.79 - Test Accuracy: 0.19\n",
      "Epoch [ 11/500] - Avg Training Loss: 1.7929 Train Accuracy: 0.16 - Test Loss: 1.79 - Test Accuracy: 0.19\n",
      "Epoch [ 16/500] - Avg Training Loss: 1.7923 Train Accuracy: 0.17 - Test Loss: 1.79 - Test Accuracy: 0.14\n",
      "Epoch [ 21/500] - Avg Training Loss: 1.7924 Train Accuracy: 0.17 - Test Loss: 1.79 - Test Accuracy: 0.15\n",
      "Epoch [ 26/500] - Avg Training Loss: 1.7925 Train Accuracy: 0.17 - Test Loss: 1.80 - Test Accuracy: 0.15\n",
      "Epoch [ 31/500] - Avg Training Loss: 1.7920 Train Accuracy: 0.17 - Test Loss: 1.79 - Test Accuracy: 0.19\n",
      "Epoch [ 36/500] - Avg Training Loss: 1.7920 Train Accuracy: 0.17 - Test Loss: 1.79 - Test Accuracy: 0.14\n",
      "Epoch [ 41/500] - Avg Training Loss: 1.7912 Train Accuracy: 0.17 - Test Loss: 1.79 - Test Accuracy: 0.19\n",
      "Epoch [ 46/500] - Avg Training Loss: 1.7906 Train Accuracy: 0.18 - Test Loss: 1.79 - Test Accuracy: 0.17\n",
      "Epoch [ 51/500] - Avg Training Loss: 1.7883 Train Accuracy: 0.18 - Test Loss: 1.79 - Test Accuracy: 0.15\n",
      "Epoch [ 56/500] - Avg Training Loss: 1.7880 Train Accuracy: 0.17 - Test Loss: 1.80 - Test Accuracy: 0.14\n",
      "Epoch [ 61/500] - Avg Training Loss: 1.7848 Train Accuracy: 0.19 - Test Loss: 1.79 - Test Accuracy: 0.17\n",
      "Epoch [ 66/500] - Avg Training Loss: 1.7762 Train Accuracy: 0.21 - Test Loss: 1.78 - Test Accuracy: 0.20\n",
      "Epoch [ 71/500] - Avg Training Loss: 1.7462 Train Accuracy: 0.23 - Test Loss: 1.75 - Test Accuracy: 0.21\n",
      "Epoch [ 76/500] - Avg Training Loss: 1.7008 Train Accuracy: 0.27 - Test Loss: 1.64 - Test Accuracy: 0.26\n",
      "Epoch [ 81/500] - Avg Training Loss: 1.6596 Train Accuracy: 0.28 - Test Loss: 1.57 - Test Accuracy: 0.31\n",
      "Epoch [ 86/500] - Avg Training Loss: 1.6354 Train Accuracy: 0.29 - Test Loss: 1.56 - Test Accuracy: 0.31\n",
      "Epoch [ 91/500] - Avg Training Loss: 1.6092 Train Accuracy: 0.30 - Test Loss: 1.55 - Test Accuracy: 0.30\n",
      "Epoch [ 96/500] - Avg Training Loss: 1.5931 Train Accuracy: 0.32 - Test Loss: 1.54 - Test Accuracy: 0.33\n",
      "Epoch [ 101/500] - Avg Training Loss: 1.5716 Train Accuracy: 0.33 - Test Loss: 1.57 - Test Accuracy: 0.31\n",
      "Epoch [ 106/500] - Avg Training Loss: 1.5531 Train Accuracy: 0.34 - Test Loss: 1.56 - Test Accuracy: 0.31\n",
      "Epoch [ 111/500] - Avg Training Loss: 1.5245 Train Accuracy: 0.37 - Test Loss: 1.54 - Test Accuracy: 0.33\n",
      "Epoch [ 116/500] - Avg Training Loss: 1.4877 Train Accuracy: 0.38 - Test Loss: 1.49 - Test Accuracy: 0.33\n"
     ]
    }
   ],
   "source": [
    "participants = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "max_epochs = 500\n",
    "learning_rate=0.0009\n",
    "\n",
    "\n",
    "\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf_outer2.split(all_data_epochs)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_epochs = np.concatenate([all_data_epochs[j] for j in train_index])\n",
    "    test_epochs = np.concatenate([all_data_epochs[k] for k in test_index])\n",
    "    train_labels = np.concatenate([encoded[l] for l in train_index])\n",
    "    test_labels = np.concatenate([encoded[m] for m in test_index])\n",
    "    no_encoded_train_labels = np.concatenate([no_encode[n] for n in train_index])\n",
    "    no_encoded_test_labels = np.concatenate([no_encode[o] for o in test_index])\n",
    "    train_ids_for_save = [participants[i] for i in train_index]\n",
    "    test_ids_for_save = [participants[i] for i in test_index]\n",
    "    \n",
    "    \n",
    "    print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "    print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "\n",
    "    print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "    print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "    print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "    print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "    print(\"      Train index:                                       \", train_ids_for_save)\n",
    "\n",
    "    print(\"      Test index:                                        \", test_ids_for_save)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Create the EEGNet model\n",
    "    model = EEGNet(nb_classes=4, Chans=22, Samples=500, dropoutRate=0.5, kernLength=22, F1=8, D=2, F2=16, norm_rate=0.25, dropoutType='Dropout')\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    patience = 60\n",
    "    train_loss_epochs = []\n",
    "    train_acc_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    test_acc_epochs = []\n",
    "    train_conf_mat = []\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    \n",
    "    # Normalizing the features\n",
    "    mean = train_epochs.mean(axis=(0, 2, 3), keepdims=True)\n",
    "    std = train_epochs.std(axis=(0, 2, 3), keepdims=True)\n",
    "    \n",
    "    print(mean.shape)\n",
    "    print(std.shape)\n",
    "    \n",
    "    norm_train_epochs = (train_epochs - mean) / std\n",
    "    norm_test_epochs = (test_epochs - mean) / std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        norm_train_epochs, train_labels,\n",
    "        validation_data=(norm_test_epochs, test_labels),\n",
    "        epochs=max_epochs,\n",
    "        batch_size=32,  # Adjust as needed\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Collect training metrics\n",
    "    train_loss_epochs.extend(history.history['loss'])\n",
    "    train_acc_epochs.extend(history.history['accuracy'])\n",
    "\n",
    "    # Collect testing metrics\n",
    "    test_loss_epochs.extend(history.history['val_loss'])\n",
    "    test_acc_epochs.extend(history.history['val_accuracy'])\n",
    "    \n",
    "    epochs_range = np.arange(1, len(train_loss_epochs[:-1*patience])+1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(\"Participant {}\".format(participants[test_index[0]]))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(epochs_range, train_loss_epochs[:-1*patience])\n",
    "    plt.plot(epochs_range, test_loss_epochs[:-1*patience])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(epochs_range, train_acc_epochs[:-1*patience])\n",
    "    plt.plot(epochs_range, test_acc_epochs[:-1*patience])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "    plt.savefig(\"P{}.jpg\".format(participants[test_index[0]]))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a28c468c-db9a-4d3f-8138-d4af320bfe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tests_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca1ee2d3-427e-40f7-9212-3eb01de03382",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd5796f-1cf4-4f51-9ab3-f2735b410bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>284</td>\n",
       "      <td>74</td>\n",
       "      <td>96</td>\n",
       "      <td>177</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>75</td>\n",
       "      <td>285</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>214</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>257</td>\n",
       "      <td>69</td>\n",
       "      <td>84</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>261</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>214</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>87</td>\n",
       "      <td>261</td>\n",
       "      <td>81</td>\n",
       "      <td>98</td>\n",
       "      <td>199</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>95</td>\n",
       "      <td>83</td>\n",
       "      <td>234</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             L (Pred)  LS (Pred)  S (Pred)  RS (True)  R (True)  Rest (Pred)\n",
       "L (True)          284         74        96        177        69           80\n",
       "LS (True)          75        285        79         75       214           52\n",
       "S (True)           82         90       257         69        84          198\n",
       "RS (True)         261         81        75        214        80           69\n",
       "R (True)           87        261        81         98       199           54\n",
       "Rest (True)        95         83       234         79        84          205"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['L (True)', 'LS (True)', 'S (True)', 'RS (True)', 'R (True)', 'Rest (True)'], columns=['L (Pred)', 'LS (Pred)', 'S (Pred)', 'RS (True)', 'R (True)', 'Rest (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0234527d-ee6f-4084-bd58-09bbffc2e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L (True)       780\n",
       "LS (True)      780\n",
       "S (True)       780\n",
       "RS (True)      780\n",
       "R (True)       780\n",
       "Rest (True)    780\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17634ff8-1043-48bb-9d81-d8e4c3b96ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>36.410256</td>\n",
       "      <td>9.487179</td>\n",
       "      <td>12.307692</td>\n",
       "      <td>22.692308</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>10.512821</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>32.948718</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>25.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>10.256410</td>\n",
       "      <td>8.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>11.153846</td>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>12.564103</td>\n",
       "      <td>25.512821</td>\n",
       "      <td>6.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>12.179487</td>\n",
       "      <td>10.641026</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>26.282051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              L (Pred)  LS (Pred)   S (Pred)  RS (True)   R (True)  \\\n",
       "L (True)     36.410256   9.487179  12.307692  22.692308   8.846154   \n",
       "LS (True)     9.615385  36.538462  10.128205   9.615385  27.435897   \n",
       "S (True)     10.512821  11.538462  32.948718   8.846154  10.769231   \n",
       "RS (True)    33.461538  10.384615   9.615385  27.435897  10.256410   \n",
       "R (True)     11.153846  33.461538  10.384615  12.564103  25.512821   \n",
       "Rest (True)  12.179487  10.641026  30.000000  10.128205  10.769231   \n",
       "\n",
       "             Rest (Pred)  \n",
       "L (True)       10.256410  \n",
       "LS (True)       6.666667  \n",
       "S (True)       25.384615  \n",
       "RS (True)       8.846154  \n",
       "R (True)        6.923077  \n",
       "Rest (True)    26.282051  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 780 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0da3ca-2632-4cde-9ff0-fbced848e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"3class_all_tests_pred\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"3class_all_tests_true\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)\n",
    "\n",
    "    \n",
    "print(all_tests_pred[1][1].shape)\n",
    "print(all_tests_pred[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6368512-0663-4c9f-a354-f5049fecec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3class_all_tests_pred\", \"rb\") as fp:\n",
    "    rand_var = pickle.load(fp)\n",
    "\n",
    "    \n",
    "with open(\"3class_all_tests_true\", \"rb\") as fp:\n",
    "    rand_var2 = pickle.load(fp)\n",
    "print(rand_var[12][1].shape)\n",
    "print(rand_var2[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08905-a166-4f57-80c1-b2cc22f13c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests_pred[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43d0b8-df4f-4cea-862b-22c54ed434f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(all_tests_true[12][1], axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5f8a9-1df5-413e-97d7-2af43d8684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 50, 6]])\n",
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ee94d-1d88-44be-a4b7-e6b61d848aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e45e8-f7bc-4075-bb3c-2f475450f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "y_pred_prob = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_pred = np.zeros(all_tests_true[i][0].shape)\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_pred += all_tests_pred[i][j]\n",
    "    y_pred_prob.append(y_pred/6)\n",
    "    confusion_matrices_ap.append(confusion_matrix(np.argmax(all_tests_true[i][0], axis=1)+1, np.argmax(y_pred_prob[i], axis=1)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b12477-bb1b-496a-b16f-a3e2736bf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659f9e1-6fcb-4fa8-8e1d-b2b29483a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = summation.values.sum()\n",
    "correct_predictions = summation.values.trace()\n",
    "overall_accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = summation.values.diagonal() / summation.sum(axis=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Accuracy for Class {i + 1}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098dbcb-6f3d-424f-a64e-bcb8de189e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7df6f-7e9d-47d8-b08d-2790c224d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation / (13 * 40) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa6dc-4794-4e57-b493-80ce26effec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([1, 1, 2, 2, 3, 3, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba87097-1690-404c-b051-55f9c13c3473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test for the effect of calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab11fff1-54d3-4dcc-8ac1-bb29e3b1e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "Calibrated_model = []\n",
    "for file in os.listdir(\"/home/bijan/py3x\"):\n",
    "    if file.endswith(\".h5\") and file.startswith(\"Calibrated\"):\n",
    "        Calibrated_model.append(file)\n",
    "    elif file.endswith(\".h5\") and file.startswith(\"Model\"):\n",
    "        models.append(file)\n",
    "        \n",
    "Calibrated_model = sorted(Calibrated_model)\n",
    "models = sorted(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6d2b9-976c-48c7-8f69-ca5033ad00dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50466690-38ae-4f90-9012-1457989185c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "Calibrated_models = {}\n",
    "for i in range(14):\n",
    "    if i == 8:\n",
    "        continue\n",
    "        \n",
    "    for j in range(6):\n",
    "        #print(\"Model{}{}.h5\".format(i+1, j+1))\n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb10d86e-1611-4280-8da5-a61bcf95bb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0203'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:02}{:02}\".format(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa5a0ea-0c50-4ec8-873a-327b68baee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b34579d-f2e3-4917-9757-ef6058078bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Calibrated_models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33991647-0cda-498a-9e52-6950779cc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "      Cross-validation index:                            [0, 9, 12]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [5, 8]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1537, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (220, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13]\n",
      "      Cross-validation index:                            [7, 10]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1537, 576)\n",
      "Cross-validation features shape:  (220, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee414b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 1 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [3, 6]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee415fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 2 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1338, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 5, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1338, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1479, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1479, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [5, 13]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [8, 11]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1539, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (219, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [3, 7]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1539, 576)\n",
      "Cross-validation features shape:  (219, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 3 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_subjects = len(EEG_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "models = {}\n",
    "Calibrated_models = {}\n",
    "\n",
    "kf_outer1 = KFold(n_splits=6, shuffle=True, random_state=42)              # Split the data into Train and Cross-Validation sets\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "for i, (train_crossval_index, test_index) in enumerate(kf_outer2.split(EEG_epochs)):\n",
    "    \n",
    "    if test_index == 7:\n",
    "        continue\n",
    "    \n",
    "    train_crossval = [EEG_epochs[i] for i in train_crossval_index]\n",
    "    test_epochs = np.concatenate([EEG_epochs[i] for i in test_index])\n",
    "    train_crossval_labels = [encoded[i] for i in train_crossval_index]\n",
    "    test_labels = np.concatenate([encoded[i] for i in test_index])\n",
    "    no_encoded_train_crossval = [no_encode[i] for i in train_crossval_index]\n",
    "    no_encoded_test = np.concatenate([no_encode[i] for i in test_index])\n",
    "\n",
    "    temp_pred = []\n",
    "    temp_true = []\n",
    "\n",
    "    for j, (train_index, val_index) in enumerate(kf_outer1.split(train_crossval)):\n",
    "        \n",
    "        \n",
    "        train_epochs = np.concatenate([train_crossval[i] for i in train_index])\n",
    "        crossval_epochs = np.concatenate([train_crossval[i] for i in val_index])\n",
    "        train_labels = np.concatenate([train_crossval_labels[i] for i in train_index])\n",
    "        crossval_labels = np.concatenate([train_crossval_labels[i] for i in val_index])\n",
    "        no_encoded_train = np.concatenate([no_encoded_train_crossval[i] for i in train_index])\n",
    "        no_encoded_crossval = np.concatenate([no_encoded_train_crossval[i] for i in val_index])\n",
    "        train_ids_for_save = [train_crossval_index[i] for i in train_index]\n",
    "        cross_val_ids_for_save = [train_crossval_index[i] for i in val_index]\n",
    "        \n",
    "        \n",
    "        print(\"Outer Loop {} and Inner Loop {}:\".format(i+1, j+1), \"\\n\")\n",
    "        print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "        #print(\"     Train labels' shape:                               \", train_labels.shape)\n",
    "        print(\"      Cross-validation epochs' shape:                    \", crossval_epochs.shape)\n",
    "        #print(\"     Cross-validation labels' shape:                    \", crossval_labels.shape)\n",
    "        print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "        #print(\"     Test labels' shape:                                \", test_labels.shape)\n",
    "        #print(\"     Train labels' shape (without encoding):            \", no_encoded_train.shape)\n",
    "        #print(\"     Cross-validation labels' shape (without encoding): \", no_encoded_crossval.shape)\n",
    "        #print(\"     Test labels' shape (without encoding):             \", no_encoded_test.shape)\n",
    "        print(\"      Train index:                                      \", train_ids_for_save)\n",
    "        print(\"      Cross-validation index:                           \", cross_val_ids_for_save)\n",
    "        print(\"      Test index:                                       \", test_index)\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = open('temp_stdout{}.txt'.format(i), 'w')  # Redirect output to a temporary file\n",
    "        train_features, CrossVal_features, test_features = feature_extraction_cv(train_epochs, no_encoded_train, crossval_epochs, test_epochs, number_of_bands=9, sampling_freq=250, low_cutoff=0, number_of_components=64)\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout\n",
    "    \n",
    "        print(\"Train features shape:            \", train_features.shape)\n",
    "        print(\"Cross-validation features shape: \", CrossVal_features.shape)\n",
    "        print(\"Test features shape:             \", test_features.shape)\n",
    "    \n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)\n",
    "        \n",
    "        temp_pred.append(models[\"{:02}{:02}\".format(i+1, j+1)].predict(test_features[60:]))\n",
    "        temp_true.append(test_labels[60:])\n",
    "        \n",
    "    all_tests_pred.append(temp_pred)\n",
    "    all_tests_true.append(temp_true)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003b1db8-fd82-4248-af7d-378f87f1f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"all_tests_pred_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"all_tests_true_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d30ebb-08d2-48c0-8cfd-dc3915c5da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_true = 2 - np.argmax(all_tests_true[i][j], axis=1)\n",
    "        y_pred = 2 - np.argmax(all_tests_pred[i][j], axis=1)\n",
    "    confusion_matrices_ap.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66dd2c7b-5dbb-4b67-b72a-15e759258c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>358</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)             358             162\n",
       "class 2 (True)             202             315"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792408a4-5e58-4ca5-a1c5-6e73b9dcd381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.311538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.605769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)        0.688462        0.311538\n",
       "class 2 (True)        0.388462        0.605769"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69570fb4-4782-4b2d-a397-a3f1ebac8bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for binary classification (Left vs Right hand):\n",
      "\n",
      "\n",
      "       Accuracy:                  0.65\n",
      "\n",
      "       Precision:                 0.66\n",
      "\n",
      "       Recall (Sensitivity):      0.61     \n",
      "\n",
      "       F1 Score:                  0.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    " \n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79248da6-dded-44ba-987d-1dc4eb71db65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
