{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42992946",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af32dba6-d557-4f5c-b2a9-6524cdd3636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from mne.decoding import CSP\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import copy\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import torch\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aa17ce7-4e1c-4f52-8963-abd86084b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bijan/py3x/Code_Zhang/Transfer_Learning_On_EEG_BCI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# projects/def-b09sdp/bijan/Phase2/P16.fdt\n",
    "path = !pwd\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f05065-9374-4e82-a6cb-cee8e826adeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working!!!!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gh\n",
    "except NameError:\n",
    "    print(\"Working!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7bc34-24a6-4250-89bf-4bc9422e0af4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45befd64-9db2-4cf8-b119-eae966306003",
   "metadata": {},
   "source": [
    "Mode: 'binary', '3-class', '4-class', '5-class', '6-class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec218e4-dc89-43dd-9105-6875b25f7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrapper(data_epochs, data_labels, mode='binary'):\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        epochs = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            binary_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2)]\n",
    "            #class2_epochs = participant_epochs[participant_labels==2]\n",
    "            #bi_epochs = np.concatenate((class1_epochs, class2_epochs), axis=0)\n",
    "            epochs.append(binary_epochs)\n",
    "    \n",
    "            binary_labels = participant_labels[(participant_labels==1) | (participant_labels==2)]\n",
    "            #bi_labels = np.concatenate((class1_labels, class2_labels), axis=0)\n",
    "            labels.append(binary_labels)\n",
    "            \n",
    "    elif mode == '3_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            labels.append(multiclass_labels)\n",
    "            \n",
    "            \n",
    "    elif mode == '4_class_RS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "        \n",
    "    elif mode == '4_class_LS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    elif mode == '6_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e97a6c-2926-493a-9a07-3d750b25f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_label_extractor(data, events, epoch_length, num_channels, sampling_freq):\n",
    "    \n",
    "    data = data.to_data_frame()\n",
    "    events = events[0]\n",
    "    third_column = events[:, 2]\n",
    "    mask = np.isin(third_column, [7, 8, 9, 10])\n",
    "    MI_events = events[mask]\n",
    "    \n",
    "    number_of_epochs = MI_events.shape[0]\n",
    "    labels = np.zeros((number_of_epochs,1)).astype(int)\n",
    "    epochs = np.zeros((number_of_epochs, num_channels, epoch_length * sampling_freq))\n",
    "    index = 0\n",
    "    for index in range(number_of_epochs):\n",
    "        start = int(MI_events[index, 0])\n",
    "        end = int(MI_events[index, 0]) + epoch_length * sampling_freq\n",
    "        all_channels = data.iloc[start:end]\n",
    "        epochs[index,:,:] = all_channels[all_channels.columns[1: num_channels+1]].T\n",
    "        labels[index] = MI_events[index, 2]\n",
    "\n",
    "            \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5154e2-0354-4913-a796-40e515129978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(y_data, method=OneHotEncoder):\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(y_data[0].reshape(-1, 1))\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        \n",
    "        a = encoder.transform(y_data[i].reshape(-1, 1))\n",
    "        y_data[i] = a.toarray()\n",
    "\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda8305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_csp(x_train, y_train, x_test, number_of_components=10):\n",
    "    \n",
    "        csp = CSP(number_of_components)\n",
    "        csp_fit = csp.fit(x_train, y_train)\n",
    "        train_feat = csp_fit.transform(x_train)\n",
    "        test_feat = csp_fit.transform(x_test)\n",
    "        return train_feat, test_feat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70687bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_4(dataset, labels, test_data, sampling_freq):\n",
    "\n",
    "    # Why number of bands were set to 24??\n",
    "    \n",
    "    low_cutoff = 0\n",
    "    number_of_bands = 8\n",
    "    for b in range(number_of_bands):\n",
    "        data = dataset.copy()\n",
    "        data_test = test_data.copy()\n",
    "        filtered_data = mne.filter.filter_data(data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        filtered_data_test = mne.filter.filter_data(data_test, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        [train_feats, test_feats] = calc_csp(filtered_data, labels[:, 0], filtered_data_test)\n",
    "        if b == 0:\n",
    "            train_features = train_feats\n",
    "            test_features = test_feats\n",
    "        else:\n",
    "            train_features = np.concatenate((train_features, train_feats), axis = 1)\n",
    "            test_features = np.concatenate((test_features, test_feats), axis = 1)\n",
    "        \n",
    "        low_cutoff += 4\n",
    "\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46e076",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Device (GPU\\CPU\\MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3963e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61c74e-3fdb-4e1a-b086-fc5180a12db4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cf427-6a5c-47af-ab15-a4d4203b1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    if path[0] == '/home/bijan/py3x/Code_Zhang/Transfer_Learning_On_EEG_BCI':\n",
    "    print(\"Running on cloud ...\")\n",
    "    print(\"Please make sure to modify how you read the data according to your need!\\n\\n\")\n",
    "    raw_data_path = \"/home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/\"\n",
    "\n",
    "    train_data_epochs = []\n",
    "    train_data_labels = []\n",
    "    test_data_epochs = []\n",
    "    test_data_labels = []\n",
    "    for participant_id in range(1, 10):\n",
    "        participant_E = f\"A0{participant_id}E\"\n",
    "        participant_T = f\"A0{participant_id}T\"\n",
    "        \n",
    "        file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "        file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "        \n",
    "        raw_train = mne.io.read_raw_gdf(file_path_T, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        raw_test = mne.io.read_raw_gdf(file_path_E, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        \n",
    "        \n",
    "        train_events = mne.events_from_annotations(raw_train)\n",
    "        test_events = mne.events_from_annotations(raw_test)\n",
    "        \n",
    "        tmin = 0.504\n",
    "        tmax = 2.5\n",
    "        \n",
    "        try:\n",
    "            train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
    "            test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
    "        except ValueError:\n",
    "            train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=(0, 0))\n",
    "            test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=(0, 0))\n",
    "        train_data_epochs.append(train_epochs.get_data())\n",
    "        test_data_epochs.append(test_epochs.get_data())\n",
    "        \n",
    "        train_data_labels.append(train_epochs.events[:, -1])\n",
    "        test_data_labels.append(test_epochs.events[:, -1])\n",
    "\n",
    "except NameError:\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "    train_data_epochs = []\n",
    "    train_data_labels = []\n",
    "    test_data_epochs = []\n",
    "    test_data_labels = []\n",
    "    for participant_id in range(1, 10):\n",
    "        participant_E = f\"A0{participant_id}E\"\n",
    "        participant_T = f\"A0{participant_id}T\"\n",
    "        \n",
    "        file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "        file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "        \n",
    "        raw_train = mne.io.read_raw_gdf(file_path_T, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        raw_test = mne.io.read_raw_gdf(file_path_E, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        \n",
    "        \n",
    "        train_events = mne.events_from_annotations(raw_train)\n",
    "        test_events = mne.events_from_annotations(raw_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "            train_epochs, train_labels = epoch_label_extractor(data, train_events, epoch_length = 4, num_channels = 22, sampling_freq = 250)\n",
    "            test_epochs, test_labels = epoch_label_extractor(data, events, epoch_length = 4, num_channels = 22, sampling_freq = 250)\n",
    "        \n",
    "        train_data_labels.append(train_epochs.events[:, -1])\n",
    "        test_data_labels.append(test_epochs.events[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4201e9e-75eb-48d0-a8bc-2d6e0785e99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf/A01E.gdf\"\n",
    "\n",
    "data = mne.io.read_raw_gdf(file_path_T, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "671b9ad6-cf20-407f-95e0-7294f3fa3e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>EEG-Fz</th>\n",
       "      <th>EEG-0</th>\n",
       "      <th>EEG-1</th>\n",
       "      <th>EEG-2</th>\n",
       "      <th>EEG-3</th>\n",
       "      <th>EEG-4</th>\n",
       "      <th>EEG-5</th>\n",
       "      <th>EEG-C3</th>\n",
       "      <th>EEG-6</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG-11</th>\n",
       "      <th>EEG-12</th>\n",
       "      <th>EEG-13</th>\n",
       "      <th>EEG-14</th>\n",
       "      <th>EEG-Pz</th>\n",
       "      <th>EEG-15</th>\n",
       "      <th>EEG-16</th>\n",
       "      <th>EOG-left</th>\n",
       "      <th>EOG-central</th>\n",
       "      <th>EOG-right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>20.849609</td>\n",
       "      <td>28.076172</td>\n",
       "      <td>26.660156</td>\n",
       "      <td>19.775391</td>\n",
       "      <td>14.892578</td>\n",
       "      <td>8.300781</td>\n",
       "      <td>41.748047</td>\n",
       "      <td>35.937500</td>\n",
       "      <td>32.666016</td>\n",
       "      <td>...</td>\n",
       "      <td>27.343750</td>\n",
       "      <td>21.533203</td>\n",
       "      <td>18.017578</td>\n",
       "      <td>28.906250</td>\n",
       "      <td>26.855469</td>\n",
       "      <td>22.363281</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>59.082031</td>\n",
       "      <td>14.648438</td>\n",
       "      <td>49.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004</td>\n",
       "      <td>-60.888672</td>\n",
       "      <td>-59.570312</td>\n",
       "      <td>-54.443359</td>\n",
       "      <td>-59.667969</td>\n",
       "      <td>-63.574219</td>\n",
       "      <td>-70.312500</td>\n",
       "      <td>-50.048828</td>\n",
       "      <td>-49.609375</td>\n",
       "      <td>-48.828125</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.976562</td>\n",
       "      <td>-56.787109</td>\n",
       "      <td>-60.644531</td>\n",
       "      <td>-48.828125</td>\n",
       "      <td>-52.197266</td>\n",
       "      <td>-55.859375</td>\n",
       "      <td>-53.125000</td>\n",
       "      <td>-27.343750</td>\n",
       "      <td>-68.847656</td>\n",
       "      <td>-44.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008</td>\n",
       "      <td>-24.560547</td>\n",
       "      <td>-14.941406</td>\n",
       "      <td>-15.234375</td>\n",
       "      <td>-14.990234</td>\n",
       "      <td>-23.925781</td>\n",
       "      <td>-25.683594</td>\n",
       "      <td>-6.542969</td>\n",
       "      <td>-5.322266</td>\n",
       "      <td>-7.958984</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.664062</td>\n",
       "      <td>-14.404297</td>\n",
       "      <td>-18.896484</td>\n",
       "      <td>-5.566406</td>\n",
       "      <td>-10.546875</td>\n",
       "      <td>-15.087891</td>\n",
       "      <td>-12.158203</td>\n",
       "      <td>13.671875</td>\n",
       "      <td>-35.156250</td>\n",
       "      <td>-5.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012</td>\n",
       "      <td>-38.232422</td>\n",
       "      <td>-32.861328</td>\n",
       "      <td>-30.029297</td>\n",
       "      <td>-30.419922</td>\n",
       "      <td>-35.351562</td>\n",
       "      <td>-43.115234</td>\n",
       "      <td>-25.048828</td>\n",
       "      <td>-28.955078</td>\n",
       "      <td>-24.804688</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.437500</td>\n",
       "      <td>-35.839844</td>\n",
       "      <td>-42.773438</td>\n",
       "      <td>-29.785156</td>\n",
       "      <td>-29.394531</td>\n",
       "      <td>-35.742188</td>\n",
       "      <td>-33.642578</td>\n",
       "      <td>9.765625</td>\n",
       "      <td>-58.593750</td>\n",
       "      <td>-34.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016</td>\n",
       "      <td>-45.214844</td>\n",
       "      <td>-46.093750</td>\n",
       "      <td>-40.332031</td>\n",
       "      <td>-40.478516</td>\n",
       "      <td>-42.041016</td>\n",
       "      <td>-50.195312</td>\n",
       "      <td>-41.650391</td>\n",
       "      <td>-46.484375</td>\n",
       "      <td>-36.914062</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.033203</td>\n",
       "      <td>-44.384766</td>\n",
       "      <td>-49.511719</td>\n",
       "      <td>-37.158203</td>\n",
       "      <td>-35.205078</td>\n",
       "      <td>-41.406250</td>\n",
       "      <td>-38.574219</td>\n",
       "      <td>-11.230469</td>\n",
       "      <td>-46.875000</td>\n",
       "      <td>-21.484375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    time     EEG-Fz      EEG-0      EEG-1      EEG-2      EEG-3      EEG-4  \\\n",
       "0  0.000  20.849609  28.076172  26.660156  19.775391  14.892578   8.300781   \n",
       "1  0.004 -60.888672 -59.570312 -54.443359 -59.667969 -63.574219 -70.312500   \n",
       "2  0.008 -24.560547 -14.941406 -15.234375 -14.990234 -23.925781 -25.683594   \n",
       "3  0.012 -38.232422 -32.861328 -30.029297 -30.419922 -35.351562 -43.115234   \n",
       "4  0.016 -45.214844 -46.093750 -40.332031 -40.478516 -42.041016 -50.195312   \n",
       "\n",
       "       EEG-5     EEG-C3      EEG-6  ...     EEG-11     EEG-12     EEG-13  \\\n",
       "0  41.748047  35.937500  32.666016  ...  27.343750  21.533203  18.017578   \n",
       "1 -50.048828 -49.609375 -48.828125  ... -50.976562 -56.787109 -60.644531   \n",
       "2  -6.542969  -5.322266  -7.958984  ...  -5.664062 -14.404297 -18.896484   \n",
       "3 -25.048828 -28.955078 -24.804688  ... -23.437500 -35.839844 -42.773438   \n",
       "4 -41.650391 -46.484375 -36.914062  ... -34.033203 -44.384766 -49.511719   \n",
       "\n",
       "      EEG-14     EEG-Pz     EEG-15     EEG-16   EOG-left  EOG-central  \\\n",
       "0  28.906250  26.855469  22.363281  25.000000  59.082031    14.648438   \n",
       "1 -48.828125 -52.197266 -55.859375 -53.125000 -27.343750   -68.847656   \n",
       "2  -5.566406 -10.546875 -15.087891 -12.158203  13.671875   -35.156250   \n",
       "3 -29.785156 -29.394531 -35.742188 -33.642578   9.765625   -58.593750   \n",
       "4 -37.158203 -35.205078 -41.406250 -38.574219 -11.230469   -46.875000   \n",
       "\n",
       "   EOG-right  \n",
       "0  49.804688  \n",
       "1 -44.433594  \n",
       "2  -5.859375  \n",
       "3 -34.179688  \n",
       "4 -21.484375  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_data_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8c289450-5afc-4fe5-bc3b-e2e0f0d2fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    }
   ],
   "source": [
    "events = mne.events_from_annotations(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ccabd69c-c2b9-4d27-a5e0-2fa0c7c4d051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      5],\n",
       "       [     0,      0,      3],\n",
       "       [ 30878,      0,      5],\n",
       "       ...,\n",
       "       [669791,      0,      8],\n",
       "       [671350,      0,      6],\n",
       "       [671850,      0,      9]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99627126-7525-4e78-84d2-fb72ec12471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1023': 1,\n",
       " '1072': 2,\n",
       " '276': 3,\n",
       " '277': 4,\n",
       " '32766': 5,\n",
       " '768': 6,\n",
       " '769': 7,\n",
       " '770': 8,\n",
       " '771': 9,\n",
       " '772': 10}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4da3b692-6a5c-4d66-84be-489b1a6c620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ex, labels_ex = epoch_label_extractor(data, events, epoch_length = 4, num_channels = 22, sampling_freq = 250)\n",
    "labels_ex = labels_ex-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f1e6cd49-7872-4c2d-ae88-bcfb7afa45db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 1000)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c084df58-f351-474e-94c9-1d690c8282ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2fed5015-5b92-4b3e-b578-94eae1aa3927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216,)\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 41 (2.2e-16 eps * 22 dim * 8.4e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 38 (2.2e-16 eps * 22 dim * 7.7e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 22 dim * 8.2e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 43 (2.2e-16 eps * 22 dim * 8.9e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 35 (2.2e-16 eps * 22 dim * 7.2e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 32 (2.2e-16 eps * 22 dim * 6.5e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 33 (2.2e-16 eps * 22 dim * 6.8e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 38 (2.2e-16 eps * 22 dim * 7.7e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 38 (2.2e-16 eps * 22 dim * 7.8e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 36 (2.2e-16 eps * 22 dim * 7.4e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 39 (2.2e-16 eps * 22 dim * 7.9e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 22 dim * 9.3e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 20 (2.2e-16 eps * 22 dim * 4e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 19 (2.2e-16 eps * 22 dim * 3.9e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 20 (2.2e-16 eps * 22 dim * 4.2e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 22 (2.2e-16 eps * 22 dim * 4.5e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 14 (2.2e-16 eps * 22 dim * 2.8e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 13 (2.2e-16 eps * 22 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 13 (2.2e-16 eps * 22 dim * 2.7e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 14 (2.2e-16 eps * 22 dim * 2.9e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 12 (2.2e-16 eps * 22 dim * 2.5e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 12 (2.2e-16 eps * 22 dim * 2.4e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 12 (2.2e-16 eps * 22 dim * 2.4e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 13 (2.2e-16 eps * 22 dim * 2.6e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 10 (2.2e-16 eps * 22 dim * 2.1e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 9.2 (2.2e-16 eps * 22 dim * 1.9e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 9 (2.2e-16 eps * 22 dim * 1.8e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 9.6 (2.2e-16 eps * 22 dim * 2e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 8.9 (2.2e-16 eps * 22 dim * 1.8e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 7.1 (2.2e-16 eps * 22 dim * 1.5e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 6.7 (2.2e-16 eps * 22 dim * 1.4e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 7.3 (2.2e-16 eps * 22 dim * 1.5e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Train features shape: (216, 80)\n",
      "Test features shape: (72, 80)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(epochs_ex, labels_ex)\n",
    "\n",
    "print(y_tr[:, 0].shape)\n",
    "\n",
    "train_features, test_features = feature_extraction_4(x_tr, y_tr, x_te, sampling_freq=250)\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Test features shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "27db5fa8-fedb-4695-99f1-2d6a46693e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 3, 1, 3, 0, 0, 3, 0, 1, 2, 0, 1, 0, 3, 1, 0, 2, 1, 2, 3,\n",
       "       3, 1, 0, 3, 3, 0, 3, 1, 3, 0, 2, 3, 1, 1, 2, 3, 0, 1, 0, 1, 0, 0,\n",
       "       3, 1, 1, 1, 0, 0, 3, 0, 2, 3, 3, 2, 3, 2, 0, 1, 0, 0, 2, 3, 0, 1,\n",
       "       3, 0, 2, 1, 2, 3, 3, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 3, 2, 1, 3, 0,\n",
       "       2, 1, 3, 2, 3, 3, 0, 2, 2, 2, 1, 3, 3, 1, 0, 0, 2, 0, 3, 0, 3, 2,\n",
       "       3, 0, 3, 0, 3, 2, 2, 2, 2, 0, 2, 1, 0, 3, 1, 3, 1, 2, 2, 2, 0, 0,\n",
       "       2, 0, 2, 1, 1, 0, 3, 2, 0, 2, 2, 3, 2, 2, 3, 2, 0, 1, 0, 2, 1, 2,\n",
       "       2, 1, 3, 1, 3, 0, 1, 0, 2, 0, 1, 0, 0, 0, 2, 3, 2, 1, 1, 0, 3, 2,\n",
       "       0, 0, 3, 0, 0, 3, 0, 3, 1, 1, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 3, 3,\n",
       "       1, 3, 3, 2, 0, 2, 1, 1, 3, 0, 1, 1, 3, 3, 2, 3, 3, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[:, 0] - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e6181f8c-de96-4037-a234-68f4d61641cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216,)\n",
      "(216, 80)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.73        17\n",
      "           1       0.85      0.89      0.87        19\n",
      "           2       0.86      0.67      0.75        18\n",
      "           3       0.64      0.89      0.74        18\n",
      "\n",
      "    accuracy                           0.78        72\n",
      "   macro avg       0.80      0.77      0.77        72\n",
      "weighted avg       0.80      0.78      0.78        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(y_tr[:, 0].shape)\n",
    "print(train_features.shape)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(train_features, y_tr[:, 0])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "print(classification_report(y_te[:, 0], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b5734-837d-4835-8c68-75d6a80ae395",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    pass\n",
    "\n",
    "elif device == 'cpu':\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "    train_data_epochs = []\n",
    "    train_data_labels = []\n",
    "    test_data_epochs = []\n",
    "    test_data_labels = []\n",
    "    for participant_id in range(1, 10):\n",
    "        participant_E = f\"A0{participant_id}E\"\n",
    "        participant_T = f\"A0{participant_id}T\"\n",
    "        \n",
    "        file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "        file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "        \n",
    "        raw_train = mne.io.read_raw_gdf(file_path_T, preload=True)\n",
    "        raw_test = mne.io.read_raw_gdf(file_path_E, preload=True)\n",
    "        \n",
    "        train_events = mne.events_from_annotations(raw_train)\n",
    "        test_events = mne.events_from_annotations(raw_test)\n",
    "        \n",
    "        tmin = 0.004\n",
    "        tmax = 4\n",
    "        sampling_freq = 250\n",
    "        \n",
    "        train_data = raw_train.to_data_frame()\n",
    "        test_data = raw_test.to_data_frame_frame()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c82e66a-6a62-4fc8-84b4-bd38d395c79e",
   "metadata": {},
   "source": [
    "\\\n",
    "\\\n",
    "Read all the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a012ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local ...\n",
      "Please make sure to change the data path!\n",
      "\n",
      "\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "7 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648774  =      0.000 ...  2595.096 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "6 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 600914  =      0.000 ...  2403.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660046  =      0.000 ...  2640.184 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 144 events and 500 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_3540\\2188678550.py:43: RuntimeWarning: No matching events found for 9 (event id 9)\n",
      "  train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_3540\\2188678550.py:43: RuntimeWarning: No matching events found for 10 (event id 10)\n",
      "  train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_3540\\2188678550.py:44: RuntimeWarning: No matching events found for 9 (event id 9)\n",
      "  test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_3540\\2188678550.py:44: RuntimeWarning: No matching events found for 10 (event id 10)\n",
      "  test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 144 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 679862  =      0.000 ...  2719.448 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "3 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 666372  =      0.000 ...  2665.488 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "6 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673134  =      0.000 ...  2692.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "4 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 687791  =      0.000 ...  2751.164 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675097  =      0.000 ...  2700.388 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 500 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "if device == 'cuda':\n",
    "    print(\"Running on cloud ...\")\n",
    "    print(\"Please make sure to modify how you read the data according to your need!\\n\\n\")\n",
    "    raw_data_path = \"/home/bijan/projects/def-b09sdp/bijan/Phase2/\"\n",
    "    data_epochs = []\n",
    "    data_labels = []\n",
    "\n",
    "    for participant_id in range(1, 10):\n",
    "        participant = f\"P{participant_id}\"\n",
    "        file_path = f\"{raw_data_path}/{participant}.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(file_path)\n",
    "        data_epochs.append(epochs.get_data())\n",
    "        data_labels.append(epochs.events[:, -1])\n",
    "\n",
    "elif device == 'cpu':\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "    train_data_epochs = []\n",
    "    train_data_labels = []\n",
    "    test_data_epochs = []\n",
    "    test_data_labels = []\n",
    "    for participant_id in range(1, 10):\n",
    "        participant_E = f\"A0{participant_id}E\"\n",
    "        participant_T = f\"A0{participant_id}T\"\n",
    "        \n",
    "        file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "        file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "        \n",
    "        raw_train = mne.io.read_raw_gdf(file_path_T, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        raw_test = mne.io.read_raw_gdf(file_path_E, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        \n",
    "        raw_train.set_eeg_reference()\n",
    "        raw_test.set_eeg_reference()\n",
    "        \n",
    "        train_events = mne.events_from_annotations(raw_train)\n",
    "        test_events = mne.events_from_annotations(raw_test)\n",
    "        \n",
    "        tmin = 0.504\n",
    "        tmax = 2.5\n",
    "        \n",
    "        try:\n",
    "            train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
    "            test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=None)\n",
    "        except ValueError:\n",
    "            train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=(0, 0))\n",
    "            test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn', tmin=tmin, tmax=tmax, baseline=(0, 0))\n",
    "        train_data_epochs.append(train_epochs.get_data())\n",
    "        test_data_epochs.append(test_epochs.get_data())\n",
    "        \n",
    "        train_data_labels.append(train_epochs.events[:, -1])\n",
    "        test_data_labels.append(test_epochs.events[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94598bfd-c790-48d8-9953-e3273ba37f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      5],\n",
       "       [     0,      0,      3],\n",
       "       [ 30878,      0,      5],\n",
       "       ...,\n",
       "       [669791,      0,      8],\n",
       "       [671350,      0,      6],\n",
       "       [671850,      0,      9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8c32f89-e0fa-43a5-8424-8219f61c27cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1023': 1,\n",
       " '1072': 2,\n",
       " '276': 3,\n",
       " '277': 4,\n",
       " '32766': 5,\n",
       " '768': 6,\n",
       " '769': 7,\n",
       " '770': 8,\n",
       " '771': 9,\n",
       " '772': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7d27c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673328,), (1, 673328))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0][1].shape, raw_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84cf04f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 train epochs:     (288, 22, 500)     Subject 1 train labels:     (288,)\n",
      "Subject 1 test epochs:      (288, 22, 500)     Subject 1 test labels:      (288,)\n",
      "Subject 2 train epochs:     (288, 22, 500)     Subject 2 train labels:     (288,)\n",
      "Subject 2 test epochs:      (281, 22, 500)     Subject 2 test labels:      (281,)\n",
      "Subject 3 train epochs:     (288, 22, 500)     Subject 3 train labels:     (288,)\n",
      "Subject 3 test epochs:      (282, 22, 500)     Subject 3 test labels:      (282,)\n",
      "Subject 4 train epochs:     (144, 22, 500)     Subject 4 train labels:     (144,)\n",
      "Subject 4 test epochs:      (144, 22, 500)     Subject 4 test labels:      (144,)\n",
      "Subject 5 train epochs:     (288, 22, 500)     Subject 5 train labels:     (288,)\n",
      "Subject 5 test epochs:      (285, 22, 500)     Subject 5 test labels:      (285,)\n",
      "Subject 6 train epochs:     (288, 22, 500)     Subject 6 train labels:     (288,)\n",
      "Subject 6 test epochs:      (282, 22, 500)     Subject 6 test labels:      (282,)\n",
      "Subject 7 train epochs:     (288, 22, 500)     Subject 7 train labels:     (288,)\n",
      "Subject 7 test epochs:      (284, 22, 500)     Subject 7 test labels:      (284,)\n",
      "Subject 8 train epochs:     (288, 22, 500)     Subject 8 train labels:     (288,)\n",
      "Subject 8 test epochs:      (288, 22, 500)     Subject 8 test labels:      (288,)\n",
      "Subject 9 train epochs:     (288, 22, 500)     Subject 9 train labels:     (288,)\n",
      "Subject 9 test epochs:      (288, 22, 500)     Subject 9 test labels:      (288,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(\"Subject {} train epochs:    \".format(i+1), train_data_epochs[i].shape, \"    Subject {} train labels:    \".format(i+1), train_data_labels[i].shape)\n",
    "    print(\"Subject {} test epochs:     \".format(i+1), test_data_epochs[i].shape, \"    Subject {} test labels:     \".format(i+1), test_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "864743ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_epochs = np.zeros(len(train_data_epochs)).tolist()\n",
    "all_data_labels = np.zeros(len(train_data_epochs)).tolist()\n",
    "\n",
    "for i in range(len(train_data_epochs)):\n",
    "    all_data_epochs[i] = np.concatenate((train_data_epochs[i], test_data_epochs[i]), axis=0)\n",
    "    all_data_labels[i] = np.concatenate((train_data_labels[i], test_data_labels[i]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17af4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific element in train and test sets:       -1.5491832386363597e-06 6.613991477272725e-06\n",
      "The same element in all data set combined:     -1.5491832386363597e-06 6.613991477272725e-06\n",
      "\n",
      "\n",
      "\n",
      "Checking the labels in train and test:         7 8\n",
      "The same element in all data set combined:     7 8\n"
     ]
    }
   ],
   "source": [
    "# Checking if the concatenation does not have a problem!\n",
    "\n",
    "print(\"Specific element in train and test sets:      \", train_data_epochs[i][10, 10, 10], test_data_epochs[i][100, 13, 14])\n",
    "print(\"The same element in all data set combined:    \", all_data_epochs[i][10, 10, 10], all_data_epochs[i][388, 13, 14])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Checking the labels in train and test:        \", train_data_labels[i][10], test_data_labels[i][100])\n",
    "print(\"The same element in all data set combined:    \", all_data_labels[i][10], all_data_labels[i][388])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a9670ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data epoch shape (sub 0):     (576, 22, 500)     All label shape (sub 0):      (576,)\n",
      "All data epoch shape (sub 1):     (569, 22, 500)     All label shape (sub 1):      (569,)\n",
      "All data epoch shape (sub 2):     (570, 22, 500)     All label shape (sub 2):      (570,)\n",
      "All data epoch shape (sub 3):     (288, 22, 500)     All label shape (sub 3):      (288,)\n",
      "All data epoch shape (sub 4):     (573, 22, 500)     All label shape (sub 4):      (573,)\n",
      "All data epoch shape (sub 5):     (570, 22, 500)     All label shape (sub 5):      (570,)\n",
      "All data epoch shape (sub 6):     (572, 22, 500)     All label shape (sub 6):      (572,)\n",
      "All data epoch shape (sub 7):     (576, 22, 500)     All label shape (sub 7):      (576,)\n",
      "All data epoch shape (sub 8):     (576, 22, 500)     All label shape (sub 8):      (576,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data_epochs)):\n",
    "    print(\"All data epoch shape (sub {}):    \".format(i), all_data_epochs[i].shape, \"    All label shape (sub {}):     \".format(i), all_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dda5acdc-8ddf-4426-bc6c-b6cbe0842c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(np.isinf(all_data_epochs[i]).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d77c53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "433703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_encode = copy.deepcopy(all_data_labels)\n",
    "encoded = encoder(all_data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26a1f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Length: 9\n",
      "labels Length: 9\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - Epochs[0] shape: (288,)\n",
      "Participant 16 - labels[0] shape: (288, 4)\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - labels[0]:\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Epochs Length:\", len(all_data_labels))\n",
    "print(\"labels Length:\", len(encoded))\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - Epochs[0] shape:\", no_encode[3].shape)\n",
    "print(\"Participant 16 - labels[0] shape:\", encoded[3].shape)\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - labels[0]:\")\n",
    "print(all_data_labels[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc6835",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Checking the criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d683208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24debe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dbccfbb-49ff-461f-b50f-0f7448e933ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Within Subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94d55a8f-6ef7-4d36-b1a9-cfb8c89122a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/500] - Avg Training Loss: 1.7928 Train Accuracy: 0.16 - Test Loss: 1.80 - Test Accuracy: 0.28\n",
      "Epoch [  6/500] - Avg Training Loss: 1.7879 Train Accuracy: 0.17 - Test Loss: 1.84 - Test Accuracy: 0.00\n",
      "Epoch [ 11/500] - Avg Training Loss: 1.7936 Train Accuracy: 0.18 - Test Loss: 1.85 - Test Accuracy: 0.00\n",
      "Epoch [ 16/500] - Avg Training Loss: 1.7871 Train Accuracy: 0.18 - Test Loss: 1.86 - Test Accuracy: 0.00\n",
      "Epoch [ 21/500] - Avg Training Loss: 1.7876 Train Accuracy: 0.21 - Test Loss: 1.84 - Test Accuracy: 0.00\n",
      "Epoch [ 26/500] - Avg Training Loss: 1.7900 Train Accuracy: 0.18 - Test Loss: 1.85 - Test Accuracy: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m train_inputs, train_labels \u001b[38;5;241m=\u001b[39m train_inputs\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device), train_labels\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 79\u001b[0m train_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(train_outputs, train_labels)\n\u001b[0;32m     81\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "participants = [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15]\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "max_epochs = 500\n",
    "learning_rate=0.0001\n",
    "weight_decay=0.25*learning_rate\n",
    "\n",
    "confusion_matrices = []\n",
    "\n",
    "\n",
    "for i in range(len(EEG_epochs)):\n",
    "\n",
    "    epoch_participant = EEG_epochs[i]\n",
    "    encoded_participant = encoded[i]\n",
    "    \n",
    "    split_index = 40 # The last n = split_index samples are in the test set\n",
    "    \n",
    "    train_epoch, test_epoch = epoch_participant[:-1*split_index], epoch_participant[-1*split_index:]\n",
    "    train_label, test_labels = encoded_participant[:-1*split_index], encoded_participant[-1*split_index:]\n",
    "    no_encode_train_label = no_encode[i][:-1*split_index]\n",
    "    no_encode_test_label = no_encode[i][-1*split_index:]\n",
    "    \n",
    "    # print(train_epoch.shape)\n",
    "    # print(train_label.shape)\n",
    "    # print(len(no_encode_train_label))\n",
    "    \n",
    "    batch_size = 12  # Set your batch size\n",
    "    fold_num = int(EEG_epochs[i].shape[0] // batch_size)\n",
    "    \n",
    "\n",
    "    \n",
    "    #model = Deep4Net(in_chans=64, n_classes=4, input_window_samples=1123, final_conv_length='auto')\n",
    "    \n",
    "    model = new_model\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    patience = 300\n",
    "    best_metric = float('inf')\n",
    "    counter = 1\n",
    "    best_model_state = model.state_dict()\n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    train_acc_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    test_acc_epochs = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        temp_train_pred = []\n",
    "        temp_train_true = []\n",
    "        \n",
    "        train_running_loss = 0\n",
    "        \n",
    "        stratified_kfold = StratifiedKFold(n_splits=fold_num, random_state=1, shuffle=True)\n",
    "        \n",
    "        for _, (_, train_batch_index) in enumerate(stratified_kfold.split(train_epoch, no_encode_train_label)):\n",
    "            \n",
    "            batch_epoch, batch_label = train_epoch[train_batch_index], train_label[train_batch_index]\n",
    "            \n",
    "            train_dataset = EEG_Dataset(batch_epoch, batch_label, transform=None)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_epoch.shape[0])\n",
    "        \n",
    "        \n",
    "            for train_inputs, train_labels in train_loader:\n",
    "                #print(train_labels)\n",
    "                train_inputs, train_labels = train_inputs.to(torch.float32).to(device), train_labels.to(torch.float32).to(device)\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "                train_outputs = model(train_inputs)\n",
    "                loss = criterion(train_outputs, train_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_running_loss += loss.item()\n",
    "                y_pred_train = torch.argmax(train_outputs, 1).tolist()\n",
    "                y_true_train = torch.argmax(train_labels, 1).tolist()\n",
    "                temp_train_pred.extend(y_pred_train)\n",
    "                temp_train_true.extend(y_true_train)\n",
    "                \n",
    "        test_dataset = EEG_Dataset(test_epoch, test_labels, transform=None)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=test_epoch.shape[0])\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for test_input, test_label in test_loader:\n",
    "                \n",
    "                test_input, test_label = test_input.to(torch.float32).to(device), test_label.to(torch.float32).to(device)\n",
    "                test_output = model(test_input)\n",
    "                test_loss = criterion(test_output, test_label).item()\n",
    "                y_pred_test = torch.argmax(test_output, 1).tolist()\n",
    "                y_true_test = torch.argmax(test_label, 1).tolist()\n",
    "                test_conf_mat = confusion_matrix(y_true_test, y_pred_test)\n",
    "                test_accuracy = np.trace(test_conf_mat) / test_conf_mat.sum()\n",
    "        \n",
    "        avg_train_loss = train_running_loss / fold_num\n",
    "        \n",
    "        train_loss_epochs.append(avg_train_loss)\n",
    "        test_loss_epochs.append(test_loss)\n",
    "        test_acc_epochs.append(test_accuracy)\n",
    "        train_conf_mat = confusion_matrix(temp_train_true, temp_train_pred)\n",
    "        train_accuracy = np.trace(train_conf_mat) / train_conf_mat.sum()\n",
    "        train_acc_epochs.append(train_accuracy)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch [{(epoch + 1): 3d}/{max_epochs}] - Avg Training Loss: {avg_train_loss:.4f} Train Accuracy: {train_accuracy:.2f} - Test Loss: {test_loss:.2f} - Test Accuracy: {test_accuracy:.2f}\")\n",
    "        \n",
    "        if test_loss < best_metric:\n",
    "            best_metric = test_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            counter = 1\n",
    "        \n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter > patience:\n",
    "            break\n",
    "        best_epoch = epoch-patience+2\n",
    "        epochs_range = np.arange(1, len(train_loss_epochs[:best_epoch])+1)\n",
    "        \n",
    "        \n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    \n",
    "                \n",
    "    test_input, test_labels = torch.tensor(test_epoch, dtype=torch.float32).to(device), torch.tensor(test_labels, dtype=torch.float32).to(device)\n",
    "    test_output = model(test_input)\n",
    "    y_pred_test = torch.argmax(test_output, 1).tolist()\n",
    "    y_true_test = torch.argmax(test_labels, 1).tolist()\n",
    "    all_tests_true.append(y_true_test)\n",
    "    all_tests_pred.append(y_pred_test)\n",
    "        \n",
    "    \n",
    "    \n",
    "    models.append(best_model_state)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(\"Participant {}\".format(participants[i]))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(epochs_range, train_loss_epochs[:best_epoch])\n",
    "    plt.plot(epochs_range, test_loss_epochs[:best_epoch])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(epochs_range, train_acc_epochs[:best_epoch])\n",
    "    plt.plot(epochs_range, test_acc_epochs[:best_epoch])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "    plt.savefig(\"P{}_within_subject.jpg\".format(participants[i]))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d3291b7-f6d9-45fb-a772-9660b71b43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tests_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "534ec3fc-0aa8-4f87-b5ab-30fc25f1369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(all_tests_pred[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c4ea157-3a96-4d27-ba8f-9605c2c75bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_tests_true)):\n",
    "   print(all_tests_true[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38ab53e9-c603-4f26-8365-d6ed4464cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "702c0285-fdf5-4b52-adfc-f4d4ae6986f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 3 1]\n",
      " [0 5 0 5]\n",
      " [2 3 5 0]\n",
      " [0 4 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ebdd581-553d-4aed-8587-6f272aae0b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "      <th>class 3 (Pred)</th>\n",
       "      <th>class 4 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3 (True)</th>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 4 (True)</th>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)  class 3 (Pred)  class 4 (Pred)\n",
       "class 1 (True)              73              18              28              11\n",
       "class 2 (True)              12              59              23              36\n",
       "class 3 (True)              27              19              68              16\n",
       "class 4 (True)              12              45              24              49"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)', 'class 4 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)', 'class 4 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b3bd396-0100-47f1-87bf-51160149d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "      <th>class 3 (Pred)</th>\n",
       "      <th>class 4 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 4 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)  class 3 (Pred)  class 4 (Pred)\n",
       "class 1 (True)        0.561538        0.000000        0.000000        0.000000\n",
       "class 2 (True)        0.000000        0.453846        0.000000        0.000000\n",
       "class 3 (True)        0.000000        0.000000        0.523077        0.000000\n",
       "class 4 (True)        0.000000        0.000000        0.000000        0.376923"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation * np.eye(4, 4) / 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "37da8839-f7ca-4302-b2cd-d39aecd2b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bijan/py3x/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4788461538461538"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(summation * np.eye(4, 4) / 130).sum() / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29cd52-5dcf-4ae1-bb58-79a1b5db4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = summation / len(confusion_matrices)\n",
    "mean_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70316f-470e-4a4a-bfd0-8fb6499bc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'mean_confusion_matrix' is the mean confusion matrix NumPy array\n",
    "mean_confusion_matrix = sum(confusion_matrices) / len(confusion_matrices)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d5222-55aa-4e69-aa7c-59f9a001736d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross-subjects (WO hyperparameter tuning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9f678b-ce96-4788-a2d8-f90f4334dc63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 \n",
      "\n",
      "      Train epochs' shape:                                (4297, 22, 500)\n",
      "      Test epochs' shape:                                 (573, 22, 500)\n",
      "      Test labels' shape:                                 (573, 4)\n",
      "      Train labels' shape (without encoding):             (4297,)\n",
      "      Test labels' shape (without encoding):              (573,)\n",
      "      Train index:                                        [1, 2, 3, 4, 6, 7, 8, 9]\n",
      "      Test index:                                         [5]\n",
      "\n",
      "\n",
      "\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 3.9e-05 (2.2e-16 eps * 22 dim * 8e+09  max singular value)\n",
      "    Estimated rank (mag): 21\n",
      "    MAG: rank 21 computed from 22 data channels with 0 projectors\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 22 -> 21\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 3.9e-05 (2.2e-16 eps * 22 dim * 8e+09  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 3.7e-05 (2.2e-16 eps * 22 dim * 7.5e+09  max singular value)\n",
      "    Estimated rank (mag): 21\n",
      "    MAG: rank 21 computed from 22 data channels with 0 projectors\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 22 -> 21\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 3.6e-05 (2.2e-16 eps * 22 dim * 7.4e+09  max singular value)\n",
      "    Estimated rank (mag): 21\n",
      "    MAG: rank 21 computed from 22 data channels with 0 projectors\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 22 -> 21\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\mne\\decoding\\csp.py:678: RuntimeWarning: invalid value encountered in sqrt\n",
      "  omega = np.sqrt(omega12 * omega21)\n",
      "C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\mne\\decoding\\csp.py:680: RuntimeWarning: invalid value encountered in sqrt\n",
      "  tmp = np.sqrt(omega21 / omega12)\n",
      "C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\mne\\decoding\\csp.py:690: RuntimeWarning: invalid value encountered in sqrt\n",
      "  tmp = np.real(tmp + np.sqrt(tmp**2 - h12 * h21))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 61\u001b[0m\n\u001b[0;32m     43\u001b[0m     model \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis()\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#     # Normalizing the features\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#     mean = train_epochs.mean(axis=(0, 2), keepdims=True)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#     std = train_epochs.std(axis=(0, 2), keepdims=True)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#     # Commented the normalization part since it reduces the rank of data and rasing errors with \u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#     # CSP filter bank\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     train_features, test_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extraction_4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_encoded_train_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(train_features, no_encoded_train_labels)\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mfeature_extraction_4\u001b[1;34m(dataset, labels, test_data, sampling_freq)\u001b[0m\n\u001b[0;32m     10\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mfilter\u001b[38;5;241m.\u001b[39mfilter_data(data, sampling_freq, low_cutoff, low_cutoff \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m filtered_data_test \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mfilter\u001b[38;5;241m.\u001b[39mfilter_data(data_test, sampling_freq, low_cutoff, low_cutoff \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m [train_feats, test_feats] \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_csp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_data_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     14\u001b[0m     train_features \u001b[38;5;241m=\u001b[39m train_feats\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mcalc_csp\u001b[1;34m(x_train, y_train, x_test, number_of_components)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_csp\u001b[39m(x_train, y_train, x_test, number_of_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      3\u001b[0m         csp \u001b[38;5;241m=\u001b[39m CSP(number_of_components)\n\u001b[1;32m----> 4\u001b[0m         csp_fit \u001b[38;5;241m=\u001b[39m \u001b[43mcsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         train_feat \u001b[38;5;241m=\u001b[39m csp_fit\u001b[38;5;241m.\u001b[39mtransform(x_train)\n\u001b[0;32m      6\u001b[0m         test_feat \u001b[38;5;241m=\u001b[39m csp_fit\u001b[38;5;241m.\u001b[39mtransform(x_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\mne\\decoding\\csp.py:196\u001b[0m, in \u001b[0;36mCSP.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    193\u001b[0m eigen_vectors \u001b[38;5;241m=\u001b[39m eigen_vectors[:, ix]\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters_ \u001b[38;5;241m=\u001b[39m eigen_vectors\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatterns_ \u001b[38;5;241m=\u001b[39m \u001b[43mpinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigen_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m pick_filters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters_[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components]\n\u001b[0;32m    199\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([np\u001b[38;5;241m.\u001b[39mdot(pick_filters, epoch) \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m X])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\mne\\fixes.py:967\u001b[0m, in \u001b[0;36mpinv\u001b[1;34m(a, rtol)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpinv\u001b[39m(a, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    966\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a pseudo-inverse of a matrix.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 967\u001b[0m     u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m a\n\u001b[0;32m    969\u001b[0m     maxS \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(s)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\linalg\\linalg.py:1642\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1639\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[0;32m   1641\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1642\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1643\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1644\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\linalg\\linalg.py:98\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "participants = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf_outer2.split(all_data_epochs)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_epochs = np.concatenate([all_data_epochs[j] for j in train_index])\n",
    "    test_epochs = np.concatenate([all_data_epochs[k] for k in test_index])\n",
    "    train_labels = np.concatenate([encoded[l] for l in train_index])\n",
    "    test_labels = np.concatenate([encoded[m] for m in test_index])\n",
    "    no_encoded_train_labels = np.concatenate([no_encode[n] for n in train_index])\n",
    "    no_encoded_test_labels = np.concatenate([no_encode[o] for o in test_index])\n",
    "    train_ids_for_save = [participants[i] for i in train_index]\n",
    "    test_ids_for_save = [participants[i] for i in test_index]\n",
    "    \n",
    "    \n",
    "    print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "    print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "\n",
    "    print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "    print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "    print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "    print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "    print(\"      Train index:                                       \", train_ids_for_save)\n",
    "\n",
    "    print(\"      Test index:                                        \", test_ids_for_save)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Create the EEGNet model\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     # Normalizing the features\n",
    "#     mean = train_epochs.mean(axis=(0, 2), keepdims=True)\n",
    "#     std = train_epochs.std(axis=(0, 2), keepdims=True)\n",
    "    \n",
    "#     print(mean.shape)\n",
    "#     print(std.shape)\n",
    "    \n",
    "#     norm_train_epochs = (train_epochs - mean) / std\n",
    "#     norm_test_epochs = (test_epochs - mean) / std\n",
    "#     # Commented the normalization part since it reduces the rank of data and rasing errors with \n",
    "#     # CSP filter bank\n",
    "    \n",
    "    \n",
    "    train_features, test_features = feature_extraction_4(train_epochs, no_encoded_train_labels, test_epochs, sampling_freq = 250)\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_features, no_encoded_train_labels)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model.predict(test_features)\n",
    "    \n",
    "    print(classification_report(no_encoded_test_labels, y_pred))\n",
    "\n",
    "    # Collect training metrics\n",
    "    train_loss_epochs.extend(history.history['loss'])\n",
    "    train_acc_epochs.extend(history.history['accuracy'])\n",
    "\n",
    "    # Collect testing metrics\n",
    "    test_loss_epochs.extend(history.history['val_loss'])\n",
    "    test_acc_epochs.extend(history.history['val_accuracy'])\n",
    "    \n",
    "    epochs_range = np.arange(1, len(train_loss_epochs[:-1*patience])+1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(\"Participant {}\".format(participants[test_index[0]]))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(epochs_range, train_loss_epochs[:-1*patience])\n",
    "    plt.plot(epochs_range, test_loss_epochs[:-1*patience])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(epochs_range, train_acc_epochs[:-1*patience])\n",
    "    plt.plot(epochs_range, test_acc_epochs[:-1*patience])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "    plt.savefig(\"P{}.jpg\".format(participants[test_index[0]]))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a28c468c-db9a-4d3f-8138-d4af320bfe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tests_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca1ee2d3-427e-40f7-9212-3eb01de03382",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd5796f-1cf4-4f51-9ab3-f2735b410bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>284</td>\n",
       "      <td>74</td>\n",
       "      <td>96</td>\n",
       "      <td>177</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>75</td>\n",
       "      <td>285</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>214</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>257</td>\n",
       "      <td>69</td>\n",
       "      <td>84</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>261</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>214</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>87</td>\n",
       "      <td>261</td>\n",
       "      <td>81</td>\n",
       "      <td>98</td>\n",
       "      <td>199</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>95</td>\n",
       "      <td>83</td>\n",
       "      <td>234</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             L (Pred)  LS (Pred)  S (Pred)  RS (True)  R (True)  Rest (Pred)\n",
       "L (True)          284         74        96        177        69           80\n",
       "LS (True)          75        285        79         75       214           52\n",
       "S (True)           82         90       257         69        84          198\n",
       "RS (True)         261         81        75        214        80           69\n",
       "R (True)           87        261        81         98       199           54\n",
       "Rest (True)        95         83       234         79        84          205"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['L (True)', 'LS (True)', 'S (True)', 'RS (True)', 'R (True)', 'Rest (True)'], columns=['L (Pred)', 'LS (Pred)', 'S (Pred)', 'RS (True)', 'R (True)', 'Rest (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0234527d-ee6f-4084-bd58-09bbffc2e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L (True)       780\n",
       "LS (True)      780\n",
       "S (True)       780\n",
       "RS (True)      780\n",
       "R (True)       780\n",
       "Rest (True)    780\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17634ff8-1043-48bb-9d81-d8e4c3b96ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>36.410256</td>\n",
       "      <td>9.487179</td>\n",
       "      <td>12.307692</td>\n",
       "      <td>22.692308</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>10.512821</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>32.948718</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>25.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>10.256410</td>\n",
       "      <td>8.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>11.153846</td>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>12.564103</td>\n",
       "      <td>25.512821</td>\n",
       "      <td>6.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>12.179487</td>\n",
       "      <td>10.641026</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>26.282051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              L (Pred)  LS (Pred)   S (Pred)  RS (True)   R (True)  \\\n",
       "L (True)     36.410256   9.487179  12.307692  22.692308   8.846154   \n",
       "LS (True)     9.615385  36.538462  10.128205   9.615385  27.435897   \n",
       "S (True)     10.512821  11.538462  32.948718   8.846154  10.769231   \n",
       "RS (True)    33.461538  10.384615   9.615385  27.435897  10.256410   \n",
       "R (True)     11.153846  33.461538  10.384615  12.564103  25.512821   \n",
       "Rest (True)  12.179487  10.641026  30.000000  10.128205  10.769231   \n",
       "\n",
       "             Rest (Pred)  \n",
       "L (True)       10.256410  \n",
       "LS (True)       6.666667  \n",
       "S (True)       25.384615  \n",
       "RS (True)       8.846154  \n",
       "R (True)        6.923077  \n",
       "Rest (True)    26.282051  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 780 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0da3ca-2632-4cde-9ff0-fbced848e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"3class_all_tests_pred\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"3class_all_tests_true\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)\n",
    "\n",
    "    \n",
    "print(all_tests_pred[1][1].shape)\n",
    "print(all_tests_pred[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6368512-0663-4c9f-a354-f5049fecec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3class_all_tests_pred\", \"rb\") as fp:\n",
    "    rand_var = pickle.load(fp)\n",
    "\n",
    "    \n",
    "with open(\"3class_all_tests_true\", \"rb\") as fp:\n",
    "    rand_var2 = pickle.load(fp)\n",
    "print(rand_var[12][1].shape)\n",
    "print(rand_var2[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08905-a166-4f57-80c1-b2cc22f13c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests_pred[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43d0b8-df4f-4cea-862b-22c54ed434f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(all_tests_true[12][1], axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5f8a9-1df5-413e-97d7-2af43d8684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 50, 6]])\n",
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ee94d-1d88-44be-a4b7-e6b61d848aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e45e8-f7bc-4075-bb3c-2f475450f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "y_pred_prob = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_pred = np.zeros(all_tests_true[i][0].shape)\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_pred += all_tests_pred[i][j]\n",
    "    y_pred_prob.append(y_pred/6)\n",
    "    confusion_matrices_ap.append(confusion_matrix(np.argmax(all_tests_true[i][0], axis=1)+1, np.argmax(y_pred_prob[i], axis=1)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b12477-bb1b-496a-b16f-a3e2736bf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659f9e1-6fcb-4fa8-8e1d-b2b29483a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = summation.values.sum()\n",
    "correct_predictions = summation.values.trace()\n",
    "overall_accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = summation.values.diagonal() / summation.sum(axis=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Accuracy for Class {i + 1}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098dbcb-6f3d-424f-a64e-bcb8de189e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7df6f-7e9d-47d8-b08d-2790c224d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation / (13 * 40) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa6dc-4794-4e57-b493-80ce26effec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([1, 1, 2, 2, 3, 3, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba87097-1690-404c-b051-55f9c13c3473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test for the effect of calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab11fff1-54d3-4dcc-8ac1-bb29e3b1e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "Calibrated_model = []\n",
    "for file in os.listdir(\"/home/bijan/py3x\"):\n",
    "    if file.endswith(\".h5\") and file.startswith(\"Calibrated\"):\n",
    "        Calibrated_model.append(file)\n",
    "    elif file.endswith(\".h5\") and file.startswith(\"Model\"):\n",
    "        models.append(file)\n",
    "        \n",
    "Calibrated_model = sorted(Calibrated_model)\n",
    "models = sorted(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6d2b9-976c-48c7-8f69-ca5033ad00dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50466690-38ae-4f90-9012-1457989185c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "Calibrated_models = {}\n",
    "for i in range(14):\n",
    "    if i == 8:\n",
    "        continue\n",
    "        \n",
    "    for j in range(6):\n",
    "        #print(\"Model{}{}.h5\".format(i+1, j+1))\n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb10d86e-1611-4280-8da5-a61bcf95bb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0203'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:02}{:02}\".format(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa5a0ea-0c50-4ec8-873a-327b68baee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b34579d-f2e3-4917-9757-ef6058078bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Calibrated_models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33991647-0cda-498a-9e52-6950779cc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "      Cross-validation index:                            [0, 9, 12]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [5, 8]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1537, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (220, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13]\n",
      "      Cross-validation index:                            [7, 10]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1537, 576)\n",
      "Cross-validation features shape:  (220, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee414b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 1 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [3, 6]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee415fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 2 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1338, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 5, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1338, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1479, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1479, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [5, 13]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [8, 11]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1539, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (219, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [3, 7]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1539, 576)\n",
      "Cross-validation features shape:  (219, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 3 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_subjects = len(EEG_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "models = {}\n",
    "Calibrated_models = {}\n",
    "\n",
    "kf_outer1 = KFold(n_splits=6, shuffle=True, random_state=42)              # Split the data into Train and Cross-Validation sets\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "for i, (train_crossval_index, test_index) in enumerate(kf_outer2.split(EEG_epochs)):\n",
    "    \n",
    "    if test_index == 7:\n",
    "        continue\n",
    "    \n",
    "    train_crossval = [EEG_epochs[i] for i in train_crossval_index]\n",
    "    test_epochs = np.concatenate([EEG_epochs[i] for i in test_index])\n",
    "    train_crossval_labels = [encoded[i] for i in train_crossval_index]\n",
    "    test_labels = np.concatenate([encoded[i] for i in test_index])\n",
    "    no_encoded_train_crossval = [no_encode[i] for i in train_crossval_index]\n",
    "    no_encoded_test = np.concatenate([no_encode[i] for i in test_index])\n",
    "\n",
    "    temp_pred = []\n",
    "    temp_true = []\n",
    "\n",
    "    for j, (train_index, val_index) in enumerate(kf_outer1.split(train_crossval)):\n",
    "        \n",
    "        \n",
    "        train_epochs = np.concatenate([train_crossval[i] for i in train_index])\n",
    "        crossval_epochs = np.concatenate([train_crossval[i] for i in val_index])\n",
    "        train_labels = np.concatenate([train_crossval_labels[i] for i in train_index])\n",
    "        crossval_labels = np.concatenate([train_crossval_labels[i] for i in val_index])\n",
    "        no_encoded_train = np.concatenate([no_encoded_train_crossval[i] for i in train_index])\n",
    "        no_encoded_crossval = np.concatenate([no_encoded_train_crossval[i] for i in val_index])\n",
    "        train_ids_for_save = [train_crossval_index[i] for i in train_index]\n",
    "        cross_val_ids_for_save = [train_crossval_index[i] for i in val_index]\n",
    "        \n",
    "        \n",
    "        print(\"Outer Loop {} and Inner Loop {}:\".format(i+1, j+1), \"\\n\")\n",
    "        print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "        #print(\"     Train labels' shape:                               \", train_labels.shape)\n",
    "        print(\"      Cross-validation epochs' shape:                    \", crossval_epochs.shape)\n",
    "        #print(\"     Cross-validation labels' shape:                    \", crossval_labels.shape)\n",
    "        print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "        #print(\"     Test labels' shape:                                \", test_labels.shape)\n",
    "        #print(\"     Train labels' shape (without encoding):            \", no_encoded_train.shape)\n",
    "        #print(\"     Cross-validation labels' shape (without encoding): \", no_encoded_crossval.shape)\n",
    "        #print(\"     Test labels' shape (without encoding):             \", no_encoded_test.shape)\n",
    "        print(\"      Train index:                                      \", train_ids_for_save)\n",
    "        print(\"      Cross-validation index:                           \", cross_val_ids_for_save)\n",
    "        print(\"      Test index:                                       \", test_index)\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = open('temp_stdout{}.txt'.format(i), 'w')  # Redirect output to a temporary file\n",
    "        train_features, CrossVal_features, test_features = feature_extraction_cv(train_epochs, no_encoded_train, crossval_epochs, test_epochs, number_of_bands=9, sampling_freq=250, low_cutoff=0, number_of_components=64)\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout\n",
    "    \n",
    "        print(\"Train features shape:            \", train_features.shape)\n",
    "        print(\"Cross-validation features shape: \", CrossVal_features.shape)\n",
    "        print(\"Test features shape:             \", test_features.shape)\n",
    "    \n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)\n",
    "        \n",
    "        temp_pred.append(models[\"{:02}{:02}\".format(i+1, j+1)].predict(test_features[60:]))\n",
    "        temp_true.append(test_labels[60:])\n",
    "        \n",
    "    all_tests_pred.append(temp_pred)\n",
    "    all_tests_true.append(temp_true)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003b1db8-fd82-4248-af7d-378f87f1f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"all_tests_pred_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"all_tests_true_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d30ebb-08d2-48c0-8cfd-dc3915c5da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_true = 2 - np.argmax(all_tests_true[i][j], axis=1)\n",
    "        y_pred = 2 - np.argmax(all_tests_pred[i][j], axis=1)\n",
    "    confusion_matrices_ap.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66dd2c7b-5dbb-4b67-b72a-15e759258c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>358</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)             358             162\n",
       "class 2 (True)             202             315"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792408a4-5e58-4ca5-a1c5-6e73b9dcd381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.311538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.605769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)        0.688462        0.311538\n",
       "class 2 (True)        0.388462        0.605769"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69570fb4-4782-4b2d-a397-a3f1ebac8bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for binary classification (Left vs Right hand):\n",
      "\n",
      "\n",
      "       Accuracy:                  0.65\n",
      "\n",
      "       Precision:                 0.66\n",
      "\n",
      "       Recall (Sensitivity):      0.61     \n",
      "\n",
      "       F1 Score:                  0.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    " \n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79248da6-dded-44ba-987d-1dc4eb71db65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3x",
   "language": "python",
   "name": "py3x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
