{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42992946",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af32dba6-d557-4f5c-b2a9-6524cdd3636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from mne.decoding import CSP\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import copy\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "import io\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa17ce7-4e1c-4f52-8963-abd86084b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'pwd' is not recognized as an internal or external command,\",\n",
       " 'operable program or batch file.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# projects/def-b09sdp/bijan/Phase2/P16.fdt\n",
    "path = !pwd\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7bc34-24a6-4250-89bf-4bc9422e0af4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45befd64-9db2-4cf8-b119-eae966306003",
   "metadata": {},
   "source": [
    "Mode: 'binary', '3-class', '4-class', '5-class', '6-class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec218e4-dc89-43dd-9105-6875b25f7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrapper(data_epochs, data_labels, mode='binary'):\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        epochs = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            binary_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2)]\n",
    "            #class2_epochs = participant_epochs[participant_labels==2]\n",
    "            #bi_epochs = np.concatenate((class1_epochs, class2_epochs), axis=0)\n",
    "            epochs.append(binary_epochs)\n",
    "    \n",
    "            binary_labels = participant_labels[(participant_labels==1) | (participant_labels==2)]\n",
    "            #bi_labels = np.concatenate((class1_labels, class2_labels), axis=0)\n",
    "            labels.append(binary_labels)\n",
    "            \n",
    "    elif mode == '3_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            labels.append(multiclass_labels)\n",
    "            \n",
    "            \n",
    "    elif mode == '4_class_RS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "        \n",
    "    elif mode == '4_class_LS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    elif mode == '6_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e97a6c-2926-493a-9a07-3d750b25f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_label_extractor(data, events, epoch_length, num_channels, sampling_freq):\n",
    "    \n",
    "    data = data.to_data_frame()\n",
    "    events = events[0]\n",
    "    third_column = events[:, 2]\n",
    "    mask = np.isin(third_column, [7, 8, 9, 10])\n",
    "    MI_events = events[mask]\n",
    "    \n",
    "    number_of_epochs = MI_events.shape[0]\n",
    "    labels = np.zeros((number_of_epochs,1)).astype(int)\n",
    "    epochs = np.zeros((number_of_epochs, num_channels, epoch_length * sampling_freq))\n",
    "    index = 0\n",
    "    for index in range(number_of_epochs):\n",
    "        start = int(MI_events[index, 0])\n",
    "        end = int(MI_events[index, 0]) + epoch_length * sampling_freq\n",
    "        all_channels = data.iloc[start:end]\n",
    "        epochs[index,:,:] = all_channels[all_channels.columns[1: num_channels+1]].T\n",
    "        \n",
    "        # Because it is numbered form 7 to 10 !!!\n",
    "        labels[index] = MI_events[index, 2] - 7\n",
    "\n",
    "            \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5154e2-0354-4913-a796-40e515129978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(y_data, method=OneHotEncoder):\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(y_data[0].reshape(-1, 1))\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        \n",
    "        a = encoder.transform(y_data[i].reshape(-1, 1))\n",
    "        y_data[i] = a.toarray()\n",
    "\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda8305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_csp(x_train, y_train, x_test, number_of_components=10):\n",
    "    \n",
    "        csp = CSP(number_of_components)\n",
    "        csp_fit = csp.fit(x_train, y_train)\n",
    "        train_feat = csp_fit.transform(x_train)\n",
    "        test_feat = csp_fit.transform(x_test)\n",
    "        return train_feat, test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70687bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_4(dataset, labels, test_data, sampling_freq):\n",
    "\n",
    "    # Why number of bands were set to 24??\n",
    "    \n",
    "    low_cutoff = 0\n",
    "    number_of_bands = 8\n",
    "    for b in range(number_of_bands):\n",
    "        data = dataset.copy()\n",
    "        data_test = test_data.copy()\n",
    "        filtered_data = mne.filter.filter_data(data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        filtered_data_test = mne.filter.filter_data(data_test, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        tic = time.time()\n",
    "        train_feats, test_feats = calc_csp(filtered_data, labels[:, 0], filtered_data_test)\n",
    "        toc = time.time()\n",
    "        print(\"Time taken for csp calculations: \", toc-tic)\n",
    "        if b == 0:\n",
    "            train_features = train_feats\n",
    "            test_features = test_feats\n",
    "        else:\n",
    "            train_features = np.concatenate((train_features, train_feats), axis = 1)\n",
    "            test_features = np.concatenate((test_features, test_feats), axis = 1)\n",
    "        \n",
    "        low_cutoff += 4\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46e076",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Device (GPU\\CPU\\MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3963e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61c74e-3fdb-4e1a-b086-fc5180a12db4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2cf427-6a5c-47af-ab15-a4d4203b1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648774  =      0.000 ...  2595.096 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 600914  =      0.000 ...  2403.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660046  =      0.000 ...  2640.184 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 679862  =      0.000 ...  2719.448 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 666372  =      0.000 ...  2665.488 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673134  =      0.000 ...  2692.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 687791  =      0.000 ...  2751.164 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675097  =      0.000 ...  2700.388 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "\n",
    "try: \n",
    "    if path[0] == '/home/bijan/py3x/Code_Zhang/Transfer_Learning_On_EEG_BCI':\n",
    "        print(\"Running on cloud ...\")\n",
    "        print(\"Please make sure to modify how you read the data according to your need!\\n\\n\")\n",
    "        raw_data_path = \"/home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/gdf\"\n",
    "            \n",
    "\n",
    "except NameError:\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "    \n",
    "    \n",
    "\n",
    "train_data_epochs = []\n",
    "train_data_labels = []\n",
    "test_data_epochs = []\n",
    "test_data_labels = []\n",
    "for participant_id in range(1, 10):\n",
    "    participant_E = f\"A0{participant_id}E\"\n",
    "    participant_T = f\"A0{participant_id}T\"\n",
    "\n",
    "    file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "    file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "\n",
    "    raw_train = mne.io.read_raw_gdf(file_path_T, preload=True)\n",
    "    raw_test = mne.io.read_raw_gdf(file_path_E, preload=True)\n",
    "\n",
    "\n",
    "    train_events = mne.events_from_annotations(raw_train)\n",
    "    test_events = mne.events_from_annotations(raw_test)\n",
    "\n",
    "    train_epochs, train_labels = epoch_label_extractor(raw_train, train_events, epoch_length = 4, num_channels = 22, sampling_freq = 250)\n",
    "    #test_epochs, test_labels = epoch_label_extractor(raw_test, test_events, epoch_length = 4, num_channels = 22, sampling_freq = 250)\n",
    "\n",
    "    train_data_epochs.append(train_epochs)\n",
    "    #test_data_epochs.append(test_epochs)\n",
    "    train_data_labels.append(train_labels)\n",
    "    #test_data_labels.append(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7395c987-0862-41a1-bd42-e9ef75ac3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 train epochs:     (288, 22, 1000)     Subject 1 train labels:     (288, 1)\n",
      "Subject 2 train epochs:     (288, 22, 1000)     Subject 2 train labels:     (288, 1)\n",
      "Subject 3 train epochs:     (288, 22, 1000)     Subject 3 train labels:     (288, 1)\n",
      "Subject 4 train epochs:     (144, 22, 1000)     Subject 4 train labels:     (144, 1)\n",
      "Subject 5 train epochs:     (288, 22, 1000)     Subject 5 train labels:     (288, 1)\n",
      "Subject 6 train epochs:     (288, 22, 1000)     Subject 6 train labels:     (288, 1)\n",
      "Subject 7 train epochs:     (288, 22, 1000)     Subject 7 train labels:     (288, 1)\n",
      "Subject 8 train epochs:     (288, 22, 1000)     Subject 8 train labels:     (288, 1)\n",
      "Subject 9 train epochs:     (288, 22, 1000)     Subject 9 train labels:     (288, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(\"Subject {} train epochs:    \".format(i+1), train_data_epochs[i].shape, \"    Subject {} train labels:    \".format(i+1), train_data_labels[i].shape)\n",
    "    #print(\"Subject {} test epochs:     \".format(i+1), test_data_epochs[i].shape, \"    Subject {} test labels:     \".format(i+1), test_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4d9f7b-7976-4bcc-a7f1-35c6b4a80903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_epochs = np.zeros(len(train_data_epochs)).tolist()\n",
    "# all_data_labels = np.zeros(len(train_data_epochs)).tolist()\n",
    "\n",
    "# for i in range(len(train_data_epochs)):\n",
    "#     all_data_epochs[i] = np.concatenate((train_data_epochs[i], test_data_epochs[i]), axis=0)\n",
    "#     all_data_labels[i] = np.concatenate((train_data_labels[i], test_data_labels[i]), axis=0)\n",
    "\n",
    "\n",
    "all_data_epochs = train_data_epochs\n",
    "all_data_labels = train_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55bdff3f-46a0-4853-94f9-c887911834bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking if the concatenation does not have a problem!\n",
    "\n",
    "# print(\"Specific element in train and test sets:      \", train_data_epochs[i][10, 10, 10], test_data_epochs[i][100, 13, 14])\n",
    "# print(\"The same element in all data set combined:    \", all_data_epochs[i][10, 10, 10], all_data_epochs[i][388, 13, 14])\n",
    "# print(\"\\n\\n\")\n",
    "# print(\"Checking the labels in train and test:        \", train_data_labels[i][10], test_data_labels[i][100])\n",
    "# print(\"The same element in all data set combined:    \", all_data_labels[i][10], all_data_labels[i][388])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "149bd418-d83e-4bb4-a1d0-29abbaaea54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 0, 0, 1, 2, 3, 1, 2, 0, 0, 0, 3, 1, 1, 0, 0, 2, 0, 1, 3,\n",
       "       3, 2, 0, 3, 3, 1, 3, 3, 1, 0, 1, 2, 2, 2, 3, 2, 0, 3, 1, 2, 1, 2,\n",
       "       3, 1, 2, 0, 0, 0, 3, 1, 0, 2, 0, 2, 1, 3, 0, 2, 2, 0, 2, 1, 3, 3,\n",
       "       3, 2, 0, 3, 1, 3, 1, 0, 2, 1, 0, 2, 2, 0, 2, 3, 3, 1, 0, 1, 3, 1,\n",
       "       3, 2, 1, 1, 1, 2, 3, 0, 1, 3, 0, 2, 2, 3, 0, 0, 2, 1, 3, 3, 3, 1,\n",
       "       0, 2, 1, 3, 0, 3, 2, 1, 3, 3, 0, 1, 1, 2, 3, 1, 0, 0, 3, 1, 0, 2,\n",
       "       1, 1, 2, 0, 3, 2, 2, 2, 2, 0, 1, 0, 1, 0, 0, 2, 2, 1, 2, 3, 0, 3,\n",
       "       0, 0, 1, 3, 2, 1, 3, 2, 3, 2, 3, 1, 1, 3, 0, 1, 1, 1, 2, 3, 0, 3,\n",
       "       0, 2, 0, 3, 0, 2, 0, 1, 2, 2, 3, 0, 1, 3, 1, 2, 2, 0, 3, 1, 3, 0,\n",
       "       0, 2, 2, 1, 3, 1, 1, 0, 1, 3, 3, 1, 1, 1, 1, 3, 3, 2, 3, 0, 1, 2,\n",
       "       1, 0, 3, 0, 3, 0, 0, 0, 0, 2, 2, 3, 1, 2, 2, 2, 3, 2, 0, 2, 0, 3,\n",
       "       1, 3, 3, 2, 3, 3, 2, 1, 3, 2, 0, 1, 1, 1, 2, 1, 3, 2, 3, 1, 2, 0,\n",
       "       3, 0, 2, 3, 0, 2, 0, 1, 1, 0, 3, 0, 3, 2, 2, 0, 2, 1, 1, 0, 2, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_labels[0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b44f23-4e9a-4b10-8a58-a3a5d6ce40cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data epoch shape (sub 0):     (288, 22, 1000)     All label shape (sub 0):      (288, 1)\n",
      "All data epoch shape (sub 1):     (288, 22, 1000)     All label shape (sub 1):      (288, 1)\n",
      "All data epoch shape (sub 2):     (288, 22, 1000)     All label shape (sub 2):      (288, 1)\n",
      "All data epoch shape (sub 3):     (144, 22, 1000)     All label shape (sub 3):      (144, 1)\n",
      "All data epoch shape (sub 4):     (288, 22, 1000)     All label shape (sub 4):      (288, 1)\n",
      "All data epoch shape (sub 5):     (288, 22, 1000)     All label shape (sub 5):      (288, 1)\n",
      "All data epoch shape (sub 6):     (288, 22, 1000)     All label shape (sub 6):      (288, 1)\n",
      "All data epoch shape (sub 7):     (288, 22, 1000)     All label shape (sub 7):      (288, 1)\n",
      "All data epoch shape (sub 8):     (288, 22, 1000)     All label shape (sub 8):      (288, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data_epochs)):\n",
    "    print(\"All data epoch shape (sub {}):    \".format(i), all_data_epochs[i].shape, \"    All label shape (sub {}):     \".format(i), all_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad8cc53-ff96-4ce2-8f8e-54f46ec896bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_labels[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d77c53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "433703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_encode = copy.deepcopy(all_data_labels)\n",
    "encoded = encoder(all_data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d26a1f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Length: 9\n",
      "labels Length: 9\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - Epochs[0] shape: (144, 1)\n",
      "Participant 16 - labels[0] shape: (144, 4)\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - labels[0]:\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Epochs Length:\", len(all_data_labels))\n",
    "print(\"labels Length:\", len(encoded))\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - Epochs[0] shape:\", no_encode[3].shape)\n",
    "print(\"Participant 16 - labels[0] shape:\", encoded[3].shape)\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - labels[0]:\")\n",
    "print(all_data_labels[3][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbccfbb-49ff-461f-b50f-0f7448e933ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Within Subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d55a8f-6ef7-4d36-b1a9-cfb8c89122a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in range(num_subjects):\n",
    "    \n",
    "    epochs_subject = all_data_epochs[j]\n",
    "    labels_subject = encoded[j]\n",
    "    labels_subject_no_encode = no_encode[j]\n",
    "    \n",
    "    print(labels_subject_no_encode.shape)\n",
    "    \n",
    "    kf_outer2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    \n",
    "    tests_pred = []\n",
    "    tests_true = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf_outer2.split(epochs_subject, labels_subject_no_encode[:, 0])):\n",
    "\n",
    "\n",
    "\n",
    "        train_epochs = np.array([epochs_subject[j] for j in train_index])\n",
    "        test_epochs = np.array([epochs_subject[k] for k in test_index])\n",
    "        train_labels = np.array([labels_subject[l] for l in train_index])\n",
    "        test_labels = np.array([labels_subject[m] for m in test_index])\n",
    "        no_encoded_train_labels = np.array([labels_subject_no_encode[n] for n in train_index])\n",
    "        no_encoded_test_labels = np.array([labels_subject_no_encode[o] for o in test_index])\n",
    "        \n",
    "\n",
    "\n",
    "        print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "        print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "        print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "        print(\"      Train labels' shape:                               \", train_labels.shape)\n",
    "        print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "        print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "        print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "\n",
    "        # Create the EEGNet model\n",
    "        model = XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #     # Normalizing the features\n",
    "        #     mean = train_epochs.mean(axis=(0, 2), keepdims=True)\n",
    "        #     std = train_epochs.std(axis=(0, 2), keepdims=True)\n",
    "\n",
    "        #     print(mean.shape)\n",
    "        #     print(std.shape)\n",
    "\n",
    "        #     norm_train_epochs = (train_epochs - mean) / std\n",
    "        #     norm_test_epochs = (test_epochs - mean) / std\n",
    "        #     # Commented the normalization part since it reduces the rank of data and rasing errors with \n",
    "        #     # CSP filter bank\n",
    "\n",
    "        train_features, test_features = feature_extraction_4(train_epochs, no_encoded_train_labels, test_epochs, sampling_freq = 250)\n",
    "        print(\"Train features shape:\", train_features.shape)\n",
    "        print(\"Test features shape:\", test_features.shape)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(train_features, no_encoded_train_labels[:, 0])\n",
    "\n",
    "        # Test the model\n",
    "        y_pred = model.predict(test_features)\n",
    "        \n",
    "        tests_pred.append(y_pred)\n",
    "        tests_true.append(no_encoded_test_labels[:, 0])\n",
    "    \n",
    "    all_tests_pred.append(tests_pred)\n",
    "    all_tests_true.append(tests_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d3291b7-f6d9-45fb-a772-9660b71b43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tests_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534ec3fc-0aa8-4f87-b5ab-30fc25f1369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288,)\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate(all_tests_pred[4]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c4ea157-3a96-4d27-ba8f-9605c2c75bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 2, 1, 3, 2, 0, 1, 0, 0, 1, 0, 1, 2, 3, 3, 2, 3, 3, 1, 1, 1, 2,\n",
      "       3, 2, 0, 3, 3, 0, 1, 0, 1, 2, 1, 0, 2, 2, 2, 3, 0, 1, 3, 1, 3, 1,\n",
      "       2, 3, 0, 1, 3, 2, 1, 3, 0, 2, 2, 0, 3, 0]), array([0, 0, 1, 3, 2, 1, 2, 3, 0, 3, 0, 2, 3, 3, 2, 1, 3, 1, 3, 0, 1, 3,\n",
      "       1, 1, 2, 3, 0, 1, 3, 1, 3, 0, 2, 0, 0, 2, 0, 1, 0, 2, 1, 0, 2, 2,\n",
      "       3, 3, 2, 1, 1, 2, 0, 3, 0, 3, 2, 2, 0, 1]), array([2, 3, 0, 2, 3, 2, 2, 1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 1, 3, 0, 1, 1,\n",
      "       2, 1, 0, 0, 3, 2, 0, 2, 1, 3, 2, 1, 1, 3, 3, 2, 0, 3, 3, 2, 0, 3,\n",
      "       2, 1, 3, 1, 3, 0, 0, 1, 1, 3, 0, 1, 2, 0]), array([1, 1, 0, 1, 3, 3, 3, 2, 2, 3, 2, 2, 0, 2, 3, 0, 1, 0, 2, 0, 1, 1,\n",
      "       0, 2, 2, 0, 0, 2, 2, 1, 2, 1, 3, 0, 3, 1, 1, 2, 3, 3, 0, 3, 1, 3,\n",
      "       1, 0, 0, 1, 3, 0, 3, 3, 1, 2, 2, 2, 0]), array([3, 0, 2, 0, 1, 0, 3, 3, 1, 1, 2, 0, 3, 1, 1, 2, 2, 0, 3, 1, 3, 0,\n",
      "       2, 3, 3, 1, 3, 3, 0, 3, 2, 0, 0, 1, 2, 3, 0, 1, 2, 0, 2, 1, 3, 1,\n",
      "       0, 1, 0, 2, 2, 1, 3, 2, 1, 2, 0, 2, 1])]\n",
      "[array([1, 0, 1, 3, 2, 2, 2, 3, 3, 3, 2, 1, 0, 0, 3, 0, 0, 1, 2, 2, 2, 0,\n",
      "       1, 3, 0, 3, 1, 3, 2, 0, 2, 1, 1, 0, 2, 3, 0, 2, 1, 3, 1, 2, 1, 0,\n",
      "       2, 0, 1, 3, 1, 0, 0, 3, 2, 1, 2, 3, 3, 0]), array([1, 1, 0, 3, 3, 2, 0, 2, 3, 0, 3, 0, 1, 0, 2, 1, 0, 0, 3, 2, 2, 0,\n",
      "       2, 1, 2, 0, 3, 2, 0, 3, 2, 3, 1, 3, 0, 1, 2, 3, 3, 1, 1, 1, 3, 2,\n",
      "       0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 0, 0, 3, 2]), array([1, 0, 1, 3, 0, 1, 1, 2, 2, 3, 1, 3, 3, 1, 0, 0, 2, 1, 3, 2, 2, 3,\n",
      "       2, 1, 3, 3, 0, 3, 1, 1, 2, 0, 1, 2, 2, 3, 1, 0, 1, 0, 0, 0, 3, 1,\n",
      "       0, 3, 3, 2, 3, 0, 0, 2, 1, 2, 2, 3, 2, 0]), array([2, 2, 3, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 3, 3, 3, 2, 3, 1, 2,\n",
      "       3, 1, 1, 3, 3, 1, 1, 2, 1, 3, 0, 2, 2, 2, 0, 1, 0, 0, 2, 0, 0, 3,\n",
      "       2, 3, 3, 0, 2, 3, 1, 1, 1, 3, 0, 0, 2]), array([0, 1, 0, 3, 3, 0, 2, 1, 2, 3, 2, 3, 0, 2, 0, 1, 1, 2, 2, 3, 0, 3,\n",
      "       1, 0, 0, 2, 0, 0, 3, 3, 1, 3, 0, 2, 3, 0, 1, 1, 2, 3, 1, 2, 0, 3,\n",
      "       2, 2, 3, 1, 1, 2, 2, 1, 1, 0, 3, 1, 2])]\n",
      "[array([1, 0, 1, 3, 2, 2, 2, 3, 3, 3, 2, 1, 0, 0, 3, 0, 0, 1, 2, 2, 2, 0,\n",
      "       1, 3, 0, 3, 1, 3, 2, 0, 2, 1, 1, 0, 2, 3, 0, 2, 1, 3, 1, 2, 1, 0,\n",
      "       2, 0, 1, 3, 1, 0, 0, 3, 2, 1, 2, 3, 3, 0]), array([1, 1, 0, 3, 3, 2, 0, 2, 3, 0, 3, 0, 1, 0, 2, 1, 0, 0, 3, 2, 2, 0,\n",
      "       2, 1, 2, 0, 3, 2, 0, 3, 2, 3, 1, 3, 0, 1, 2, 3, 3, 1, 1, 1, 3, 2,\n",
      "       0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 0, 0, 3, 2]), array([1, 0, 1, 3, 0, 1, 1, 2, 2, 3, 1, 3, 3, 1, 0, 0, 2, 1, 3, 2, 2, 3,\n",
      "       2, 1, 3, 3, 0, 3, 1, 1, 2, 0, 1, 2, 2, 3, 1, 0, 1, 0, 0, 0, 3, 1,\n",
      "       0, 3, 3, 2, 3, 0, 0, 2, 1, 2, 2, 3, 2, 0]), array([2, 2, 3, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 3, 3, 3, 2, 3, 1, 2,\n",
      "       3, 1, 1, 3, 3, 1, 1, 2, 1, 3, 0, 2, 2, 2, 0, 1, 0, 0, 2, 0, 0, 3,\n",
      "       2, 3, 3, 0, 2, 3, 1, 1, 1, 3, 0, 0, 2]), array([0, 1, 0, 3, 3, 0, 2, 1, 2, 3, 2, 3, 0, 2, 0, 1, 1, 2, 2, 3, 0, 3,\n",
      "       1, 0, 0, 2, 0, 0, 3, 3, 1, 3, 0, 2, 3, 0, 1, 1, 2, 3, 1, 2, 0, 3,\n",
      "       2, 2, 3, 1, 1, 2, 2, 1, 1, 0, 3, 1, 2])]\n",
      "[array([1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 0, 1, 1]), array([1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "       1, 0, 0, 1, 1, 0, 0]), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0]), array([1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 0]), array([1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "       0, 0, 0, 1, 0, 0])]\n",
      "[array([1, 0, 1, 3, 2, 2, 2, 3, 3, 3, 2, 1, 0, 0, 3, 0, 0, 1, 2, 2, 2, 0,\n",
      "       1, 3, 0, 3, 1, 3, 2, 0, 2, 1, 1, 0, 2, 3, 0, 2, 1, 3, 1, 2, 1, 0,\n",
      "       2, 0, 1, 3, 1, 0, 0, 3, 2, 1, 2, 3, 3, 0]), array([1, 1, 0, 3, 3, 2, 0, 2, 3, 0, 3, 0, 1, 0, 2, 1, 0, 0, 3, 2, 2, 0,\n",
      "       2, 1, 2, 0, 3, 2, 0, 3, 2, 3, 1, 3, 0, 1, 2, 3, 3, 1, 1, 1, 3, 2,\n",
      "       0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 0, 0, 3, 2]), array([1, 0, 1, 3, 0, 1, 1, 2, 2, 3, 1, 3, 3, 1, 0, 0, 2, 1, 3, 2, 2, 3,\n",
      "       2, 1, 3, 3, 0, 3, 1, 1, 2, 0, 1, 2, 2, 3, 1, 0, 1, 0, 0, 0, 3, 1,\n",
      "       0, 3, 3, 2, 3, 0, 0, 2, 1, 2, 2, 3, 2, 0]), array([2, 2, 3, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 3, 3, 3, 2, 3, 1, 2,\n",
      "       3, 1, 1, 3, 3, 1, 1, 2, 1, 3, 0, 2, 2, 2, 0, 1, 0, 0, 2, 0, 0, 3,\n",
      "       2, 3, 3, 0, 2, 3, 1, 1, 1, 3, 0, 0, 2]), array([0, 1, 0, 3, 3, 0, 2, 1, 2, 3, 2, 3, 0, 2, 0, 1, 1, 2, 2, 3, 0, 3,\n",
      "       1, 0, 0, 2, 0, 0, 3, 3, 1, 3, 0, 2, 3, 0, 1, 1, 2, 3, 1, 2, 0, 3,\n",
      "       2, 2, 3, 1, 1, 2, 2, 1, 1, 0, 3, 1, 2])]\n",
      "[array([1, 3, 2, 0, 1, 0, 2, 0, 2, 2, 0, 3, 3, 1, 2, 0, 3, 3, 1, 0, 0, 1,\n",
      "       3, 1, 3, 0, 2, 2, 2, 3, 0, 1, 0, 1, 3, 0, 3, 1, 1, 3, 0, 2, 0, 3,\n",
      "       2, 1, 1, 2, 1, 1, 3, 0, 3, 0, 2, 2, 2, 3]), array([3, 1, 2, 2, 0, 1, 0, 3, 2, 3, 3, 3, 2, 1, 0, 1, 3, 3, 0, 2, 0, 1,\n",
      "       3, 0, 0, 3, 0, 3, 3, 0, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 1, 1, 0, 2,\n",
      "       0, 2, 3, 3, 1, 0, 2, 1, 1, 2, 1, 3, 3, 0]), array([1, 3, 2, 1, 3, 1, 1, 0, 0, 2, 1, 2, 2, 1, 3, 1, 3, 0, 0, 0, 1, 2,\n",
      "       2, 0, 3, 2, 2, 1, 2, 1, 0, 3, 1, 0, 0, 1, 1, 3, 3, 2, 3, 3, 2, 2,\n",
      "       1, 3, 2, 0, 0, 0, 3, 2, 3, 0, 0, 3, 1, 2]), array([0, 0, 3, 2, 0, 1, 3, 3, 1, 3, 1, 3, 1, 0, 2, 2, 0, 1, 2, 2, 1, 0,\n",
      "       1, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 0, 3, 2, 1, 0, 3, 3, 2, 0, 3, 0,\n",
      "       3, 2, 2, 0, 3, 2, 1, 2, 3, 0, 1, 3, 1]), array([3, 1, 2, 3, 2, 0, 2, 3, 0, 2, 0, 1, 0, 3, 0, 0, 3, 1, 2, 2, 1, 3,\n",
      "       1, 3, 3, 0, 2, 3, 2, 1, 3, 2, 3, 0, 3, 1, 0, 2, 1, 2, 1, 0, 0, 3,\n",
      "       0, 2, 1, 2, 1, 0, 0, 1, 2, 1, 3, 0, 1])]\n",
      "[array([1, 0, 1, 3, 2, 2, 2, 3, 3, 3, 2, 1, 0, 0, 3, 0, 0, 1, 2, 2, 2, 0,\n",
      "       1, 3, 0, 3, 1, 3, 2, 0, 2, 1, 1, 0, 2, 3, 0, 2, 1, 3, 1, 2, 1, 0,\n",
      "       2, 0, 1, 3, 1, 0, 0, 3, 2, 1, 2, 3, 3, 0]), array([1, 1, 0, 3, 3, 2, 0, 2, 3, 0, 3, 0, 1, 0, 2, 1, 0, 0, 3, 2, 2, 0,\n",
      "       2, 1, 2, 0, 3, 2, 0, 3, 2, 3, 1, 3, 0, 1, 2, 3, 3, 1, 1, 1, 3, 2,\n",
      "       0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 0, 0, 3, 2]), array([1, 0, 1, 3, 0, 1, 1, 2, 2, 3, 1, 3, 3, 1, 0, 0, 2, 1, 3, 2, 2, 3,\n",
      "       2, 1, 3, 3, 0, 3, 1, 1, 2, 0, 1, 2, 2, 3, 1, 0, 1, 0, 0, 0, 3, 1,\n",
      "       0, 3, 3, 2, 3, 0, 0, 2, 1, 2, 2, 3, 2, 0]), array([2, 2, 3, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 3, 3, 3, 2, 3, 1, 2,\n",
      "       3, 1, 1, 3, 3, 1, 1, 2, 1, 3, 0, 2, 2, 2, 0, 1, 0, 0, 2, 0, 0, 3,\n",
      "       2, 3, 3, 0, 2, 3, 1, 1, 1, 3, 0, 0, 2]), array([0, 1, 0, 3, 3, 0, 2, 1, 2, 3, 2, 3, 0, 2, 0, 1, 1, 2, 2, 3, 0, 3,\n",
      "       1, 0, 0, 2, 0, 0, 3, 3, 1, 3, 0, 2, 3, 0, 1, 1, 2, 3, 1, 2, 0, 3,\n",
      "       2, 2, 3, 1, 1, 2, 2, 1, 1, 0, 3, 1, 2])]\n",
      "[array([1, 0, 1, 3, 2, 2, 2, 3, 3, 3, 2, 1, 0, 0, 3, 0, 0, 1, 2, 2, 2, 0,\n",
      "       1, 3, 0, 3, 1, 3, 2, 0, 2, 1, 1, 0, 2, 3, 0, 2, 1, 3, 1, 2, 1, 0,\n",
      "       2, 0, 1, 3, 1, 0, 0, 3, 2, 1, 2, 3, 3, 0]), array([1, 1, 0, 3, 3, 2, 0, 2, 3, 0, 3, 0, 1, 0, 2, 1, 0, 0, 3, 2, 2, 0,\n",
      "       2, 1, 2, 0, 3, 2, 0, 3, 2, 3, 1, 3, 0, 1, 2, 3, 3, 1, 1, 1, 3, 2,\n",
      "       0, 0, 2, 3, 1, 1, 1, 3, 2, 1, 0, 0, 3, 2]), array([1, 0, 1, 3, 0, 1, 1, 2, 2, 3, 1, 3, 3, 1, 0, 0, 2, 1, 3, 2, 2, 3,\n",
      "       2, 1, 3, 3, 0, 3, 1, 1, 2, 0, 1, 2, 2, 3, 1, 0, 1, 0, 0, 0, 3, 1,\n",
      "       0, 3, 3, 2, 3, 0, 0, 2, 1, 2, 2, 3, 2, 0]), array([2, 2, 3, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 3, 3, 3, 2, 3, 1, 2,\n",
      "       3, 1, 1, 3, 3, 1, 1, 2, 1, 3, 0, 2, 2, 2, 0, 1, 0, 0, 2, 0, 0, 3,\n",
      "       2, 3, 3, 0, 2, 3, 1, 1, 1, 3, 0, 0, 2]), array([0, 1, 0, 3, 3, 0, 2, 1, 2, 3, 2, 3, 0, 2, 0, 1, 1, 2, 2, 3, 0, 3,\n",
      "       1, 0, 0, 2, 0, 0, 3, 3, 1, 3, 0, 2, 3, 0, 1, 1, 2, 3, 1, 2, 0, 3,\n",
      "       2, 2, 3, 1, 1, 2, 2, 1, 1, 0, 3, 1, 2])]\n",
      "[array([1, 3, 2, 0, 1, 0, 2, 0, 2, 2, 0, 3, 3, 1, 2, 0, 3, 3, 1, 0, 0, 1,\n",
      "       3, 1, 3, 0, 2, 2, 2, 3, 0, 1, 0, 1, 3, 0, 3, 1, 1, 3, 0, 2, 0, 3,\n",
      "       2, 1, 1, 2, 1, 1, 3, 0, 3, 0, 2, 2, 2, 3]), array([3, 1, 2, 2, 0, 1, 0, 3, 2, 3, 3, 3, 2, 1, 0, 1, 3, 3, 0, 2, 0, 1,\n",
      "       3, 0, 0, 3, 0, 3, 3, 0, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 1, 1, 0, 2,\n",
      "       0, 2, 3, 3, 1, 0, 2, 1, 1, 2, 1, 3, 3, 0]), array([1, 3, 2, 1, 3, 1, 1, 0, 0, 2, 1, 2, 2, 1, 3, 1, 3, 0, 0, 0, 1, 2,\n",
      "       2, 0, 3, 2, 2, 1, 2, 1, 0, 3, 1, 0, 0, 1, 1, 3, 3, 2, 3, 3, 2, 2,\n",
      "       1, 3, 2, 0, 0, 0, 3, 2, 3, 0, 0, 3, 1, 2]), array([0, 0, 3, 2, 0, 1, 3, 3, 1, 3, 1, 3, 1, 0, 2, 2, 0, 1, 2, 2, 1, 0,\n",
      "       1, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 0, 3, 2, 1, 0, 3, 3, 2, 0, 3, 0,\n",
      "       3, 2, 2, 0, 3, 2, 1, 2, 3, 0, 1, 3, 1]), array([3, 1, 2, 3, 2, 0, 2, 3, 0, 2, 0, 1, 0, 3, 0, 0, 3, 1, 2, 2, 1, 3,\n",
      "       1, 3, 3, 0, 2, 3, 2, 1, 3, 2, 3, 0, 3, 1, 0, 2, 1, 2, 1, 0, 0, 3,\n",
      "       0, 2, 1, 2, 1, 0, 0, 1, 2, 1, 3, 0, 1])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_tests_true)):\n",
    "   print(all_tests_true[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ab53e9-c603-4f26-8365-d6ed4464cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    if i == 3:\n",
    "        continue\n",
    "    y_true = np.concatenate(all_tests_true[i])\n",
    "    y_pred = np.concatenate(all_tests_pred[i])\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "702c0285-fdf5-4b52-adfc-f4d4ae6986f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35 24  4  9]\n",
      " [21 34  6 11]\n",
      " [ 1  2 67  2]\n",
      " [16  4  6 46]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ebdd581-553d-4aed-8587-6f272aae0b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['Left (True)', 'Right (True)', 'Feet (True)', 'Tongue (True)'], columns=['Left (Pred)', 'Right (Pred)', 'Feet (Pred)', 'Tongue (Pred)'])\n",
    "acc = np.sum(summation / 576 * np.eye(4, 4)).sum() / 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c4c5f0d-9b8b-4556-8846-94475c43677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The within subject scenario:\n",
      "Algorithm: XGBClassifier\n",
      "Accuracy:  0.74609375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left (Pred)</th>\n",
       "      <th>Right (Pred)</th>\n",
       "      <th>Feet (Pred)</th>\n",
       "      <th>Tongue (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Left (True)</th>\n",
       "      <td>0.737847</td>\n",
       "      <td>0.112847</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Right (True)</th>\n",
       "      <td>0.112847</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.071181</td>\n",
       "      <td>0.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feet (True)</th>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.067708</td>\n",
       "      <td>0.732639</td>\n",
       "      <td>0.135417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tongue (True)</th>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.774306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Left (Pred)  Right (Pred)  Feet (Pred)  Tongue (Pred)\n",
       "Left (True)       0.737847      0.112847     0.055556       0.093750\n",
       "Right (True)      0.112847      0.739583     0.071181       0.076389\n",
       "Feet (True)       0.064236      0.067708     0.732639       0.135417\n",
       "Tongue (True)     0.076389      0.048611     0.100694       0.774306"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The within subject scenario:\")\n",
    "print(\"Algorithm: XGBClassifier\")\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "summation / 576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b3bd396-0100-47f1-87bf-51160149d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Left (True)      576\n",
       "Right (True)     576\n",
       "Feet (True)      576\n",
       "Tongue (True)    576\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37da8839-f7ca-4302-b2cd-d39aecd2b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74609375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(summation / 576 * np.eye(4, 4)).sum() / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d5222-55aa-4e69-aa7c-59f9a001736d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross-subjects (WO hyperparameter tuning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9f678b-ce96-4788-a2d8-f90f4334dc63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 0th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 1th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 2th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 3th run out of 9 is done!\n",
      "Train features shape: (2304, 80)\n",
      "Test features shape: (144, 80)\n",
      "The 4th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 5th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 6th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 7th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 8th run out of 9 is done!\n"
     ]
    }
   ],
   "source": [
    "participants = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf_outer2.split(all_data_epochs)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_epochs = np.concatenate([all_data_epochs[j] for j in train_index])\n",
    "    test_epochs = np.concatenate([all_data_epochs[k] for k in test_index])\n",
    "    train_labels = np.concatenate([encoded[l] for l in train_index])\n",
    "    test_labels = np.concatenate([encoded[m] for m in test_index])\n",
    "    no_encoded_train_labels = np.concatenate([no_encode[n] for n in train_index])\n",
    "    no_encoded_test_labels = np.concatenate([no_encode[o] for o in test_index])\n",
    "    train_ids_for_save = [participants[i] for i in train_index]\n",
    "    test_ids_for_save = [participants[i] for i in test_index]\n",
    "    \n",
    "    \n",
    "#     print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "#     print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "\n",
    "#     print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "#     print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "#     print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "#     print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "#     print(\"      Train index:                                       \", train_ids_for_save)\n",
    "\n",
    "#     print(\"      Test index:                                        \", test_ids_for_save)\n",
    "#     print('\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Create the EEGNet model\n",
    "    model = XGBClassifier()\n",
    "    \n",
    "    \n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('temp_stdout{}.txt'.format(i+10000), 'w')  # Redirect output to a temporary file\n",
    "    train_features, test_features = feature_extraction_4(train_epochs, no_encoded_train_labels, test_epochs, sampling_freq = 250)\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = original_stdout\n",
    "    \n",
    "    \n",
    "    print(\"Train features shape:\", train_features.shape)\n",
    "    print(\"Test features shape:\", test_features.shape)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_features, no_encoded_train_labels)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model.predict(test_features)\n",
    "    \n",
    "    \n",
    "    all_tests_pred.append(y_pred)\n",
    "    all_tests_true.append(no_encoded_test_labels)\n",
    "    with open(\"all_tests_pred_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(all_tests_pred, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        \n",
    "    with open(\"all_tests_true_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(all_tests_true, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        \n",
    "    with open(\"indexes.pickle\", \"wb\") as f:\n",
    "        pickle.dump(test_index, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    \n",
    "    with open(\"train_features_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(train_features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        \n",
    "    with open(\"test_features_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(test_features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    print(\"The {}th run out of 9 is done!\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28c468c-db9a-4d3f-8138-d4af320bfe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tests_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca1ee2d3-427e-40f7-9212-3eb01de03382",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    if i == 3:\n",
    "        continue\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fd5796f-1cf4-4f51-9ab3-f2735b410bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['Left (True)', 'Right (True)', 'Feet (True)', 'Tongue (True)'], columns=['Left (Pred)', 'Right (Pred)', 'Feet (Pred)', 'Tongue (Pred)'])\n",
    "acc = np.sum(summation / 576 * np.eye(4, 4)).sum() / 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0234527d-ee6f-4084-bd58-09bbffc2e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Left (True)      576\n",
       "Right (True)     576\n",
       "Feet (True)      504\n",
       "Tongue (True)    504\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c990859c-22c2-476d-90c6-2ad17c00b752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Hello, worimport sys\")\n",
    "sys.stdout\n",
    "sys.stdout = sys.__stdout__\n",
    "sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a26125-1e6f-4ab0-b029-cc6075356f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3120659722222222"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e38d298-983b-4399-b59d-fbfb65986317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-subject scenario:\n",
      "Algorithm: XGBClassifier\n",
      "Accuracy:  0.3125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left (Pred)</th>\n",
       "      <th>Right (Pred)</th>\n",
       "      <th>Feet (Pred)</th>\n",
       "      <th>Tongue (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Left (True)</th>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.164931</td>\n",
       "      <td>0.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Right (True)</th>\n",
       "      <td>0.184028</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feet (True)</th>\n",
       "      <td>0.190972</td>\n",
       "      <td>0.288194</td>\n",
       "      <td>0.147569</td>\n",
       "      <td>0.248264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tongue (True)</th>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.267361</td>\n",
       "      <td>0.105903</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Left (Pred)  Right (Pred)  Feet (Pred)  Tongue (Pred)\n",
       "Left (True)       0.319444      0.296875     0.164931       0.218750\n",
       "Right (True)      0.184028      0.505208     0.102431       0.208333\n",
       "Feet (True)       0.190972      0.288194     0.147569       0.248264\n",
       "Tongue (True)     0.223958      0.267361     0.105903       0.277778"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The cross-subject scenario:\")\n",
    "print(\"Algorithm: XGBClassifier\")\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "summation / 576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17634ff8-1043-48bb-9d81-d8e4c3b96ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>36.410256</td>\n",
       "      <td>9.487179</td>\n",
       "      <td>12.307692</td>\n",
       "      <td>22.692308</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>10.512821</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>32.948718</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>25.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>10.256410</td>\n",
       "      <td>8.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>11.153846</td>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>12.564103</td>\n",
       "      <td>25.512821</td>\n",
       "      <td>6.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>12.179487</td>\n",
       "      <td>10.641026</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>26.282051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              L (Pred)  LS (Pred)   S (Pred)  RS (True)   R (True)  \\\n",
       "L (True)     36.410256   9.487179  12.307692  22.692308   8.846154   \n",
       "LS (True)     9.615385  36.538462  10.128205   9.615385  27.435897   \n",
       "S (True)     10.512821  11.538462  32.948718   8.846154  10.769231   \n",
       "RS (True)    33.461538  10.384615   9.615385  27.435897  10.256410   \n",
       "R (True)     11.153846  33.461538  10.384615  12.564103  25.512821   \n",
       "Rest (True)  12.179487  10.641026  30.000000  10.128205  10.769231   \n",
       "\n",
       "             Rest (Pred)  \n",
       "L (True)       10.256410  \n",
       "LS (True)       6.666667  \n",
       "S (True)       25.384615  \n",
       "RS (True)       8.846154  \n",
       "R (True)        6.923077  \n",
       "Rest (True)    26.282051  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 780 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0da3ca-2632-4cde-9ff0-fbced848e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"3class_all_tests_pred\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"3class_all_tests_true\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)\n",
    "\n",
    "    \n",
    "print(all_tests_pred[1][1].shape)\n",
    "print(all_tests_pred[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6368512-0663-4c9f-a354-f5049fecec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3class_all_tests_pred\", \"rb\") as fp:\n",
    "    rand_var = pickle.load(fp)\n",
    "\n",
    "    \n",
    "with open(\"3class_all_tests_true\", \"rb\") as fp:\n",
    "    rand_var2 = pickle.load(fp)\n",
    "print(rand_var[12][1].shape)\n",
    "print(rand_var2[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08905-a166-4f57-80c1-b2cc22f13c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests_pred[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43d0b8-df4f-4cea-862b-22c54ed434f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(all_tests_true[12][1], axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5f8a9-1df5-413e-97d7-2af43d8684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 50, 6]])\n",
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ee94d-1d88-44be-a4b7-e6b61d848aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e45e8-f7bc-4075-bb3c-2f475450f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "y_pred_prob = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_pred = np.zeros(all_tests_true[i][0].shape)\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_pred += all_tests_pred[i][j]\n",
    "    y_pred_prob.append(y_pred/6)\n",
    "    confusion_matrices_ap.append(confusion_matrix(np.argmax(all_tests_true[i][0], axis=1)+1, np.argmax(y_pred_prob[i], axis=1)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b12477-bb1b-496a-b16f-a3e2736bf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659f9e1-6fcb-4fa8-8e1d-b2b29483a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = summation.values.sum()\n",
    "correct_predictions = summation.values.trace()\n",
    "overall_accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = summation.values.diagonal() / summation.sum(axis=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Accuracy for Class {i + 1}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098dbcb-6f3d-424f-a64e-bcb8de189e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7df6f-7e9d-47d8-b08d-2790c224d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation / (13 * 40) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa6dc-4794-4e57-b493-80ce26effec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([1, 1, 2, 2, 3, 3, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba87097-1690-404c-b051-55f9c13c3473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test for the effect of calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab11fff1-54d3-4dcc-8ac1-bb29e3b1e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "Calibrated_model = []\n",
    "for file in os.listdir(\"/home/bijan/py3x\"):\n",
    "    if file.endswith(\".h5\") and file.startswith(\"Calibrated\"):\n",
    "        Calibrated_model.append(file)\n",
    "    elif file.endswith(\".h5\") and file.startswith(\"Model\"):\n",
    "        models.append(file)\n",
    "        \n",
    "Calibrated_model = sorted(Calibrated_model)\n",
    "models = sorted(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6d2b9-976c-48c7-8f69-ca5033ad00dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50466690-38ae-4f90-9012-1457989185c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "Calibrated_models = {}\n",
    "for i in range(14):\n",
    "    if i == 8:\n",
    "        continue\n",
    "        \n",
    "    for j in range(6):\n",
    "        #print(\"Model{}{}.h5\".format(i+1, j+1))\n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb10d86e-1611-4280-8da5-a61bcf95bb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0203'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:02}{:02}\".format(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa5a0ea-0c50-4ec8-873a-327b68baee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b34579d-f2e3-4917-9757-ef6058078bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Calibrated_models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33991647-0cda-498a-9e52-6950779cc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "      Cross-validation index:                            [0, 9, 12]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [5, 8]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1537, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (220, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13]\n",
      "      Cross-validation index:                            [7, 10]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1537, 576)\n",
      "Cross-validation features shape:  (220, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee414b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 1 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [3, 6]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee415fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 2 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1338, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 5, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1338, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1479, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1479, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [5, 13]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [8, 11]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1539, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (219, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [3, 7]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1539, 576)\n",
      "Cross-validation features shape:  (219, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 3 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_subjects = len(EEG_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "models = {}\n",
    "Calibrated_models = {}\n",
    "\n",
    "kf_outer1 = KFold(n_splits=6, shuffle=True, random_state=42)              # Split the data into Train and Cross-Validation sets\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "for i, (train_crossval_index, test_index) in enumerate(kf_outer2.split(EEG_epochs)):\n",
    "    \n",
    "    if test_index == 7:\n",
    "        continue\n",
    "    \n",
    "    train_crossval = [EEG_epochs[i] for i in train_crossval_index]\n",
    "    test_epochs = np.concatenate([EEG_epochs[i] for i in test_index])\n",
    "    train_crossval_labels = [encoded[i] for i in train_crossval_index]\n",
    "    test_labels = np.concatenate([encoded[i] for i in test_index])\n",
    "    no_encoded_train_crossval = [no_encode[i] for i in train_crossval_index]\n",
    "    no_encoded_test = np.concatenate([no_encode[i] for i in test_index])\n",
    "\n",
    "    temp_pred = []\n",
    "    temp_true = []\n",
    "\n",
    "    for j, (train_index, val_index) in enumerate(kf_outer1.split(train_crossval)):\n",
    "        \n",
    "        \n",
    "        train_epochs = np.concatenate([train_crossval[i] for i in train_index])\n",
    "        crossval_epochs = np.concatenate([train_crossval[i] for i in val_index])\n",
    "        train_labels = np.concatenate([train_crossval_labels[i] for i in train_index])\n",
    "        crossval_labels = np.concatenate([train_crossval_labels[i] for i in val_index])\n",
    "        no_encoded_train = np.concatenate([no_encoded_train_crossval[i] for i in train_index])\n",
    "        no_encoded_crossval = np.concatenate([no_encoded_train_crossval[i] for i in val_index])\n",
    "        train_ids_for_save = [train_crossval_index[i] for i in train_index]\n",
    "        cross_val_ids_for_save = [train_crossval_index[i] for i in val_index]\n",
    "        \n",
    "        \n",
    "        print(\"Outer Loop {} and Inner Loop {}:\".format(i+1, j+1), \"\\n\")\n",
    "        print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "        #print(\"     Train labels' shape:                               \", train_labels.shape)\n",
    "        print(\"      Cross-validation epochs' shape:                    \", crossval_epochs.shape)\n",
    "        #print(\"     Cross-validation labels' shape:                    \", crossval_labels.shape)\n",
    "        print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "        #print(\"     Test labels' shape:                                \", test_labels.shape)\n",
    "        #print(\"     Train labels' shape (without encoding):            \", no_encoded_train.shape)\n",
    "        #print(\"     Cross-validation labels' shape (without encoding): \", no_encoded_crossval.shape)\n",
    "        #print(\"     Test labels' shape (without encoding):             \", no_encoded_test.shape)\n",
    "        print(\"      Train index:                                      \", train_ids_for_save)\n",
    "        print(\"      Cross-validation index:                           \", cross_val_ids_for_save)\n",
    "        print(\"      Test index:                                       \", test_index)\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = open('temp_stdout{}.txt'.format(i), 'w')  # Redirect output to a temporary file\n",
    "        train_features, CrossVal_features, test_features = feature_extraction_cv(train_epochs, no_encoded_train, crossval_epochs, test_epochs, number_of_bands=9, sampling_freq=250, low_cutoff=0, number_of_components=64)\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout\n",
    "    \n",
    "        print(\"Train features shape:            \", train_features.shape)\n",
    "        print(\"Cross-validation features shape: \", CrossVal_features.shape)\n",
    "        print(\"Test features shape:             \", test_features.shape)\n",
    "    \n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)\n",
    "        \n",
    "        temp_pred.append(models[\"{:02}{:02}\".format(i+1, j+1)].predict(test_features[60:]))\n",
    "        temp_true.append(test_labels[60:])\n",
    "        \n",
    "    all_tests_pred.append(temp_pred)\n",
    "    all_tests_true.append(temp_true)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003b1db8-fd82-4248-af7d-378f87f1f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"all_tests_pred_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"all_tests_true_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d30ebb-08d2-48c0-8cfd-dc3915c5da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_true = 2 - np.argmax(all_tests_true[i][j], axis=1)\n",
    "        y_pred = 2 - np.argmax(all_tests_pred[i][j], axis=1)\n",
    "    confusion_matrices_ap.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66dd2c7b-5dbb-4b67-b72a-15e759258c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>358</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)             358             162\n",
       "class 2 (True)             202             315"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792408a4-5e58-4ca5-a1c5-6e73b9dcd381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.311538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.605769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)        0.688462        0.311538\n",
       "class 2 (True)        0.388462        0.605769"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69570fb4-4782-4b2d-a397-a3f1ebac8bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for binary classification (Left vs Right hand):\n",
      "\n",
      "\n",
      "       Accuracy:                  0.65\n",
      "\n",
      "       Precision:                 0.66\n",
      "\n",
      "       Recall (Sensitivity):      0.61     \n",
      "\n",
      "       F1 Score:                  0.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    " \n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79248da6-dded-44ba-987d-1dc4eb71db65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
