{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42992946",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af32dba6-d557-4f5c-b2a9-6524cdd3636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from mne.decoding import CSP\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import copy\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import torch\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa17ce7-4e1c-4f52-8963-abd86084b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bijan/py3x/Code_Zhang/Transfer_Learning_On_EEG_BCI']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# projects/def-b09sdp/bijan/Phase2/P16.fdt\n",
    "path = !pwd\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7bc34-24a6-4250-89bf-4bc9422e0af4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45befd64-9db2-4cf8-b119-eae966306003",
   "metadata": {},
   "source": [
    "Mode: 'binary', '3-class', '4-class', '5-class', '6-class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec218e4-dc89-43dd-9105-6875b25f7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrapper(data_epochs, data_labels, mode='binary'):\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        epochs = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            binary_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2)]\n",
    "            #class2_epochs = participant_epochs[participant_labels==2]\n",
    "            #bi_epochs = np.concatenate((class1_epochs, class2_epochs), axis=0)\n",
    "            epochs.append(binary_epochs)\n",
    "    \n",
    "            binary_labels = participant_labels[(participant_labels==1) | (participant_labels==2)]\n",
    "            #bi_labels = np.concatenate((class1_labels, class2_labels), axis=0)\n",
    "            labels.append(binary_labels)\n",
    "            \n",
    "    elif mode == '3_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            labels.append(multiclass_labels)\n",
    "            \n",
    "            \n",
    "    elif mode == '4_class_RS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "        \n",
    "    elif mode == '4_class_LS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    elif mode == '6_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e97a6c-2926-493a-9a07-3d750b25f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_label_extractor(data, events, epoch_length, num_channels, sampling_freq):\n",
    "    \n",
    "    data = data.to_data_frame()\n",
    "    events = events[0]\n",
    "    third_column = events[:, 2]\n",
    "    mask = np.isin(third_column, [7, 8, 9, 10])\n",
    "    MI_events = events[mask]\n",
    "    \n",
    "    number_of_epochs = MI_events.shape[0]\n",
    "    labels = np.zeros((number_of_epochs,1)).astype(int)\n",
    "    epochs = np.zeros((number_of_epochs, num_channels, epoch_length * sampling_freq))\n",
    "    index = 0\n",
    "    for index in range(number_of_epochs):\n",
    "        start = int(MI_events[index, 0])\n",
    "        end = int(MI_events[index, 0]) + epoch_length * sampling_freq\n",
    "        all_channels = data.iloc[start:end]\n",
    "        epochs[index,:,:] = all_channels[all_channels.columns[1: num_channels+1]].T\n",
    "        \n",
    "        # Because it is numbered form 7 to 10 !!!\n",
    "        labels[index] = MI_events[index, 2] - 7\n",
    "\n",
    "            \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5154e2-0354-4913-a796-40e515129978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(y_data, method=OneHotEncoder):\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(y_data[0].reshape(-1, 1))\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        \n",
    "        a = encoder.transform(y_data[i].reshape(-1, 1))\n",
    "        y_data[i] = a.toarray()\n",
    "\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda8305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_csp(x_train, y_train, x_test, number_of_components=10):\n",
    "    \n",
    "        csp = CSP(number_of_components)\n",
    "        csp_fit = csp.fit(x_train, y_train)\n",
    "        train_feat = csp_fit.transform(x_train)\n",
    "        test_feat = csp_fit.transform(x_test)\n",
    "        return train_feat, test_feat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70687bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_4(dataset, labels, test_data, sampling_freq):\n",
    "\n",
    "    # Why number of bands were set to 24??\n",
    "    \n",
    "    low_cutoff = 0\n",
    "    number_of_bands = 8\n",
    "    for b in range(number_of_bands):\n",
    "        data = dataset.copy()\n",
    "        data_test = test_data.copy()\n",
    "        filtered_data = mne.filter.filter_data(data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        filtered_data_test = mne.filter.filter_data(data_test, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        [train_feats, test_feats] = calc_csp(filtered_data, labels[:, 0], filtered_data_test)\n",
    "        if b == 0:\n",
    "            train_features = train_feats\n",
    "            test_features = test_feats\n",
    "        else:\n",
    "            train_features = np.concatenate((train_features, train_feats), axis = 1)\n",
    "            test_features = np.concatenate((test_features, test_feats), axis = 1)\n",
    "        \n",
    "        low_cutoff += 4\n",
    "\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46e076",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Device (GPU\\CPU\\MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3963e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61c74e-3fdb-4e1a-b086-fc5180a12db4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2cf427-6a5c-47af-ab15-a4d4203b1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cloud ...\n",
      "Please make sure to modify how you read the data according to your need!\n",
      "\n",
      "\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648774  =      0.000 ...  2595.096 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 600914  =      0.000 ...  2403.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660046  =      0.000 ...  2640.184 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A05E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 679862  =      0.000 ...  2719.448 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A06E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 666372  =      0.000 ...  2665.488 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673134  =      0.000 ...  2692.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A08E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 687791  =      0.000 ...  2751.164 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/A09E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675097  =      0.000 ...  2700.388 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    if path[0] == '/home/bijan/py3x/Code_Zhang/Transfer_Learning_On_EEG_BCI':\n",
    "        print(\"Running on cloud ...\")\n",
    "        print(\"Please make sure to modify how you read the data according to your need!\\n\\n\")\n",
    "        raw_data_path = \"/home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/\"\n",
    "            \n",
    "\n",
    "except NameError:\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "    \n",
    "    \n",
    "\n",
    "train_data_epochs = []\n",
    "train_data_labels = []\n",
    "test_data_epochs = []\n",
    "test_data_labels = []\n",
    "for participant_id in range(1, 10):\n",
    "    participant_E = f\"A0{participant_id}E\"\n",
    "    participant_T = f\"A0{participant_id}T\"\n",
    "\n",
    "    file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "    file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "\n",
    "    raw_train = mne.io.read_raw_gdf(file_path_T, preload=True)\n",
    "    raw_test = mne.io.read_raw_gdf(file_path_E, preload=True)\n",
    "\n",
    "\n",
    "    train_events = mne.events_from_annotations(raw_train)\n",
    "    test_events = mne.events_from_annotations(raw_test)\n",
    "\n",
    "\n",
    "    train_epochs, train_labels = epoch_label_extractor(raw_train, train_events, epoch_length = 4, num_channels = 22, sampling_freq = 250)\n",
    "    test_epochs, test_labels = epoch_label_extractor(raw_test, test_events, epoch_length = 4, num_channels = 22, sampling_freq = 250)\n",
    "\n",
    "    train_data_epochs.append(train_epochs)\n",
    "    test_data_epochs.append(test_epochs)\n",
    "    train_data_labels.append(train_labels)\n",
    "    test_data_labels.append(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7395c987-0862-41a1-bd42-e9ef75ac3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 train epochs:     (288, 22, 1000)     Subject 1 train labels:     (288, 1)\n",
      "Subject 1 test epochs:      (288, 22, 1000)     Subject 1 test labels:      (288, 1)\n",
      "Subject 2 train epochs:     (288, 22, 1000)     Subject 2 train labels:     (288, 1)\n",
      "Subject 2 test epochs:      (288, 22, 1000)     Subject 2 test labels:      (288, 1)\n",
      "Subject 3 train epochs:     (288, 22, 1000)     Subject 3 train labels:     (288, 1)\n",
      "Subject 3 test epochs:      (288, 22, 1000)     Subject 3 test labels:      (288, 1)\n",
      "Subject 4 train epochs:     (144, 22, 1000)     Subject 4 train labels:     (144, 1)\n",
      "Subject 4 test epochs:      (288, 22, 1000)     Subject 4 test labels:      (288, 1)\n",
      "Subject 5 train epochs:     (288, 22, 1000)     Subject 5 train labels:     (288, 1)\n",
      "Subject 5 test epochs:      (288, 22, 1000)     Subject 5 test labels:      (288, 1)\n",
      "Subject 6 train epochs:     (288, 22, 1000)     Subject 6 train labels:     (288, 1)\n",
      "Subject 6 test epochs:      (288, 22, 1000)     Subject 6 test labels:      (288, 1)\n",
      "Subject 7 train epochs:     (288, 22, 1000)     Subject 7 train labels:     (288, 1)\n",
      "Subject 7 test epochs:      (288, 22, 1000)     Subject 7 test labels:      (288, 1)\n",
      "Subject 8 train epochs:     (288, 22, 1000)     Subject 8 train labels:     (288, 1)\n",
      "Subject 8 test epochs:      (288, 22, 1000)     Subject 8 test labels:      (288, 1)\n",
      "Subject 9 train epochs:     (288, 22, 1000)     Subject 9 train labels:     (288, 1)\n",
      "Subject 9 test epochs:      (288, 22, 1000)     Subject 9 test labels:      (288, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(\"Subject {} train epochs:    \".format(i+1), train_data_epochs[i].shape, \"    Subject {} train labels:    \".format(i+1), train_data_labels[i].shape)\n",
    "    print(\"Subject {} test epochs:     \".format(i+1), test_data_epochs[i].shape, \"    Subject {} test labels:     \".format(i+1), test_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4d9f7b-7976-4bcc-a7f1-35c6b4a80903",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_epochs = np.zeros(len(train_data_epochs)).tolist()\n",
    "all_data_labels = np.zeros(len(train_data_epochs)).tolist()\n",
    "\n",
    "for i in range(len(train_data_epochs)):\n",
    "    all_data_epochs[i] = np.concatenate((train_data_epochs[i], test_data_epochs[i]), axis=0)\n",
    "    all_data_labels[i] = np.concatenate((train_data_labels[i], test_data_labels[i]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55bdff3f-46a0-4853-94f9-c887911834bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific element in train and test sets:       -2.0019531249999996 -3.1249999999999996\n",
      "The same element in all data set combined:     -2.0019531249999996 -3.1249999999999996\n",
      "\n",
      "\n",
      "\n",
      "Checking the labels in train and test:         [0] [0]\n",
      "The same element in all data set combined:     [0] [0]\n"
     ]
    }
   ],
   "source": [
    "# Checking if the concatenation does not have a problem!\n",
    "\n",
    "print(\"Specific element in train and test sets:      \", train_data_epochs[i][10, 10, 10], test_data_epochs[i][100, 13, 14])\n",
    "print(\"The same element in all data set combined:    \", all_data_epochs[i][10, 10, 10], all_data_epochs[i][388, 13, 14])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Checking the labels in train and test:        \", train_data_labels[i][10], test_data_labels[i][100])\n",
    "print(\"The same element in all data set combined:    \", all_data_labels[i][10], all_data_labels[i][388])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b44f23-4e9a-4b10-8a58-a3a5d6ce40cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data epoch shape (sub 0):     (576, 22, 1000)     All label shape (sub 0):      (576, 1)\n",
      "All data epoch shape (sub 1):     (576, 22, 1000)     All label shape (sub 1):      (576, 1)\n",
      "All data epoch shape (sub 2):     (576, 22, 1000)     All label shape (sub 2):      (576, 1)\n",
      "All data epoch shape (sub 3):     (432, 22, 1000)     All label shape (sub 3):      (432, 1)\n",
      "All data epoch shape (sub 4):     (576, 22, 1000)     All label shape (sub 4):      (576, 1)\n",
      "All data epoch shape (sub 5):     (576, 22, 1000)     All label shape (sub 5):      (576, 1)\n",
      "All data epoch shape (sub 6):     (576, 22, 1000)     All label shape (sub 6):      (576, 1)\n",
      "All data epoch shape (sub 7):     (576, 22, 1000)     All label shape (sub 7):      (576, 1)\n",
      "All data epoch shape (sub 8):     (576, 22, 1000)     All label shape (sub 8):      (576, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data_epochs)):\n",
    "    print(\"All data epoch shape (sub {}):    \".format(i), all_data_epochs[i].shape, \"    All label shape (sub {}):     \".format(i), all_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ad8cc53-ff96-4ce2-8f8e-54f46ec896bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_labels[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed5015-5b92-4b3e-b578-94eae1aa3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(epochs_ex, labels_ex)\n",
    "\n",
    "print(y_tr[:, 0].shape)\n",
    "\n",
    "train_features, test_features = feature_extraction_4(x_tr, y_tr, x_te, sampling_freq=250)\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Test features shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e6181f8c-de96-4037-a234-68f4d61641cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216,)\n",
      "(216, 80)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.73        17\n",
      "           1       0.85      0.89      0.87        19\n",
      "           2       0.86      0.67      0.75        18\n",
      "           3       0.64      0.89      0.74        18\n",
      "\n",
      "    accuracy                           0.78        72\n",
      "   macro avg       0.80      0.77      0.77        72\n",
      "weighted avg       0.80      0.78      0.78        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(y_tr[:, 0].shape)\n",
    "print(train_features.shape)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(train_features, y_tr[:, 0])\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "print(classification_report(y_te[:, 0], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d77c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "433703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_encode = copy.deepcopy(all_data_labels)\n",
    "encoded = encoder(all_data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26a1f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Length: 9\n",
      "labels Length: 9\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - Epochs[0] shape: (432, 1)\n",
      "Participant 16 - labels[0] shape: (432, 4)\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - labels[0]:\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Epochs Length:\", len(all_data_labels))\n",
    "print(\"labels Length:\", len(encoded))\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - Epochs[0] shape:\", no_encode[3].shape)\n",
    "print(\"Participant 16 - labels[0] shape:\", encoded[3].shape)\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - labels[0]:\")\n",
    "print(all_data_labels[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc6835",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Checking the criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d683208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24debe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dbccfbb-49ff-461f-b50f-0f7448e933ab",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Within Subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94d55a8f-6ef7-4d36-b1a9-cfb8c89122a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/500] - Avg Training Loss: 1.7928 Train Accuracy: 0.16 - Test Loss: 1.80 - Test Accuracy: 0.28\n",
      "Epoch [  6/500] - Avg Training Loss: 1.7879 Train Accuracy: 0.17 - Test Loss: 1.84 - Test Accuracy: 0.00\n",
      "Epoch [ 11/500] - Avg Training Loss: 1.7936 Train Accuracy: 0.18 - Test Loss: 1.85 - Test Accuracy: 0.00\n",
      "Epoch [ 16/500] - Avg Training Loss: 1.7871 Train Accuracy: 0.18 - Test Loss: 1.86 - Test Accuracy: 0.00\n",
      "Epoch [ 21/500] - Avg Training Loss: 1.7876 Train Accuracy: 0.21 - Test Loss: 1.84 - Test Accuracy: 0.00\n",
      "Epoch [ 26/500] - Avg Training Loss: 1.7900 Train Accuracy: 0.18 - Test Loss: 1.85 - Test Accuracy: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m train_inputs, train_labels \u001b[38;5;241m=\u001b[39m train_inputs\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device), train_labels\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 79\u001b[0m train_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(train_outputs, train_labels)\n\u001b[0;32m     81\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "participants = [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15]\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "\n",
    "\n",
    "confusion_matrices = []\n",
    "\n",
    "\n",
    "for i in range(len(EEG_epochs)):\n",
    "\n",
    "    epoch_participant = EEG_epochs[i]\n",
    "    encoded_participant = encoded[i]\n",
    "    \n",
    "    split_index = 40 # The last n = split_index samples are in the test set\n",
    "    \n",
    "    train_epoch, test_epoch = epoch_participant[:-1*split_index], epoch_participant[-1*split_index:]\n",
    "    train_label, test_labels = encoded_participant[:-1*split_index], encoded_participant[-1*split_index:]\n",
    "    no_encode_train_label = no_encode[i][:-1*split_index]\n",
    "    no_encode_test_label = no_encode[i][-1*split_index:]\n",
    "    \n",
    "    # print(train_epoch.shape)\n",
    "    # print(train_label.shape)\n",
    "    # print(len(no_encode_train_label))\n",
    "    \n",
    "    batch_size = 12  # Set your batch size\n",
    "    fold_num = int(EEG_epochs[i].shape[0] // batch_size)\n",
    "    \n",
    "\n",
    "    \n",
    "    #model = Deep4Net(in_chans=64, n_classes=4, input_window_samples=1123, final_conv_length='auto')\n",
    "    \n",
    "    model = new_model\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    patience = 300\n",
    "    best_metric = float('inf')\n",
    "    counter = 1\n",
    "    best_model_state = model.state_dict()\n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    train_acc_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    test_acc_epochs = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        temp_train_pred = []\n",
    "        temp_train_true = []\n",
    "        \n",
    "        train_running_loss = 0\n",
    "        \n",
    "        stratified_kfold = StratifiedKFold(n_splits=fold_num, random_state=1, shuffle=True)\n",
    "        \n",
    "        for _, (_, train_batch_index) in enumerate(stratified_kfold.split(train_epoch, no_encode_train_label)):\n",
    "            \n",
    "            batch_epoch, batch_label = train_epoch[train_batch_index], train_label[train_batch_index]\n",
    "            \n",
    "            train_dataset = EEG_Dataset(batch_epoch, batch_label, transform=None)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_epoch.shape[0])\n",
    "        \n",
    "        \n",
    "            for train_inputs, train_labels in train_loader:\n",
    "                #print(train_labels)\n",
    "                train_inputs, train_labels = train_inputs.to(torch.float32).to(device), train_labels.to(torch.float32).to(device)\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "                train_outputs = model(train_inputs)\n",
    "                loss = criterion(train_outputs, train_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_running_loss += loss.item()\n",
    "                y_pred_train = torch.argmax(train_outputs, 1).tolist()\n",
    "                y_true_train = torch.argmax(train_labels, 1).tolist()\n",
    "                temp_train_pred.extend(y_pred_train)\n",
    "                temp_train_true.extend(y_true_train)\n",
    "                \n",
    "        test_dataset = EEG_Dataset(test_epoch, test_labels, transform=None)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=test_epoch.shape[0])\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for test_input, test_label in test_loader:\n",
    "                \n",
    "                test_input, test_label = test_input.to(torch.float32).to(device), test_label.to(torch.float32).to(device)\n",
    "                test_output = model(test_input)\n",
    "                test_loss = criterion(test_output, test_label).item()\n",
    "                y_pred_test = torch.argmax(test_output, 1).tolist()\n",
    "                y_true_test = torch.argmax(test_label, 1).tolist()\n",
    "                test_conf_mat = confusion_matrix(y_true_test, y_pred_test)\n",
    "                test_accuracy = np.trace(test_conf_mat) / test_conf_mat.sum()\n",
    "        \n",
    "        avg_train_loss = train_running_loss / fold_num\n",
    "        \n",
    "        train_loss_epochs.append(avg_train_loss)\n",
    "        test_loss_epochs.append(test_loss)\n",
    "        test_acc_epochs.append(test_accuracy)\n",
    "        train_conf_mat = confusion_matrix(temp_train_true, temp_train_pred)\n",
    "        train_accuracy = np.trace(train_conf_mat) / train_conf_mat.sum()\n",
    "        train_acc_epochs.append(train_accuracy)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch [{(epoch + 1): 3d}/{max_epochs}] - Avg Training Loss: {avg_train_loss:.4f} Train Accuracy: {train_accuracy:.2f} - Test Loss: {test_loss:.2f} - Test Accuracy: {test_accuracy:.2f}\")\n",
    "        \n",
    "        if test_loss < best_metric:\n",
    "            best_metric = test_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            counter = 1\n",
    "        \n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter > patience:\n",
    "            break\n",
    "        best_epoch = epoch-patience+2\n",
    "        epochs_range = np.arange(1, len(train_loss_epochs[:best_epoch])+1)\n",
    "        \n",
    "        \n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    \n",
    "                \n",
    "    test_input, test_labels = torch.tensor(test_epoch, dtype=torch.float32).to(device), torch.tensor(test_labels, dtype=torch.float32).to(device)\n",
    "    test_output = model(test_input)\n",
    "    y_pred_test = torch.argmax(test_output, 1).tolist()\n",
    "    y_true_test = torch.argmax(test_labels, 1).tolist()\n",
    "    all_tests_true.append(y_true_test)\n",
    "    all_tests_pred.append(y_pred_test)\n",
    "        \n",
    "    \n",
    "    \n",
    "    models.append(best_model_state)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(\"Participant {}\".format(participants[i]))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(epochs_range, train_loss_epochs[:best_epoch])\n",
    "    plt.plot(epochs_range, test_loss_epochs[:best_epoch])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(epochs_range, train_acc_epochs[:best_epoch])\n",
    "    plt.plot(epochs_range, test_acc_epochs[:best_epoch])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "    plt.savefig(\"P{}_within_subject.jpg\".format(participants[i]))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d3291b7-f6d9-45fb-a772-9660b71b43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tests_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "534ec3fc-0aa8-4f87-b5ab-30fc25f1369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(all_tests_pred[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c4ea157-3a96-4d27-ba8f-9605c2c75bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_tests_true)):\n",
    "   print(all_tests_true[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38ab53e9-c603-4f26-8365-d6ed4464cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "702c0285-fdf5-4b52-adfc-f4d4ae6986f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 3 1]\n",
      " [0 5 0 5]\n",
      " [2 3 5 0]\n",
      " [0 4 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ebdd581-553d-4aed-8587-6f272aae0b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "      <th>class 3 (Pred)</th>\n",
       "      <th>class 4 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3 (True)</th>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 4 (True)</th>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)  class 3 (Pred)  class 4 (Pred)\n",
       "class 1 (True)              73              18              28              11\n",
       "class 2 (True)              12              59              23              36\n",
       "class 3 (True)              27              19              68              16\n",
       "class 4 (True)              12              45              24              49"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)', 'class 4 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)', 'class 4 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b3bd396-0100-47f1-87bf-51160149d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "      <th>class 3 (Pred)</th>\n",
       "      <th>class 4 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 3 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 4 (True)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)  class 3 (Pred)  class 4 (Pred)\n",
       "class 1 (True)        0.561538        0.000000        0.000000        0.000000\n",
       "class 2 (True)        0.000000        0.453846        0.000000        0.000000\n",
       "class 3 (True)        0.000000        0.000000        0.523077        0.000000\n",
       "class 4 (True)        0.000000        0.000000        0.000000        0.376923"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation * np.eye(4, 4) / 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "37da8839-f7ca-4302-b2cd-d39aecd2b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bijan/py3x/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4788461538461538"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(summation * np.eye(4, 4) / 130).sum() / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29cd52-5dcf-4ae1-bb58-79a1b5db4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = summation / len(confusion_matrices)\n",
    "mean_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70316f-470e-4a4a-bfd0-8fb6499bc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'mean_confusion_matrix' is the mean confusion matrix NumPy array\n",
    "mean_confusion_matrix = sum(confusion_matrices) / len(confusion_matrices)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d5222-55aa-4e69-aa7c-59f9a001736d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross-subjects (WO hyperparameter tuning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9f678b-ce96-4788-a2d8-f90f4334dc63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 \n",
      "\n",
      "      Train epochs' shape:                                (4464, 22, 1000)\n",
      "      Test epochs' shape:                                 (576, 22, 1000)\n",
      "      Test labels' shape:                                 (576, 4)\n",
      "      Train labels' shape (without encoding):             (4464, 1)\n",
      "      Test labels' shape (without encoding):              (576, 1)\n",
      "      Train index:                                        [1, 2, 3, 4, 6, 7, 8, 9]\n",
      "      Test index:                                         [5]\n",
      "\n",
      "\n",
      "\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.4e+02 (2.2e-16 eps * 22 dim * 5e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.1e+02 (2.2e-16 eps * 22 dim * 2.2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.1e+02 (2.2e-16 eps * 22 dim * 2.2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.1e+02 (2.2e-16 eps * 22 dim * 2.1e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9e+02 (2.2e-16 eps * 22 dim * 3.8e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 79 (2.2e-16 eps * 22 dim * 1.6e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 79 (2.2e-16 eps * 22 dim * 1.6e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 81 (2.2e-16 eps * 22 dim * 1.7e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9e+02 (2.2e-16 eps * 22 dim * 3.9e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 81 (2.2e-16 eps * 22 dim * 1.7e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 83 (2.2e-16 eps * 22 dim * 1.7e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 92 (2.2e-16 eps * 22 dim * 1.9e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.3e+02 (2.2e-16 eps * 22 dim * 2.7e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 57 (2.2e-16 eps * 22 dim * 1.2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 56 (2.2e-16 eps * 22 dim * 1.1e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 59 (2.2e-16 eps * 22 dim * 1.2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.1e+02 (2.2e-16 eps * 22 dim * 2.2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 45 (2.2e-16 eps * 22 dim * 9.1e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 42 (2.2e-16 eps * 22 dim * 8.7e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 43 (2.2e-16 eps * 22 dim * 8.9e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.1e+02 (2.2e-16 eps * 22 dim * 2.2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 42 (2.2e-16 eps * 22 dim * 8.7e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 41 (2.2e-16 eps * 22 dim * 8.4e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 42 (2.2e-16 eps * 22 dim * 8.6e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.1e+02 (2.2e-16 eps * 22 dim * 2.2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 22 dim * 8.3e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 22 dim * 8.3e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 40 (2.2e-16 eps * 22 dim * 8.3e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1e+02 (2.2e-16 eps * 22 dim * 2e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 22 dim * 7.7e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 22 dim * 7.6e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 37 (2.2e-16 eps * 22 dim * 7.6e+15  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Train features shape: (4464, 80)\n",
      "Test features shape: (576, 80)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.06      0.10       360\n",
      "           1       0.11      0.81      0.20        72\n",
      "           2       0.50      0.04      0.08        72\n",
      "           3       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.14       576\n",
      "   macro avg       0.24      0.23      0.10       576\n",
      "weighted avg       0.30      0.14      0.10       576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bijan/py3x/lib/python3.10/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/bijan/py3x/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bijan/py3x/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bijan/py3x/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "participants = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf_outer2.split(all_data_epochs)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_epochs = np.concatenate([all_data_epochs[j] for j in train_index])\n",
    "    test_epochs = np.concatenate([all_data_epochs[k] for k in test_index])\n",
    "    train_labels = np.concatenate([encoded[l] for l in train_index])\n",
    "    test_labels = np.concatenate([encoded[m] for m in test_index])\n",
    "    no_encoded_train_labels = np.concatenate([no_encode[n] for n in train_index])\n",
    "    no_encoded_test_labels = np.concatenate([no_encode[o] for o in test_index])\n",
    "    train_ids_for_save = [participants[i] for i in train_index]\n",
    "    test_ids_for_save = [participants[i] for i in test_index]\n",
    "    \n",
    "    \n",
    "    print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "    print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "\n",
    "    print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "    print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "    print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "    print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "    print(\"      Train index:                                       \", train_ids_for_save)\n",
    "\n",
    "    print(\"      Test index:                                        \", test_ids_for_save)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Create the EEGNet model\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     # Normalizing the features\n",
    "#     mean = train_epochs.mean(axis=(0, 2), keepdims=True)\n",
    "#     std = train_epochs.std(axis=(0, 2), keepdims=True)\n",
    "    \n",
    "#     print(mean.shape)\n",
    "#     print(std.shape)\n",
    "    \n",
    "#     norm_train_epochs = (train_epochs - mean) / std\n",
    "#     norm_test_epochs = (test_epochs - mean) / std\n",
    "#     # Commented the normalization part since it reduces the rank of data and rasing errors with \n",
    "#     # CSP filter bank\n",
    "    \n",
    "    train_features, test_features = feature_extraction_4(train_epochs, no_encoded_train_labels, test_epochs, sampling_freq = 250)\n",
    "    print(\"Train features shape:\", train_features.shape)\n",
    "    print(\"Test features shape:\", test_features.shape)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_features, no_encoded_train_labels)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model.predict(test_features)\n",
    "    \n",
    "    print(classification_report(no_encoded_test_labels, y_pred))\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a28c468c-db9a-4d3f-8138-d4af320bfe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tests_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca1ee2d3-427e-40f7-9212-3eb01de03382",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd5796f-1cf4-4f51-9ab3-f2735b410bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>284</td>\n",
       "      <td>74</td>\n",
       "      <td>96</td>\n",
       "      <td>177</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>75</td>\n",
       "      <td>285</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>214</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>257</td>\n",
       "      <td>69</td>\n",
       "      <td>84</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>261</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>214</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>87</td>\n",
       "      <td>261</td>\n",
       "      <td>81</td>\n",
       "      <td>98</td>\n",
       "      <td>199</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>95</td>\n",
       "      <td>83</td>\n",
       "      <td>234</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             L (Pred)  LS (Pred)  S (Pred)  RS (True)  R (True)  Rest (Pred)\n",
       "L (True)          284         74        96        177        69           80\n",
       "LS (True)          75        285        79         75       214           52\n",
       "S (True)           82         90       257         69        84          198\n",
       "RS (True)         261         81        75        214        80           69\n",
       "R (True)           87        261        81         98       199           54\n",
       "Rest (True)        95         83       234         79        84          205"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['L (True)', 'LS (True)', 'S (True)', 'RS (True)', 'R (True)', 'Rest (True)'], columns=['L (Pred)', 'LS (Pred)', 'S (Pred)', 'RS (True)', 'R (True)', 'Rest (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0234527d-ee6f-4084-bd58-09bbffc2e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L (True)       780\n",
       "LS (True)      780\n",
       "S (True)       780\n",
       "RS (True)      780\n",
       "R (True)       780\n",
       "Rest (True)    780\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17634ff8-1043-48bb-9d81-d8e4c3b96ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>36.410256</td>\n",
       "      <td>9.487179</td>\n",
       "      <td>12.307692</td>\n",
       "      <td>22.692308</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>10.512821</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>32.948718</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>25.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>10.256410</td>\n",
       "      <td>8.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>11.153846</td>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>12.564103</td>\n",
       "      <td>25.512821</td>\n",
       "      <td>6.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>12.179487</td>\n",
       "      <td>10.641026</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>26.282051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              L (Pred)  LS (Pred)   S (Pred)  RS (True)   R (True)  \\\n",
       "L (True)     36.410256   9.487179  12.307692  22.692308   8.846154   \n",
       "LS (True)     9.615385  36.538462  10.128205   9.615385  27.435897   \n",
       "S (True)     10.512821  11.538462  32.948718   8.846154  10.769231   \n",
       "RS (True)    33.461538  10.384615   9.615385  27.435897  10.256410   \n",
       "R (True)     11.153846  33.461538  10.384615  12.564103  25.512821   \n",
       "Rest (True)  12.179487  10.641026  30.000000  10.128205  10.769231   \n",
       "\n",
       "             Rest (Pred)  \n",
       "L (True)       10.256410  \n",
       "LS (True)       6.666667  \n",
       "S (True)       25.384615  \n",
       "RS (True)       8.846154  \n",
       "R (True)        6.923077  \n",
       "Rest (True)    26.282051  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 780 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0da3ca-2632-4cde-9ff0-fbced848e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"3class_all_tests_pred\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"3class_all_tests_true\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)\n",
    "\n",
    "    \n",
    "print(all_tests_pred[1][1].shape)\n",
    "print(all_tests_pred[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6368512-0663-4c9f-a354-f5049fecec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3class_all_tests_pred\", \"rb\") as fp:\n",
    "    rand_var = pickle.load(fp)\n",
    "\n",
    "    \n",
    "with open(\"3class_all_tests_true\", \"rb\") as fp:\n",
    "    rand_var2 = pickle.load(fp)\n",
    "print(rand_var[12][1].shape)\n",
    "print(rand_var2[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08905-a166-4f57-80c1-b2cc22f13c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests_pred[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43d0b8-df4f-4cea-862b-22c54ed434f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(all_tests_true[12][1], axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5f8a9-1df5-413e-97d7-2af43d8684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 50, 6]])\n",
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ee94d-1d88-44be-a4b7-e6b61d848aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e45e8-f7bc-4075-bb3c-2f475450f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "y_pred_prob = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_pred = np.zeros(all_tests_true[i][0].shape)\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_pred += all_tests_pred[i][j]\n",
    "    y_pred_prob.append(y_pred/6)\n",
    "    confusion_matrices_ap.append(confusion_matrix(np.argmax(all_tests_true[i][0], axis=1)+1, np.argmax(y_pred_prob[i], axis=1)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b12477-bb1b-496a-b16f-a3e2736bf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659f9e1-6fcb-4fa8-8e1d-b2b29483a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = summation.values.sum()\n",
    "correct_predictions = summation.values.trace()\n",
    "overall_accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = summation.values.diagonal() / summation.sum(axis=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Accuracy for Class {i + 1}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098dbcb-6f3d-424f-a64e-bcb8de189e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7df6f-7e9d-47d8-b08d-2790c224d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation / (13 * 40) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa6dc-4794-4e57-b493-80ce26effec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([1, 1, 2, 2, 3, 3, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba87097-1690-404c-b051-55f9c13c3473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test for the effect of calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab11fff1-54d3-4dcc-8ac1-bb29e3b1e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "Calibrated_model = []\n",
    "for file in os.listdir(\"/home/bijan/py3x\"):\n",
    "    if file.endswith(\".h5\") and file.startswith(\"Calibrated\"):\n",
    "        Calibrated_model.append(file)\n",
    "    elif file.endswith(\".h5\") and file.startswith(\"Model\"):\n",
    "        models.append(file)\n",
    "        \n",
    "Calibrated_model = sorted(Calibrated_model)\n",
    "models = sorted(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6d2b9-976c-48c7-8f69-ca5033ad00dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50466690-38ae-4f90-9012-1457989185c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "Calibrated_models = {}\n",
    "for i in range(14):\n",
    "    if i == 8:\n",
    "        continue\n",
    "        \n",
    "    for j in range(6):\n",
    "        #print(\"Model{}{}.h5\".format(i+1, j+1))\n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb10d86e-1611-4280-8da5-a61bcf95bb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0203'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:02}{:02}\".format(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa5a0ea-0c50-4ec8-873a-327b68baee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b34579d-f2e3-4917-9757-ef6058078bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Calibrated_models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33991647-0cda-498a-9e52-6950779cc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "      Cross-validation index:                            [0, 9, 12]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [5, 8]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1537, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (220, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13]\n",
      "      Cross-validation index:                            [7, 10]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1537, 576)\n",
      "Cross-validation features shape:  (220, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee414b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 1 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [3, 6]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee415fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 2 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1338, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 5, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1338, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1479, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1479, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [5, 13]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [8, 11]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1539, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (219, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [3, 7]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1539, 576)\n",
      "Cross-validation features shape:  (219, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 3 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_subjects = len(EEG_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "models = {}\n",
    "Calibrated_models = {}\n",
    "\n",
    "kf_outer1 = KFold(n_splits=6, shuffle=True, random_state=42)              # Split the data into Train and Cross-Validation sets\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "for i, (train_crossval_index, test_index) in enumerate(kf_outer2.split(EEG_epochs)):\n",
    "    \n",
    "    if test_index == 7:\n",
    "        continue\n",
    "    \n",
    "    train_crossval = [EEG_epochs[i] for i in train_crossval_index]\n",
    "    test_epochs = np.concatenate([EEG_epochs[i] for i in test_index])\n",
    "    train_crossval_labels = [encoded[i] for i in train_crossval_index]\n",
    "    test_labels = np.concatenate([encoded[i] for i in test_index])\n",
    "    no_encoded_train_crossval = [no_encode[i] for i in train_crossval_index]\n",
    "    no_encoded_test = np.concatenate([no_encode[i] for i in test_index])\n",
    "\n",
    "    temp_pred = []\n",
    "    temp_true = []\n",
    "\n",
    "    for j, (train_index, val_index) in enumerate(kf_outer1.split(train_crossval)):\n",
    "        \n",
    "        \n",
    "        train_epochs = np.concatenate([train_crossval[i] for i in train_index])\n",
    "        crossval_epochs = np.concatenate([train_crossval[i] for i in val_index])\n",
    "        train_labels = np.concatenate([train_crossval_labels[i] for i in train_index])\n",
    "        crossval_labels = np.concatenate([train_crossval_labels[i] for i in val_index])\n",
    "        no_encoded_train = np.concatenate([no_encoded_train_crossval[i] for i in train_index])\n",
    "        no_encoded_crossval = np.concatenate([no_encoded_train_crossval[i] for i in val_index])\n",
    "        train_ids_for_save = [train_crossval_index[i] for i in train_index]\n",
    "        cross_val_ids_for_save = [train_crossval_index[i] for i in val_index]\n",
    "        \n",
    "        \n",
    "        print(\"Outer Loop {} and Inner Loop {}:\".format(i+1, j+1), \"\\n\")\n",
    "        print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "        #print(\"     Train labels' shape:                               \", train_labels.shape)\n",
    "        print(\"      Cross-validation epochs' shape:                    \", crossval_epochs.shape)\n",
    "        #print(\"     Cross-validation labels' shape:                    \", crossval_labels.shape)\n",
    "        print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "        #print(\"     Test labels' shape:                                \", test_labels.shape)\n",
    "        #print(\"     Train labels' shape (without encoding):            \", no_encoded_train.shape)\n",
    "        #print(\"     Cross-validation labels' shape (without encoding): \", no_encoded_crossval.shape)\n",
    "        #print(\"     Test labels' shape (without encoding):             \", no_encoded_test.shape)\n",
    "        print(\"      Train index:                                      \", train_ids_for_save)\n",
    "        print(\"      Cross-validation index:                           \", cross_val_ids_for_save)\n",
    "        print(\"      Test index:                                       \", test_index)\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = open('temp_stdout{}.txt'.format(i), 'w')  # Redirect output to a temporary file\n",
    "        train_features, CrossVal_features, test_features = feature_extraction_cv(train_epochs, no_encoded_train, crossval_epochs, test_epochs, number_of_bands=9, sampling_freq=250, low_cutoff=0, number_of_components=64)\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout\n",
    "    \n",
    "        print(\"Train features shape:            \", train_features.shape)\n",
    "        print(\"Cross-validation features shape: \", CrossVal_features.shape)\n",
    "        print(\"Test features shape:             \", test_features.shape)\n",
    "    \n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)\n",
    "        \n",
    "        temp_pred.append(models[\"{:02}{:02}\".format(i+1, j+1)].predict(test_features[60:]))\n",
    "        temp_true.append(test_labels[60:])\n",
    "        \n",
    "    all_tests_pred.append(temp_pred)\n",
    "    all_tests_true.append(temp_true)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003b1db8-fd82-4248-af7d-378f87f1f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"all_tests_pred_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"all_tests_true_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d30ebb-08d2-48c0-8cfd-dc3915c5da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_true = 2 - np.argmax(all_tests_true[i][j], axis=1)\n",
    "        y_pred = 2 - np.argmax(all_tests_pred[i][j], axis=1)\n",
    "    confusion_matrices_ap.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66dd2c7b-5dbb-4b67-b72a-15e759258c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>358</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)             358             162\n",
       "class 2 (True)             202             315"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792408a4-5e58-4ca5-a1c5-6e73b9dcd381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.311538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.605769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)        0.688462        0.311538\n",
       "class 2 (True)        0.388462        0.605769"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69570fb4-4782-4b2d-a397-a3f1ebac8bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for binary classification (Left vs Right hand):\n",
      "\n",
      "\n",
      "       Accuracy:                  0.65\n",
      "\n",
      "       Precision:                 0.66\n",
      "\n",
      "       Recall (Sensitivity):      0.61     \n",
      "\n",
      "       F1 Score:                  0.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    " \n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79248da6-dded-44ba-987d-1dc4eb71db65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3x",
   "language": "python",
   "name": "py3x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
