{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42992946",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af32dba6-d557-4f5c-b2a9-6524cdd3636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from mne.decoding import CSP\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import copy\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "import io\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa17ce7-4e1c-4f52-8963-abd86084b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'pwd' is not recognized as an internal or external command,\",\n",
       " 'operable program or batch file.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# projects/def-b09sdp/bijan/Phase2/P16.fdt\n",
    "path = !pwd\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7bc34-24a6-4250-89bf-4bc9422e0af4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45befd64-9db2-4cf8-b119-eae966306003",
   "metadata": {},
   "source": [
    "Mode: 'binary', '3-class', '4-class', '5-class', '6-class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec218e4-dc89-43dd-9105-6875b25f7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrapper(data_epochs, data_labels, mode='binary'):\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        epochs = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            binary_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2)]\n",
    "            #class2_epochs = participant_epochs[participant_labels==2]\n",
    "            #bi_epochs = np.concatenate((class1_epochs, class2_epochs), axis=0)\n",
    "            epochs.append(binary_epochs)\n",
    "    \n",
    "            binary_labels = participant_labels[(participant_labels==1) | (participant_labels==2)]\n",
    "            #bi_labels = np.concatenate((class1_labels, class2_labels), axis=0)\n",
    "            labels.append(binary_labels)\n",
    "            \n",
    "    elif mode == '3_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==1) | (participant_labels==2) | (participant_labels==3)]\n",
    "            labels.append(multiclass_labels)\n",
    "            \n",
    "            \n",
    "    elif mode == '4_class_RS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==2) | (participant_labels==6) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "        \n",
    "    elif mode == '4_class_LS':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    elif mode == '6_class':\n",
    "        \n",
    "        epochs = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(len(data_epochs)):\n",
    "            participant_epochs = data_epochs[i]\n",
    "            participant_labels = data_labels[i]\n",
    "    \n",
    "            multiclass_epochs = participant_epochs[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            epochs.append(multiclass_epochs)\n",
    "    \n",
    "            multiclass_labels = participant_labels[(participant_labels==3) | (participant_labels==7) | (participant_labels==5) | (participant_labels==6) | (participant_labels==2) | (participant_labels==1)]\n",
    "            labels.append(multiclass_labels)\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e97a6c-2926-493a-9a07-3d750b25f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_extraction(class_1, class_2, class_3, class_4, data, labels):\n",
    "    mask = np.isin(labels[:, 0], [class_1, class_2, class_3, class_4])\n",
    "    dataset = data[mask, :, :]\n",
    "    Final_labels = labels[mask, :]\n",
    "    return dataset, Final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1df0ac-3b7e-4257-9a23-2587dfada64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_label_extractor(Data, epoch_length=1123, num_channels=64):\n",
    "    df = Data.to_data_frame()\n",
    "    X = df[df.columns[3:]].to_numpy()\n",
    "    X = np.transpose(X)\n",
    "\n",
    "    number_of_epochs = int(len(df)/epoch_length)\n",
    "    \n",
    "    randomlist = random.sample(range(number_of_epochs), number_of_epochs)\n",
    "\n",
    "    data = np.zeros((number_of_epochs,num_channels, epoch_length))\n",
    "    labels = np.zeros((number_of_epochs,1)).astype(int)\n",
    "\n",
    "    for i in range(number_of_epochs):\n",
    "        data[i,:,:] = X[:, randomlist[i]*epoch_length:(randomlist[i] + 1)*epoch_length]\n",
    "        if (df['condition'][randomlist[i]*epoch_length] == 'Left'):\n",
    "            labels[i,0] = 0\n",
    "        elif(df['condition'][randomlist[i]*epoch_length] == 'Right'):\n",
    "            labels[i,0] = 1\n",
    "        elif(df['condition'][randomlist[i]*epoch_length] == 'Feet'):\n",
    "            labels[i,0] = 2\n",
    "        elif(df['condition'][randomlist[i]*epoch_length] == 'Tongue'):\n",
    "            labels[i,0] = 3\n",
    "        elif(df['condition'][randomlist[i]*epoch_length] == 'Mis'):\n",
    "            labels[i,0] = 4\n",
    "        elif(df['condition'][randomlist[i]*epoch_length] == 'Si'):\n",
    "            labels[i,0] = 5\n",
    "        else:\n",
    "            labels[i,0] = 6\n",
    "        \n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5154e2-0354-4913-a796-40e515129978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(y_data, method=OneHotEncoder):\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(y_data[0].reshape(-1, 1))\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        \n",
    "        a = encoder.transform(y_data[i].reshape(-1, 1))\n",
    "        y_data[i] = a.toarray()\n",
    "\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda8305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_csp(x_train, y_train, x_test, number_of_components=10):\n",
    "    \n",
    "        csp = CSP(number_of_components)\n",
    "        csp_fit = csp.fit(x_train, y_train)\n",
    "        train_feat = csp_fit.transform(x_train)\n",
    "        test_feat = csp_fit.transform(x_test)\n",
    "        return train_feat, test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70687bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_4(dataset, labels, test_data, sampling_freq):\n",
    "\n",
    "    # Why number of bands were set to 24??\n",
    "    \n",
    "    low_cutoff = 0\n",
    "    number_of_bands = 8\n",
    "    for b in range(number_of_bands):\n",
    "        data = dataset.copy()\n",
    "        data_test = test_data.copy()\n",
    "        filtered_data = mne.filter.filter_data(data, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        filtered_data_test = mne.filter.filter_data(data_test, sampling_freq, low_cutoff, low_cutoff + 4, verbose = False)\n",
    "        tic = time.time()\n",
    "        train_feats, test_feats = calc_csp(filtered_data, labels[:, 0], filtered_data_test)\n",
    "        toc = time.time()\n",
    "        print(\"Time taken for csp calculations: \", toc-tic)\n",
    "        if b == 0:\n",
    "            train_features = train_feats\n",
    "            test_features = test_feats\n",
    "        else:\n",
    "            train_features = np.concatenate((train_features, train_feats), axis = 1)\n",
    "            test_features = np.concatenate((test_features, test_feats), axis = 1)\n",
    "        \n",
    "        low_cutoff += 4\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46e076",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Device (GPU\\CPU\\MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3963e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61c74e-3fdb-4e1a-b086-fc5180a12db4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2cf427-6a5c-47af-ab15-a4d4203b1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P2\\P2.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P3\\P3.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Channel names are not unique, found duplicates for: {'FCz'}. Applying running numbers for duplicates.\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "488 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P4\\P4.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Channel names are not unique, found duplicates for: {'FCz'}. Applying running numbers for duplicates.\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "491 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P5\\P5.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "489 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P6\\P6.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "489 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P7\\P7.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P8\\P8.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P9\\P9.set...\n",
      "Not setting metadata\n",
      "280 matching events found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P10\\P10.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P11\\P11.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P12\\P12.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P13\\P13.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "488 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P14\\P14.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\\P15\\P15.set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_25260\\2620136347.py:27: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ref: ['FCz']\n",
      "  raw_data = mne.read_epochs_eeglab(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "490 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = \"D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\"\n",
    "\n",
    "try: \n",
    "    if path[0] == '/home/bijan/py3x/Code_Zhang/Transfer_Learning_On_EEG_BCI':\n",
    "        print(\"Running on cloud ...\")\n",
    "        print(\"Please make sure to modify how you read the data according to your need!\\n\\n\")\n",
    "        raw_data_path = \"/home/bijan/projects/def-b09sdp/bijan/BCI_IV_2a/gdf\"\n",
    "            \n",
    "\n",
    "except NameError:\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:\\Hadi_BCI\\Recordings\\Phase 1\\PreProcessedData\"\n",
    "    \n",
    "    \n",
    "\n",
    "all_data_epochs = []\n",
    "all_data_labels = []\n",
    "\n",
    "for participant_id in range(1, 16):\n",
    "    if participant_id == 1:\n",
    "        continue\n",
    "    participant = f\"P{participant_id}\\P{participant_id}.set\"\n",
    "\n",
    "    file_path = f\"{raw_data_path}/{participant}\"\n",
    "\n",
    "    raw_data = mne.read_epochs_eeglab(file_path)\n",
    "\n",
    "    epochs, labels = epoch_label_extractor(raw_data, epoch_length=1123, num_channels=64)\n",
    "    \n",
    "    class_1=0\n",
    "    class_2=1 \n",
    "    class_3=2 \n",
    "    class_4=3\n",
    "    num_channels = 64\n",
    "    epoch_length = 1123\n",
    "    \n",
    "    data_epochs, data_labels = class_extraction(class_1, class_2, class_3, class_4, epochs, labels)\n",
    "    \n",
    "    all_data_epochs.append(data_epochs)\n",
    "    all_data_labels.append(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7395c987-0862-41a1-bd42-e9ef75ac3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 train epochs:     (280, 64, 1123)     Subject 1 train labels:     (280, 1)\n",
      "Subject 2 train epochs:     (278, 64, 1123)     Subject 2 train labels:     (278, 1)\n",
      "Subject 3 train epochs:     (280, 64, 1123)     Subject 3 train labels:     (280, 1)\n",
      "Subject 4 train epochs:     (279, 64, 1123)     Subject 4 train labels:     (279, 1)\n",
      "Subject 5 train epochs:     (279, 64, 1123)     Subject 5 train labels:     (279, 1)\n",
      "Subject 6 train epochs:     (280, 64, 1123)     Subject 6 train labels:     (280, 1)\n",
      "Subject 7 train epochs:     (280, 64, 1123)     Subject 7 train labels:     (280, 1)\n",
      "Subject 8 train epochs:     (160, 64, 1123)     Subject 8 train labels:     (160, 1)\n",
      "Subject 9 train epochs:     (280, 64, 1123)     Subject 9 train labels:     (280, 1)\n",
      "Subject 10 train epochs:     (280, 64, 1123)     Subject 10 train labels:     (280, 1)\n",
      "Subject 11 train epochs:     (280, 64, 1123)     Subject 11 train labels:     (280, 1)\n",
      "Subject 12 train epochs:     (279, 64, 1123)     Subject 12 train labels:     (279, 1)\n",
      "Subject 13 train epochs:     (280, 64, 1123)     Subject 13 train labels:     (280, 1)\n",
      "Subject 14 train epochs:     (280, 64, 1123)     Subject 14 train labels:     (280, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data_epochs)):\n",
    "    print(\"Subject {} train epochs:    \".format(i+1), all_data_epochs[i].shape, \"    Subject {} train labels:    \".format(i+1), all_data_labels[i].shape)\n",
    "    #print(\"Subject {} test epochs:     \".format(i+1), test_data_epochs[i].shape, \"    Subject {} test labels:     \".format(i+1), test_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "149bd418-d83e-4bb4-a1d0-29abbaaea54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 70, 0: 70, 1: 70, 2: 70})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(all_data_labels[13][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a45a5ccf-dc63-4283-bf4b-a90d8a5a5556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 6, 1, 5, 6, 1, 3, 2, 3, 2, 1, 2, 2, 0, 3, 6, 5, 0, 6, 2,\n",
       "       1, 4, 6, 1, 2, 4, 2, 6, 1, 5, 5, 6, 0, 0, 4, 5, 3, 3, 1, 4, 3, 1,\n",
       "       5, 3, 1, 5, 0, 6, 4, 4, 4, 3, 4, 1, 1, 2, 0, 4, 4, 6, 2, 6, 3, 2,\n",
       "       6, 4, 0, 6, 4, 2, 6, 3, 5, 1, 3, 4, 6, 5, 6, 2, 6, 4, 5, 1, 0, 5,\n",
       "       5, 5, 0, 4, 3, 3, 6, 3, 0, 4, 2, 4, 2, 0, 1, 0, 5, 4, 0, 1, 3, 4,\n",
       "       3, 4, 3, 2, 0, 5, 4, 4, 0, 0, 0, 1, 4, 2, 2, 1, 3, 6, 2, 6, 2, 5,\n",
       "       3, 4, 6, 0, 6, 2, 3, 2, 1, 5, 2, 3, 2, 2, 2, 1, 6, 5, 1, 0, 1, 0,\n",
       "       6, 2, 4, 0, 4, 0, 1, 3, 3, 6, 5, 2, 4, 3, 2, 0, 5, 6, 1, 1, 0, 1,\n",
       "       4, 6, 3, 6, 5, 6, 6, 5, 3, 6, 6, 2, 3, 0, 1, 3, 0, 5, 2, 5, 3, 1,\n",
       "       0, 6, 2, 3, 0, 3, 0, 5, 4, 0, 5, 3, 6, 0, 5, 6, 5, 1, 1, 3, 3, 0,\n",
       "       2, 6, 6, 5, 3, 6, 0, 6, 5, 3, 6, 0, 5, 4, 5, 0, 0, 5, 1, 6, 4, 3,\n",
       "       2, 5, 2, 4, 3, 1, 6, 3, 3, 6, 0, 2, 6, 5, 1, 0, 1, 3, 4, 2, 4, 5,\n",
       "       6, 4, 2, 1, 4, 1, 1, 3, 3, 2, 3, 5, 4, 4, 4, 2, 3, 2, 5, 1, 6, 0,\n",
       "       3, 1, 2, 2, 5, 5, 1, 2, 4, 4, 0, 0, 4, 5, 4, 1, 5, 2, 4, 2, 5, 3,\n",
       "       3, 0, 5, 0, 3, 1, 2, 1, 1, 5, 0, 6, 2, 1, 2, 5, 3, 2, 3, 5, 2, 4,\n",
       "       5, 6, 2, 2, 1, 5, 2, 6, 2, 5, 1, 6, 1, 4, 5, 4, 6, 2, 4, 0, 4, 0,\n",
       "       5, 4, 4, 5, 5, 2, 0, 0, 6, 2, 0, 6, 0, 5, 6, 1, 4, 6, 0, 4, 2, 4,\n",
       "       2, 5, 5, 2, 4, 1, 0, 2, 2, 4, 3, 1, 1, 5, 3, 1, 1, 1, 3, 3, 2, 1,\n",
       "       4, 6, 3, 4, 6, 3, 2, 1, 1, 5, 5, 1, 1, 4, 1, 6, 6, 6, 6, 3, 6, 4,\n",
       "       1, 4, 3, 3, 1, 3, 4, 0, 0, 0, 1, 6, 5, 2, 0, 1, 0, 6, 6, 2, 1, 0,\n",
       "       4, 6, 0, 6, 3, 5, 6, 0, 1, 3, 0, 3, 5, 0, 5, 4, 1, 6, 5, 4, 5, 3,\n",
       "       5, 2, 5, 2, 3, 1, 0, 4, 4, 0, 4, 4, 0, 0, 0, 5, 6, 5, 3, 1, 2, 2,\n",
       "       6, 0, 1, 3, 4, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b44f23-4e9a-4b10-8a58-a3a5d6ce40cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data epoch shape (sub 0):     (280, 64, 1123)     All label shape (sub 0):      (280, 1)\n",
      "All data epoch shape (sub 1):     (278, 64, 1123)     All label shape (sub 1):      (278, 1)\n",
      "All data epoch shape (sub 2):     (280, 64, 1123)     All label shape (sub 2):      (280, 1)\n",
      "All data epoch shape (sub 3):     (279, 64, 1123)     All label shape (sub 3):      (279, 1)\n",
      "All data epoch shape (sub 4):     (279, 64, 1123)     All label shape (sub 4):      (279, 1)\n",
      "All data epoch shape (sub 5):     (280, 64, 1123)     All label shape (sub 5):      (280, 1)\n",
      "All data epoch shape (sub 6):     (280, 64, 1123)     All label shape (sub 6):      (280, 1)\n",
      "All data epoch shape (sub 7):     (160, 64, 1123)     All label shape (sub 7):      (160, 1)\n",
      "All data epoch shape (sub 8):     (280, 64, 1123)     All label shape (sub 8):      (280, 1)\n",
      "All data epoch shape (sub 9):     (280, 64, 1123)     All label shape (sub 9):      (280, 1)\n",
      "All data epoch shape (sub 10):     (280, 64, 1123)     All label shape (sub 10):      (280, 1)\n",
      "All data epoch shape (sub 11):     (279, 64, 1123)     All label shape (sub 11):      (279, 1)\n",
      "All data epoch shape (sub 12):     (280, 64, 1123)     All label shape (sub 12):      (280, 1)\n",
      "All data epoch shape (sub 13):     (280, 64, 1123)     All label shape (sub 13):      (280, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data_epochs)):\n",
    "    print(\"All data epoch shape (sub {}):    \".format(i), all_data_epochs[i].shape, \"    All label shape (sub {}):     \".format(i), all_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ad8cc53-ff96-4ce2-8f8e-54f46ec896bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_labels[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d77c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "433703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_encode = copy.deepcopy(all_data_labels)\n",
    "encoded = encoder(all_data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d26a1f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Length: 14\n",
      "labels Length: 14\n",
      "\n",
      "\n",
      "\n",
      "Participant 14 - Epochs[0] shape: (280, 1)\n",
      "Participant 14 - labels[0] shape: (280, 4)\n",
      "\n",
      "\n",
      "\n",
      "Participant 14 - labels[0]:\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "id = 13\n",
    "print(\"Epochs Length:\", len(all_data_labels))\n",
    "print(\"labels Length:\", len(encoded))\n",
    "print('\\n\\n')\n",
    "print(f\"Participant {id+1} - Epochs[0] shape:\", no_encode[id].shape)\n",
    "print(f\"Participant {id+1} - labels[0] shape:\", encoded[id].shape)\n",
    "print('\\n\\n')\n",
    "print(f\"Participant {id+1} - labels[0]:\")\n",
    "print(all_data_labels[id][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbccfbb-49ff-461f-b50f-0f7448e933ab",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Within Subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d55a8f-6ef7-4d36-b1a9-cfb8c89122a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in range(num_subjects):\n",
    "    \n",
    "    epochs_subject = all_data_epochs[j]\n",
    "    labels_subject = encoded[j]\n",
    "    labels_subject_no_encode = no_encode[j]\n",
    "    \n",
    "    print(labels_subject_no_encode.shape)\n",
    "    \n",
    "    kf_outer2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    \n",
    "    tests_pred = []\n",
    "    tests_true = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf_outer2.split(epochs_subject, labels_subject_no_encode[:, 0])):\n",
    "\n",
    "\n",
    "\n",
    "        train_epochs = np.array([epochs_subject[j] for j in train_index])\n",
    "        test_epochs = np.array([epochs_subject[k] for k in test_index])\n",
    "        train_labels = np.array([labels_subject[l] for l in train_index])\n",
    "        test_labels = np.array([labels_subject[m] for m in test_index])\n",
    "        no_encoded_train_labels = np.array([labels_subject_no_encode[n] for n in train_index])\n",
    "        no_encoded_test_labels = np.array([labels_subject_no_encode[o] for o in test_index])\n",
    "        \n",
    "\n",
    "\n",
    "        print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "        print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "        print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "        print(\"      Train labels' shape:                               \", train_labels.shape)\n",
    "        print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "        print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "        print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "\n",
    "        # Create the EEGNet model\n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #     # Normalizing the features\n",
    "        #     mean = train_epochs.mean(axis=(0, 2), keepdims=True)\n",
    "        #     std = train_epochs.std(axis=(0, 2), keepdims=True)\n",
    "\n",
    "        #     print(mean.shape)\n",
    "        #     print(std.shape)\n",
    "\n",
    "        #     norm_train_epochs = (train_epochs - mean) / std\n",
    "        #     norm_test_epochs = (test_epochs - mean) / std\n",
    "        #     # Commented the normalization part since it reduces the rank of data and rasing errors with \n",
    "        #     # CSP filter bank\n",
    "\n",
    "        train_features, test_features = feature_extraction_4(train_epochs, no_encoded_train_labels, test_epochs, sampling_freq = 250)\n",
    "        print(\"Train features shape:\", train_features.shape)\n",
    "        print(\"Test features shape:\", test_features.shape)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(train_features, no_encoded_train_labels[:, 0])\n",
    "\n",
    "        # Test the model\n",
    "        y_pred = model.predict(test_features)\n",
    "        \n",
    "        tests_pred.append(y_pred)\n",
    "        tests_true.append(no_encoded_test_labels[:, 0])\n",
    "    \n",
    "    all_tests_pred.append(tests_pred)\n",
    "    all_tests_true.append(tests_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d3291b7-f6d9-45fb-a772-9660b71b43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tests_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "534ec3fc-0aa8-4f87-b5ab-30fc25f1369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(279,)\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate(all_tests_pred[4]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38ab53e9-c603-4f26-8365-d6ed4464cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_true = np.concatenate(all_tests_true[i])\n",
    "    y_pred = np.concatenate(all_tests_pred[i])\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "702c0285-fdf5-4b52-adfc-f4d4ae6986f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64  2  3  0]\n",
      " [ 3 63  2  2]\n",
      " [ 0  5 51 13]\n",
      " [ 0  3 19 48]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ebdd581-553d-4aed-8587-6f272aae0b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['Left (True)', 'Right (True)', 'Feet (True)', 'Tongue (True)'], columns=['Left (Pred)', 'Right (Pred)', 'Feet (Pred)', 'Tongue (Pred)'])\n",
    "acc = np.sum(summation * np.eye(4, 4)).sum() / np.sum(summation).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac6929fe-6598-4960-9fd4-89ff7503b019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left (Pred)</th>\n",
       "      <th>Right (Pred)</th>\n",
       "      <th>Feet (Pred)</th>\n",
       "      <th>Tongue (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Left (True)</th>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.132017</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Right (True)</th>\n",
       "      <td>0.152679</td>\n",
       "      <td>0.699584</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feet (True)</th>\n",
       "      <td>0.087968</td>\n",
       "      <td>0.087318</td>\n",
       "      <td>0.653105</td>\n",
       "      <td>0.184615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tongue (True)</th>\n",
       "      <td>0.061678</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.184154</td>\n",
       "      <td>0.701099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Left (Pred)  Right (Pred)  Feet (Pred)  Tongue (Pred)\n",
       "Left (True)       0.697674      0.132017     0.083512       0.057143\n",
       "Right (True)      0.152679      0.699584     0.079229       0.057143\n",
       "Feet (True)       0.087968      0.087318     0.653105       0.184615\n",
       "Tongue (True)     0.061678      0.081081     0.184154       0.701099"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / np.sum(summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c4c5f0d-9b8b-4556-8846-94475c43677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadi's Dataset - The within subject scenario:\n",
      "Algorithm: RF\n",
      "Accuracy:  0.6880105401844532\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left (Pred)</th>\n",
       "      <th>Right (Pred)</th>\n",
       "      <th>Feet (Pred)</th>\n",
       "      <th>Tongue (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Left (True)</th>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.134108</td>\n",
       "      <td>0.082365</td>\n",
       "      <td>0.054910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Right (True)</th>\n",
       "      <td>0.158947</td>\n",
       "      <td>0.708421</td>\n",
       "      <td>0.077895</td>\n",
       "      <td>0.054737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feet (True)</th>\n",
       "      <td>0.091675</td>\n",
       "      <td>0.088514</td>\n",
       "      <td>0.642782</td>\n",
       "      <td>0.177028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tongue (True)</th>\n",
       "      <td>0.064278</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.181243</td>\n",
       "      <td>0.672287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Left (Pred)  Right (Pred)  Feet (Pred)  Tongue (Pred)\n",
       "Left (True)       0.728617      0.134108     0.082365       0.054910\n",
       "Right (True)      0.158947      0.708421     0.077895       0.054737\n",
       "Feet (True)       0.091675      0.088514     0.642782       0.177028\n",
       "Tongue (True)     0.064278      0.082192     0.181243       0.672287"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Hadi's Dataset - The within subject scenario:\")\n",
    "print(\"Algorithm: RF\")\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "summation.div(summation.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b3bd396-0100-47f1-87bf-51160149d657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Left (True)      947\n",
       "Right (True)     950\n",
       "Feet (True)      949\n",
       "Tongue (True)    949\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37da8839-f7ca-4302-b2cd-d39aecd2b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74609375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(summation / 576 * np.eye(4, 4)).sum() / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d5222-55aa-4e69-aa7c-59f9a001736d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross-subjects (WO hyperparameter tuning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9f678b-ce96-4788-a2d8-f90f4334dc63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 0th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 1th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 2th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 3th run out of 9 is done!\n",
      "Train features shape: (2304, 80)\n",
      "Test features shape: (144, 80)\n",
      "The 4th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 5th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 6th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 7th run out of 9 is done!\n",
      "Train features shape: (2160, 80)\n",
      "Test features shape: (288, 80)\n",
      "The 8th run out of 9 is done!\n"
     ]
    }
   ],
   "source": [
    "participants = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf_outer2.split(all_data_epochs)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_epochs = np.concatenate([all_data_epochs[j] for j in train_index])\n",
    "    test_epochs = np.concatenate([all_data_epochs[k] for k in test_index])\n",
    "    train_labels = np.concatenate([encoded[l] for l in train_index])\n",
    "    test_labels = np.concatenate([encoded[m] for m in test_index])\n",
    "    no_encoded_train_labels = np.concatenate([no_encode[n] for n in train_index])\n",
    "    no_encoded_test_labels = np.concatenate([no_encode[o] for o in test_index])\n",
    "    train_ids_for_save = [participants[i] for i in train_index]\n",
    "    test_ids_for_save = [participants[i] for i in test_index]\n",
    "    \n",
    "    \n",
    "#     print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "#     print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "\n",
    "#     print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "#     print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "#     print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "#     print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "#     print(\"      Train index:                                       \", train_ids_for_save)\n",
    "\n",
    "#     print(\"      Test index:                                        \", test_ids_for_save)\n",
    "#     print('\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Create the EEGNet model\n",
    "    model = XGBClassifier()\n",
    "    \n",
    "    \n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open('temp_stdout{}.txt'.format(i+10000), 'w')  # Redirect output to a temporary file\n",
    "    train_features, test_features = feature_extraction_4(train_epochs, no_encoded_train_labels, test_epochs, sampling_freq = 250)\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = original_stdout\n",
    "    \n",
    "    \n",
    "    print(\"Train features shape:\", train_features.shape)\n",
    "    print(\"Test features shape:\", test_features.shape)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_features, no_encoded_train_labels)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model.predict(test_features)\n",
    "    \n",
    "    \n",
    "    all_tests_pred.append(y_pred)\n",
    "    all_tests_true.append(no_encoded_test_labels)\n",
    "    with open(\"all_tests_pred_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(all_tests_pred, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        \n",
    "    with open(\"all_tests_true_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(all_tests_true, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        \n",
    "    with open(\"indexes.pickle\", \"wb\") as f:\n",
    "        pickle.dump(test_index, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    \n",
    "    with open(\"train_features_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(train_features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        \n",
    "    with open(\"test_features_{}.pickle\".format(i), \"wb\") as f:\n",
    "        pickle.dump(test_features, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    print(\"The {}th run out of 9 is done!\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28c468c-db9a-4d3f-8138-d4af320bfe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tests_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca1ee2d3-427e-40f7-9212-3eb01de03382",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    if i == 3:\n",
    "        continue\n",
    "    y_true = all_tests_true[i]\n",
    "    y_pred = all_tests_pred[i]\n",
    "    confusion_matrices.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fd5796f-1cf4-4f51-9ab3-f2735b410bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices), index=['Left (True)', 'Right (True)', 'Feet (True)', 'Tongue (True)'], columns=['Left (Pred)', 'Right (Pred)', 'Feet (Pred)', 'Tongue (Pred)'])\n",
    "acc = np.sum(summation / 576 * np.eye(4, 4)).sum() / 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0234527d-ee6f-4084-bd58-09bbffc2e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Left (True)      576\n",
       "Right (True)     576\n",
       "Feet (True)      504\n",
       "Tongue (True)    504\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c990859c-22c2-476d-90c6-2ad17c00b752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Hello, worimport sys\")\n",
    "sys.stdout\n",
    "sys.stdout = sys.__stdout__\n",
    "sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a26125-1e6f-4ab0-b029-cc6075356f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3120659722222222"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e38d298-983b-4399-b59d-fbfb65986317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-subject scenario:\n",
      "Algorithm: XGBClassifier\n",
      "Accuracy:  0.3125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left (Pred)</th>\n",
       "      <th>Right (Pred)</th>\n",
       "      <th>Feet (Pred)</th>\n",
       "      <th>Tongue (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Left (True)</th>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.164931</td>\n",
       "      <td>0.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Right (True)</th>\n",
       "      <td>0.184028</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feet (True)</th>\n",
       "      <td>0.190972</td>\n",
       "      <td>0.288194</td>\n",
       "      <td>0.147569</td>\n",
       "      <td>0.248264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tongue (True)</th>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.267361</td>\n",
       "      <td>0.105903</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Left (Pred)  Right (Pred)  Feet (Pred)  Tongue (Pred)\n",
       "Left (True)       0.319444      0.296875     0.164931       0.218750\n",
       "Right (True)      0.184028      0.505208     0.102431       0.208333\n",
       "Feet (True)       0.190972      0.288194     0.147569       0.248264\n",
       "Tongue (True)     0.223958      0.267361     0.105903       0.277778"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The cross-subject scenario:\")\n",
    "print(\"Algorithm: XGBClassifier\")\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "summation / 576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17634ff8-1043-48bb-9d81-d8e4c3b96ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L (Pred)</th>\n",
       "      <th>LS (Pred)</th>\n",
       "      <th>S (Pred)</th>\n",
       "      <th>RS (True)</th>\n",
       "      <th>R (True)</th>\n",
       "      <th>Rest (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L (True)</th>\n",
       "      <td>36.410256</td>\n",
       "      <td>9.487179</td>\n",
       "      <td>12.307692</td>\n",
       "      <td>22.692308</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LS (True)</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S (True)</th>\n",
       "      <td>10.512821</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>32.948718</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>25.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS (True)</th>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>27.435897</td>\n",
       "      <td>10.256410</td>\n",
       "      <td>8.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R (True)</th>\n",
       "      <td>11.153846</td>\n",
       "      <td>33.461538</td>\n",
       "      <td>10.384615</td>\n",
       "      <td>12.564103</td>\n",
       "      <td>25.512821</td>\n",
       "      <td>6.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rest (True)</th>\n",
       "      <td>12.179487</td>\n",
       "      <td>10.641026</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.128205</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>26.282051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              L (Pred)  LS (Pred)   S (Pred)  RS (True)   R (True)  \\\n",
       "L (True)     36.410256   9.487179  12.307692  22.692308   8.846154   \n",
       "LS (True)     9.615385  36.538462  10.128205   9.615385  27.435897   \n",
       "S (True)     10.512821  11.538462  32.948718   8.846154  10.769231   \n",
       "RS (True)    33.461538  10.384615   9.615385  27.435897  10.256410   \n",
       "R (True)     11.153846  33.461538  10.384615  12.564103  25.512821   \n",
       "Rest (True)  12.179487  10.641026  30.000000  10.128205  10.769231   \n",
       "\n",
       "             Rest (Pred)  \n",
       "L (True)       10.256410  \n",
       "LS (True)       6.666667  \n",
       "S (True)       25.384615  \n",
       "RS (True)       8.846154  \n",
       "R (True)        6.923077  \n",
       "Rest (True)    26.282051  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 780 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0da3ca-2632-4cde-9ff0-fbced848e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"3class_all_tests_pred\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"3class_all_tests_true\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)\n",
    "\n",
    "    \n",
    "print(all_tests_pred[1][1].shape)\n",
    "print(all_tests_pred[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6368512-0663-4c9f-a354-f5049fecec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3class_all_tests_pred\", \"rb\") as fp:\n",
    "    rand_var = pickle.load(fp)\n",
    "\n",
    "    \n",
    "with open(\"3class_all_tests_true\", \"rb\") as fp:\n",
    "    rand_var2 = pickle.load(fp)\n",
    "print(rand_var[12][1].shape)\n",
    "print(rand_var2[12][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08905-a166-4f57-80c1-b2cc22f13c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests_pred[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43d0b8-df4f-4cea-862b-22c54ed434f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(all_tests_true[12][1], axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5f8a9-1df5-413e-97d7-2af43d8684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 50, 6]])\n",
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ee94d-1d88-44be-a4b7-e6b61d848aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e45e8-f7bc-4075-bb3c-2f475450f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "y_pred_prob = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    y_pred = np.zeros(all_tests_true[i][0].shape)\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_pred += all_tests_pred[i][j]\n",
    "    y_pred_prob.append(y_pred/6)\n",
    "    confusion_matrices_ap.append(confusion_matrix(np.argmax(all_tests_true[i][0], axis=1)+1, np.argmax(y_pred_prob[i], axis=1)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b12477-bb1b-496a-b16f-a3e2736bf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)', 'class 3 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)', 'class 3 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659f9e1-6fcb-4fa8-8e1d-b2b29483a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = summation.values.sum()\n",
    "correct_predictions = summation.values.trace()\n",
    "overall_accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = summation.values.diagonal() / summation.sum(axis=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Accuracy for Class {i + 1}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098dbcb-6f3d-424f-a64e-bcb8de189e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    "\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7df6f-7e9d-47d8-b08d-2790c224d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summation / (13 * 40) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa6dc-4794-4e57-b493-80ce26effec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([1, 1, 2, 2, 3, 3, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba87097-1690-404c-b051-55f9c13c3473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test for the effect of calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab11fff1-54d3-4dcc-8ac1-bb29e3b1e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "Calibrated_model = []\n",
    "for file in os.listdir(\"/home/bijan/py3x\"):\n",
    "    if file.endswith(\".h5\") and file.startswith(\"Calibrated\"):\n",
    "        Calibrated_model.append(file)\n",
    "    elif file.endswith(\".h5\") and file.startswith(\"Model\"):\n",
    "        models.append(file)\n",
    "        \n",
    "Calibrated_model = sorted(Calibrated_model)\n",
    "models = sorted(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6d2b9-976c-48c7-8f69-ca5033ad00dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50466690-38ae-4f90-9012-1457989185c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "Calibrated_models = {}\n",
    "for i in range(14):\n",
    "    if i == 8:\n",
    "        continue\n",
    "        \n",
    "    for j in range(6):\n",
    "        #print(\"Model{}{}.h5\".format(i+1, j+1))\n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb10d86e-1611-4280-8da5-a61bcf95bb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0203'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:02}{:02}\".format(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa5a0ea-0c50-4ec8-873a-327b68baee79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b34579d-f2e3-4917-9757-ef6058078bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_251 (Dense)           (None, 36)                20772     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 148       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,930\n",
      "Trainable params: 20,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Calibrated_models[\"1406\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33991647-0cda-498a-9e52-6950779cc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n",
      "      Cross-validation index:                            [0, 9, 12]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [5, 8]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 1 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1537, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (220, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13]\n",
      "      Cross-validation index:                            [7, 10]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1537, 576)\n",
      "Cross-validation features shape:  (220, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee414b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 1 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [3, 6]\n",
      "      Test index:                                        [11]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ab2ee415fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Outer Loop 2 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1338, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 5, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1338, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1479, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1479, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [5, 13]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 5: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13]\n",
      "      Cross-validation index:                            [8, 11]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 2 and Inner Loop 6: \n",
      "\n",
      "      Train epochs' shape:                                (1539, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (219, 64, 1123)\n",
      "      Test epochs' shape:                                 (139, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [3, 7]\n",
      "      Test index:                                        [4]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1539, 576)\n",
      "Cross-validation features shape:  (219, 576)\n",
      "Test features shape:              (139, 576)\n",
      "Outer Loop 3 and Inner Loop 1: \n",
      "\n",
      "      Train epochs' shape:                                (1337, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (420, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [1, 2, 3, 4, 6, 7, 8, 9, 11, 13]\n",
      "      Cross-validation index:                            [0, 10, 12]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1337, 576)\n",
      "Cross-validation features shape:  (420, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 2: \n",
      "\n",
      "      Train epochs' shape:                                (1477, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (280, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [6, 9]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1477, 576)\n",
      "Cross-validation features shape:  (280, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 3: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "      Cross-validation index:                            [1, 2]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n",
      "Train features shape:             (1478, 576)\n",
      "Cross-validation features shape:  (279, 576)\n",
      "Test features shape:              (140, 576)\n",
      "Outer Loop 3 and Inner Loop 4: \n",
      "\n",
      "      Train epochs' shape:                                (1478, 64, 1123)\n",
      "      Cross-validation epochs' shape:                     (279, 64, 1123)\n",
      "      Test epochs' shape:                                 (140, 64, 1123)\n",
      "      Train index:                                       [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12]\n",
      "      Cross-validation index:                            [4, 13]\n",
      "      Test index:                                        [5]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_subjects = len(EEG_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "models = {}\n",
    "Calibrated_models = {}\n",
    "\n",
    "kf_outer1 = KFold(n_splits=6, shuffle=True, random_state=42)              # Split the data into Train and Cross-Validation sets\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "for i, (train_crossval_index, test_index) in enumerate(kf_outer2.split(EEG_epochs)):\n",
    "    \n",
    "    if test_index == 7:\n",
    "        continue\n",
    "    \n",
    "    train_crossval = [EEG_epochs[i] for i in train_crossval_index]\n",
    "    test_epochs = np.concatenate([EEG_epochs[i] for i in test_index])\n",
    "    train_crossval_labels = [encoded[i] for i in train_crossval_index]\n",
    "    test_labels = np.concatenate([encoded[i] for i in test_index])\n",
    "    no_encoded_train_crossval = [no_encode[i] for i in train_crossval_index]\n",
    "    no_encoded_test = np.concatenate([no_encode[i] for i in test_index])\n",
    "\n",
    "    temp_pred = []\n",
    "    temp_true = []\n",
    "\n",
    "    for j, (train_index, val_index) in enumerate(kf_outer1.split(train_crossval)):\n",
    "        \n",
    "        \n",
    "        train_epochs = np.concatenate([train_crossval[i] for i in train_index])\n",
    "        crossval_epochs = np.concatenate([train_crossval[i] for i in val_index])\n",
    "        train_labels = np.concatenate([train_crossval_labels[i] for i in train_index])\n",
    "        crossval_labels = np.concatenate([train_crossval_labels[i] for i in val_index])\n",
    "        no_encoded_train = np.concatenate([no_encoded_train_crossval[i] for i in train_index])\n",
    "        no_encoded_crossval = np.concatenate([no_encoded_train_crossval[i] for i in val_index])\n",
    "        train_ids_for_save = [train_crossval_index[i] for i in train_index]\n",
    "        cross_val_ids_for_save = [train_crossval_index[i] for i in val_index]\n",
    "        \n",
    "        \n",
    "        print(\"Outer Loop {} and Inner Loop {}:\".format(i+1, j+1), \"\\n\")\n",
    "        print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "        #print(\"     Train labels' shape:                               \", train_labels.shape)\n",
    "        print(\"      Cross-validation epochs' shape:                    \", crossval_epochs.shape)\n",
    "        #print(\"     Cross-validation labels' shape:                    \", crossval_labels.shape)\n",
    "        print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "        #print(\"     Test labels' shape:                                \", test_labels.shape)\n",
    "        #print(\"     Train labels' shape (without encoding):            \", no_encoded_train.shape)\n",
    "        #print(\"     Cross-validation labels' shape (without encoding): \", no_encoded_crossval.shape)\n",
    "        #print(\"     Test labels' shape (without encoding):             \", no_encoded_test.shape)\n",
    "        print(\"      Train index:                                      \", train_ids_for_save)\n",
    "        print(\"      Cross-validation index:                           \", cross_val_ids_for_save)\n",
    "        print(\"      Test index:                                       \", test_index)\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = open('temp_stdout{}.txt'.format(i), 'w')  # Redirect output to a temporary file\n",
    "        train_features, CrossVal_features, test_features = feature_extraction_cv(train_epochs, no_encoded_train, crossval_epochs, test_epochs, number_of_bands=9, sampling_freq=250, low_cutoff=0, number_of_components=64)\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout\n",
    "    \n",
    "        print(\"Train features shape:            \", train_features.shape)\n",
    "        print(\"Cross-validation features shape: \", CrossVal_features.shape)\n",
    "        print(\"Test features shape:             \", test_features.shape)\n",
    "    \n",
    "        model_name = \"Model{}{}.h5\".format(i+1, j+1)\n",
    "        Calibrated_model_name = \"Calibrated_Model{}{}.h5\".format(i+1, j+1)\n",
    "        models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(model_name)\n",
    "        Calibrated_models[\"{:02}{:02}\".format(i+1, j+1)] = load_model(Calibrated_model_name)\n",
    "        \n",
    "        temp_pred.append(models[\"{:02}{:02}\".format(i+1, j+1)].predict(test_features[60:]))\n",
    "        temp_true.append(test_labels[60:])\n",
    "        \n",
    "    all_tests_pred.append(temp_pred)\n",
    "    all_tests_true.append(temp_true)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003b1db8-fd82-4248-af7d-378f87f1f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"all_tests_pred_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_pred, fp)\n",
    "\n",
    "with open(\"all_tests_true_without_calibration\", \"wb\") as fp:\n",
    "    pickle.dump(all_tests_true, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d30ebb-08d2-48c0-8cfd-dc3915c5da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices_ap = []\n",
    "for i in range(len(all_tests_pred)):\n",
    "    for j in range(len(all_tests_pred[1])):\n",
    "        y_true = 2 - np.argmax(all_tests_true[i][j], axis=1)\n",
    "        y_pred = 2 - np.argmax(all_tests_pred[i][j], axis=1)\n",
    "    confusion_matrices_ap.append(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66dd2c7b-5dbb-4b67-b72a-15e759258c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>358</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)             358             162\n",
       "class 2 (True)             202             315"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation = pd.DataFrame(sum(confusion_matrices_ap), index=['class 1 (True)', 'class 2 (True)'], columns=['class 1 (Pred)', 'class 2 (Pred)'])\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792408a4-5e58-4ca5-a1c5-6e73b9dcd381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 1 (Pred)</th>\n",
       "      <th>class 2 (Pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class 1 (True)</th>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.311538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class 2 (True)</th>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.605769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class 1 (Pred)  class 2 (Pred)\n",
       "class 1 (True)        0.688462        0.311538\n",
       "class 2 (True)        0.388462        0.605769"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation / 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69570fb4-4782-4b2d-a397-a3f1ebac8bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for binary classification (Left vs Right hand):\n",
      "\n",
      "\n",
      "       Accuracy:                  0.65\n",
      "\n",
      "       Precision:                 0.66\n",
      "\n",
      "       Recall (Sensitivity):      0.61     \n",
      "\n",
      "       F1 Score:                  0.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_confusion_matrix = sum(confusion_matrices_ap) / len(confusion_matrices_ap)\n",
    "\n",
    "true_positive = mean_confusion_matrix[1, 1]\n",
    "true_negative = mean_confusion_matrix[0, 0]\n",
    "false_positive = mean_confusion_matrix[0, 1]\n",
    "false_negative = mean_confusion_matrix[1, 0]\n",
    " \n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "sensitivity = recall  # Same as recall\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Average metrics for binary classification (Left vs Right hand):\\n\\n\")\n",
    "print(f\"       Accuracy:                  {accuracy:.2f}\\n\")\n",
    "print(f\"       Precision:                 {precision:.2f}\\n\")\n",
    "print(f\"       Recall (Sensitivity):      {recall:.2f}     \\n\")\n",
    "print(f\"       F1 Score:                  {f1:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79248da6-dded-44ba-987d-1dc4eb71db65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
