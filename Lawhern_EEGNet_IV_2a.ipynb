{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6ea4e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "# from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "# while the default tensorflow ordering is 'channels_last' we set it here\n",
    "# to be explicit in case if the user has changed the default ordering\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "18bd3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEGNet(nb_classes, Chans = 64, Samples = 128, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \"\"\" Keras Implementation of EEGNet\n",
    "    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n",
    "\n",
    "    Note that this implements the newest version of EEGNet and NOT the earlier\n",
    "    version (version v1 and v2 on arxiv). We strongly recommend using this\n",
    "    architecture as it performs much better and has nicer properties than\n",
    "    our earlier version. For example:\n",
    "        \n",
    "        1. Depthwise Convolutions to learn spatial filters within a \n",
    "        temporal convolution. The use of the depth_multiplier option maps \n",
    "        exactly to the number of spatial filters learned within a temporal\n",
    "        filter. This matches the setup of algorithms like FBCSP which learn \n",
    "        spatial filters within each filter in a filter-bank. This also limits \n",
    "        the number of free parameters to fit when compared to a fully-connected\n",
    "        convolution. \n",
    "        \n",
    "        2. Separable Convolutions to learn how to optimally combine spatial\n",
    "        filters across temporal bands. Separable Convolutions are Depthwise\n",
    "        Convolutions followed by (1x1) Pointwise Convolutions. \n",
    "        \n",
    "    \n",
    "    While the original paper used Dropout, we found that SpatialDropout2D \n",
    "    sometimes produced slightly better results for classification of ERP \n",
    "    signals. However, SpatialDropout2D significantly reduced performance \n",
    "    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n",
    "    the default Dropout in most cases.\n",
    "        \n",
    "    Assumes the input signal is sampled at 128Hz. If you want to use this model\n",
    "    for any other sampling rate you will need to modify the lengths of temporal\n",
    "    kernels and average pooling size in blocks 1 and 2 as needed (double the \n",
    "    kernel lengths for double the sampling rate, etc). Note that we haven't \n",
    "    tested the model performance with this rule so this may not work well. \n",
    "    \n",
    "    The model with default parameters gives the EEGNet-8,2 model as discussed\n",
    "    in the paper. This model should do pretty well in general, although it is\n",
    "\tadvised to do some model searching to get optimal performance on your\n",
    "\tparticular dataset.\n",
    "\n",
    "    We set F2 = F1 * D (number of input filters = number of output filters) for\n",
    "    the SeparableConv2D layer. We haven't extensively tested other values of this\n",
    "    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n",
    "    overcomplete). We believe the main parameters to focus on are F1 and D. \n",
    "\n",
    "    Inputs:\n",
    "        \n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.     \n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense', \n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0b5f17c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 22, 176, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 22, 176, 8)        176       \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 22, 176, 8)        32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_9 (Depthw  (None, 1, 176, 16)        352       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 1, 176, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1, 176, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_18 (Aver  (None, 1, 44, 16)         0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 44, 16)         0         \n",
      "                                                                 \n",
      " separable_conv2d_9 (Separa  (None, 1, 44, 16)         512       \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 1, 44, 16)         64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 1, 44, 16)         0         \n",
      "                                                                 \n",
      " average_pooling2d_19 (Aver  (None, 1, 5, 16)          0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 1, 5, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 80)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 324       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1524 (5.95 KB)\n",
      "Trainable params: 1444 (5.64 KB)\n",
      "Non-trainable params: 80 (320.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create the EEGNet model\n",
    "model = EEGNet(nb_classes=4, Chans=22, Samples=176, dropoutRate=0.5, kernLength=22, F1=8, D=2, F2=16, norm_rate=0.25, dropoutType='Dropout')\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)  # You can adjust the learning rate\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cd5b5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5e18a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>January 17, 2005  12:00:00 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>22 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>100.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>A01T.gdf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:44:51 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawGDF | A01T.gdf, 22 x 672528 (2690.1 s), ~26 kB, data not loaded>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw=mne.io.read_raw_gdf(\"D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01T.gdf\", eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "\n",
    "raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9deedfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6b081824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local ...\n",
      "Please make sure to change the data path!\n",
      "\n",
      "\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "7 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A03E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648774  =      0.000 ...  2595.096 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "6 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 600914  =      0.000 ...  2403.656 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A04E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660046  =      0.000 ...  2640.184 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 144 events and 176 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_5280\\2369254686.py:39: RuntimeWarning: No matching events found for 9 (event id 9)\n",
      "  train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn')\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_5280\\2369254686.py:39: RuntimeWarning: No matching events found for 10 (event id 10)\n",
      "  train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn')\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_5280\\2369254686.py:40: RuntimeWarning: No matching events found for 9 (event id 9)\n",
      "  test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn')\n",
      "C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_5280\\2369254686.py:40: RuntimeWarning: No matching events found for 10 (event id 10)\n",
      "  test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 144 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A05E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 679862  =      0.000 ...  2719.448 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "3 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A06E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 666372  =      0.000 ...  2665.488 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "6 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A07E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673134  =      0.000 ...  2692.536 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "4 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A08E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 687791  =      0.000 ...  2751.164 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Research Dr. Power\\BCI_IV_2a\\BCICIV_2a_gdf\\A09E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675097  =      0.000 ...  2700.388 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\contextlib.py:126: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 288 events and 176 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "if device == 'cuda':\n",
    "    print(\"Running on cloud ...\")\n",
    "    print(\"Please make sure to modify how you read the data according to your need!\\n\\n\")\n",
    "    raw_data_path = \"/home/bijan/projects/def-b09sdp/bijan/Phase2/\"\n",
    "    data_epochs = []\n",
    "    data_labels = []\n",
    "\n",
    "    for participant_id in range(1, 10):\n",
    "        participant = f\"P{participant_id}\"\n",
    "        file_path = f\"{raw_data_path}/{participant}.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(file_path)\n",
    "        data_epochs.append(epochs.get_data())\n",
    "        data_labels.append(epochs.events[:, -1])\n",
    "\n",
    "elif device == 'cpu':\n",
    "    print(\"Running local ...\")\n",
    "    print(\"Please make sure to change the data path!\\n\\n\")\n",
    "    raw_data_path = \"D:/Research Dr. Power/BCI_IV_2a/BCICIV_2a_gdf\"\n",
    "    train_data_epochs = []\n",
    "    train_data_labels = []\n",
    "    test_data_epochs = []\n",
    "    test_data_labels = []\n",
    "    for participant_id in range(1, 10):\n",
    "        participant_E = f\"A0{participant_id}E\"\n",
    "        participant_T = f\"A0{participant_id}T\"\n",
    "        \n",
    "        file_path_E = f\"{raw_data_path}/{participant_E}.gdf\"\n",
    "        file_path_T = f\"{raw_data_path}/{participant_T}.gdf\"\n",
    "        \n",
    "        raw_train = mne.io.read_raw_gdf(file_path_T, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        raw_test = mne.io.read_raw_gdf(file_path_E, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True).drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        \n",
    "        raw_train.set_eeg_reference()\n",
    "        raw_test.set_eeg_reference()\n",
    "        \n",
    "        train_events = mne.events_from_annotations(raw_train)\n",
    "        test_events = mne.events_from_annotations(raw_test)\n",
    "        \n",
    "        train_epochs = mne.Epochs(raw_train, train_events[0], event_id=[7,8,9,10], on_missing ='warn')\n",
    "        test_epochs = mne.Epochs(raw_test, train_events[0], event_id=[7,8,9,10], on_missing ='warn')\n",
    "        \n",
    "        train_data_epochs.append(train_epochs.get_data())\n",
    "        test_data_epochs.append(test_epochs.get_data())\n",
    "        \n",
    "        train_data_labels.append(train_epochs.events[:, -1])\n",
    "        test_data_labels.append(test_epochs.events[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cc355ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      5],\n",
       "       [     0,      0,      3],\n",
       "       [ 30878,      0,      5],\n",
       "       ...,\n",
       "       [669791,      0,      8],\n",
       "       [671350,      0,      6],\n",
       "       [671850,      0,      9]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bf3452cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1023': 1,\n",
       " '1072': 2,\n",
       " '276': 3,\n",
       " '277': 4,\n",
       " '32766': 5,\n",
       " '768': 6,\n",
       " '769': 7,\n",
       " '770': 8,\n",
       " '771': 9,\n",
       " '772': 10}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7febeb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673328,), (1, 673328))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0][1].shape, raw_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6349169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    \n",
    "    train_data_epochs[i] = train_data_epochs[i][:, :, :, np.newaxis]\n",
    "    test_data_epochs[i] = test_data_epochs[i][:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5b2fa2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 train epochs:     (288, 22, 176, 1)     Subject 1 train labels:     (288,)\n",
      "Subject 1 test epochs:      (288, 22, 176, 1)     Subject 1 test labels:      (288,)\n",
      "Subject 2 train epochs:     (288, 22, 176, 1)     Subject 2 train labels:     (288,)\n",
      "Subject 2 test epochs:      (281, 22, 176, 1)     Subject 2 test labels:      (281,)\n",
      "Subject 3 train epochs:     (288, 22, 176, 1)     Subject 3 train labels:     (288,)\n",
      "Subject 3 test epochs:      (282, 22, 176, 1)     Subject 3 test labels:      (282,)\n",
      "Subject 4 train epochs:     (144, 22, 176, 1)     Subject 4 train labels:     (144,)\n",
      "Subject 4 test epochs:      (144, 22, 176, 1)     Subject 4 test labels:      (144,)\n",
      "Subject 5 train epochs:     (288, 22, 176, 1)     Subject 5 train labels:     (288,)\n",
      "Subject 5 test epochs:      (285, 22, 176, 1)     Subject 5 test labels:      (285,)\n",
      "Subject 6 train epochs:     (288, 22, 176, 1)     Subject 6 train labels:     (288,)\n",
      "Subject 6 test epochs:      (282, 22, 176, 1)     Subject 6 test labels:      (282,)\n",
      "Subject 7 train epochs:     (288, 22, 176, 1)     Subject 7 train labels:     (288,)\n",
      "Subject 7 test epochs:      (284, 22, 176, 1)     Subject 7 test labels:      (284,)\n",
      "Subject 8 train epochs:     (288, 22, 176, 1)     Subject 8 train labels:     (288,)\n",
      "Subject 8 test epochs:      (288, 22, 176, 1)     Subject 8 test labels:      (288,)\n",
      "Subject 9 train epochs:     (288, 22, 176, 1)     Subject 9 train labels:     (288,)\n",
      "Subject 9 test epochs:      (288, 22, 176, 1)     Subject 9 test labels:      (288,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(\"Subject {} train epochs:    \".format(i+1), train_data_epochs[i].shape, \"    Subject {} train labels:    \".format(i+1), train_data_labels[i].shape)\n",
    "    print(\"Subject {} test epochs:     \".format(i+1), test_data_epochs[i].shape, \"    Subject {} test labels:     \".format(i+1), test_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2ab5ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_epochs = np.zeros(len(train_data_epochs)).tolist()\n",
    "all_data_labels = np.zeros(len(train_data_epochs)).tolist()\n",
    "\n",
    "for i in range(len(train_data_epochs)):\n",
    "    all_data_epochs[i] = np.concatenate((train_data_epochs[i], test_data_epochs[i]), axis=0)\n",
    "    all_data_labels[i] = np.concatenate((train_data_labels[i], test_data_labels[i]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24fedeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific element in train and test sets:       [1.83144636e-06] [4.31228067e-06]\n",
      "The same element in all data set combined:     [1.83144636e-06] [4.31228067e-06]\n",
      "\n",
      "\n",
      "\n",
      "Checking the labels in train and test:         7 8\n",
      "The same element in all data set combined:     7 8\n"
     ]
    }
   ],
   "source": [
    "# Checking if the concatenation does not have a problem!\n",
    "\n",
    "print(\"Specific element in train and test sets:      \", train_data_epochs[i][10, 10, 10], test_data_epochs[i][100, 13, 14])\n",
    "print(\"The same element in all data set combined:    \", all_data_epochs[i][10, 10, 10], all_data_epochs[i][388, 13, 14])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Checking the labels in train and test:        \", train_data_labels[i][10], test_data_labels[i][100])\n",
    "print(\"The same element in all data set combined:    \", all_data_labels[i][10], all_data_labels[i][388])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9b791055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data epoch shape (sub 0):     (576, 22, 176, 1)     All label shape (sub 0):      (576,)\n",
      "All data epoch shape (sub 1):     (569, 22, 176, 1)     All label shape (sub 1):      (569,)\n",
      "All data epoch shape (sub 2):     (570, 22, 176, 1)     All label shape (sub 2):      (570,)\n",
      "All data epoch shape (sub 3):     (288, 22, 176, 1)     All label shape (sub 3):      (288,)\n",
      "All data epoch shape (sub 4):     (573, 22, 176, 1)     All label shape (sub 4):      (573,)\n",
      "All data epoch shape (sub 5):     (570, 22, 176, 1)     All label shape (sub 5):      (570,)\n",
      "All data epoch shape (sub 6):     (572, 22, 176, 1)     All label shape (sub 6):      (572,)\n",
      "All data epoch shape (sub 7):     (576, 22, 176, 1)     All label shape (sub 7):      (576,)\n",
      "All data epoch shape (sub 8):     (576, 22, 176, 1)     All label shape (sub 8):      (576,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data_epochs)):\n",
    "    print(\"All data epoch shape (sub {}):    \".format(i), all_data_epochs[i].shape, \"    All label shape (sub {}):     \".format(i), all_data_labels[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3bfdc26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 22, 176, 1)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_epochs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a1acf2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(y_data, method=OneHotEncoder):\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(y_data[0].reshape(-1, 1))\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        \n",
    "        a = encoder.transform(y_data[i].reshape(-1, 1))\n",
    "        y_data[i] = a.toarray()\n",
    "\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "068ca1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_encode = copy.deepcopy(all_data_labels)\n",
    "encoded = encoder(all_data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "da5a03f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Length: 9\n",
      "labels Length: 9\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - Epochs[0] shape: (576,)\n",
      "Participant 16 - labels[0] shape: (576, 4)\n",
      "\n",
      "\n",
      "\n",
      "Participant 16 - labels[0]:\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Epochs Length:\", len(all_data_labels))\n",
    "print(\"labels Length:\", len(encoded))\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - Epochs[0] shape:\", no_encode[0].shape)\n",
    "print(\"Participant 16 - labels[0] shape:\", encoded[0].shape)\n",
    "print('\\n\\n')\n",
    "print(\"Participant 16 - labels[0]:\")\n",
    "print(all_data_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b6831fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = [7, 8, 0.9899, 97, 34]\n",
    "\n",
    "a.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4cf90c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 0.9899, 97, 34]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990dc6d9",
   "metadata": {},
   "source": [
    "# Cross-subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "55b80571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Loop 1 \n",
      "\n",
      "      Train epochs' shape:                                (4297, 22, 176, 1)\n",
      "      Test epochs' shape:                                 (573, 22, 176, 1)\n",
      "      Test labels' shape:                                 (573, 4)\n",
      "      Train labels' shape (without encoding):             (4297,)\n",
      "      Test labels' shape (without encoding):              (573,)\n",
      "      Train index:                                        [1, 2, 3, 4, 6, 7, 8, 9]\n",
      "      Test index:                                         [5]\n",
      "\n",
      "\n",
      "\n",
      "(1, 1, 176, 1)\n",
      "(1, 1, 176, 1)\n",
      "Epoch 1/500\n",
      "135/135 [==============================] - 6s 35ms/step - loss: 1.3864 - accuracy: 0.2760 - val_loss: 1.3836 - val_accuracy: 0.2862\n",
      "Epoch 2/500\n",
      "135/135 [==============================] - 5s 34ms/step - loss: 1.3742 - accuracy: 0.2918 - val_loss: 1.3786 - val_accuracy: 0.2792\n",
      "Epoch 3/500\n",
      "135/135 [==============================] - 4s 33ms/step - loss: 1.3654 - accuracy: 0.3128 - val_loss: 1.3712 - val_accuracy: 0.2932\n",
      "Epoch 4/500\n",
      "135/135 [==============================] - 5s 36ms/step - loss: 1.3565 - accuracy: 0.3188 - val_loss: 1.3641 - val_accuracy: 0.3037\n",
      "Epoch 5/500\n",
      "135/135 [==============================] - 5s 39ms/step - loss: 1.3476 - accuracy: 0.3360 - val_loss: 1.3558 - val_accuracy: 0.3229\n",
      "Epoch 6/500\n",
      "135/135 [==============================] - 5s 36ms/step - loss: 1.3461 - accuracy: 0.3442 - val_loss: 1.3533 - val_accuracy: 0.3455\n",
      "Epoch 7/500\n",
      "135/135 [==============================] - 5s 38ms/step - loss: 1.3406 - accuracy: 0.3519 - val_loss: 1.3514 - val_accuracy: 0.3386\n",
      "Epoch 8/500\n",
      "135/135 [==============================] - 6s 42ms/step - loss: 1.3366 - accuracy: 0.3565 - val_loss: 1.3524 - val_accuracy: 0.3298\n",
      "Epoch 9/500\n",
      "135/135 [==============================] - 5s 41ms/step - loss: 1.3348 - accuracy: 0.3523 - val_loss: 1.3441 - val_accuracy: 0.3525\n",
      "Epoch 10/500\n",
      "135/135 [==============================] - 6s 41ms/step - loss: 1.3337 - accuracy: 0.3542 - val_loss: 1.3479 - val_accuracy: 0.3211\n",
      "Epoch 11/500\n",
      "135/135 [==============================] - 6s 43ms/step - loss: 1.3306 - accuracy: 0.3635 - val_loss: 1.3430 - val_accuracy: 0.3246\n",
      "Epoch 12/500\n",
      "135/135 [==============================] - 5s 40ms/step - loss: 1.3286 - accuracy: 0.3647 - val_loss: 1.3419 - val_accuracy: 0.3525\n",
      "Epoch 13/500\n",
      "135/135 [==============================] - 5s 39ms/step - loss: 1.3295 - accuracy: 0.3635 - val_loss: 1.3433 - val_accuracy: 0.3490\n",
      "Epoch 14/500\n",
      "135/135 [==============================] - 5s 38ms/step - loss: 1.3241 - accuracy: 0.3749 - val_loss: 1.3408 - val_accuracy: 0.3578\n",
      "Epoch 15/500\n",
      "135/135 [==============================] - 5s 35ms/step - loss: 1.3225 - accuracy: 0.3768 - val_loss: 1.3453 - val_accuracy: 0.3508\n",
      "Epoch 16/500\n",
      "135/135 [==============================] - 5s 34ms/step - loss: 1.3246 - accuracy: 0.3700 - val_loss: 1.3430 - val_accuracy: 0.3438\n",
      "Epoch 17/500\n",
      "135/135 [==============================] - 5s 36ms/step - loss: 1.3214 - accuracy: 0.3756 - val_loss: 1.3371 - val_accuracy: 0.3473\n",
      "Epoch 18/500\n",
      "135/135 [==============================] - 5s 36ms/step - loss: 1.3191 - accuracy: 0.3710 - val_loss: 1.3385 - val_accuracy: 0.3647\n",
      "Epoch 19/500\n",
      "135/135 [==============================] - 5s 36ms/step - loss: 1.3170 - accuracy: 0.3914 - val_loss: 1.3428 - val_accuracy: 0.3543\n",
      "Epoch 20/500\n",
      "135/135 [==============================] - 5s 39ms/step - loss: 1.3167 - accuracy: 0.3765 - val_loss: 1.3470 - val_accuracy: 0.3368\n",
      "Epoch 21/500\n",
      "135/135 [==============================] - 6s 41ms/step - loss: 1.3158 - accuracy: 0.3835 - val_loss: 1.3418 - val_accuracy: 0.3333\n",
      "Epoch 22/500\n",
      "135/135 [==============================] - 6s 41ms/step - loss: 1.3189 - accuracy: 0.3735 - val_loss: 1.3378 - val_accuracy: 0.3421\n",
      "Epoch 23/500\n",
      "135/135 [==============================] - 6s 41ms/step - loss: 1.3166 - accuracy: 0.3770 - val_loss: 1.3402 - val_accuracy: 0.3386\n",
      "Epoch 24/500\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 1.3168 - accuracy: 0.3735 - val_loss: 1.3387 - val_accuracy: 0.3438\n",
      "Epoch 25/500\n",
      "135/135 [==============================] - 5s 40ms/step - loss: 1.3105 - accuracy: 0.3938 - val_loss: 1.3384 - val_accuracy: 0.3438\n",
      "Epoch 26/500\n",
      "135/135 [==============================] - 6s 41ms/step - loss: 1.3078 - accuracy: 0.3819 - val_loss: 1.3424 - val_accuracy: 0.3473\n",
      "Epoch 27/500\n",
      "135/135 [==============================] - 5s 38ms/step - loss: 1.3155 - accuracy: 0.3821 - val_loss: 1.3451 - val_accuracy: 0.3403\n",
      "Epoch 28/500\n",
      "135/135 [==============================] - 5s 36ms/step - loss: 1.3148 - accuracy: 0.3777 - val_loss: 1.3425 - val_accuracy: 0.3473\n",
      "Epoch 29/500\n",
      "135/135 [==============================] - 5s 35ms/step - loss: 1.3066 - accuracy: 0.3784 - val_loss: 1.3357 - val_accuracy: 0.3438\n",
      "Epoch 30/500\n",
      "135/135 [==============================] - 5s 35ms/step - loss: 1.3089 - accuracy: 0.3907 - val_loss: 1.3370 - val_accuracy: 0.3438\n",
      "Epoch 31/500\n",
      "135/135 [==============================] - 5s 37ms/step - loss: 1.3096 - accuracy: 0.3838 - val_loss: 1.3381 - val_accuracy: 0.3455\n",
      "Epoch 32/500\n",
      "135/135 [==============================] - 5s 39ms/step - loss: 1.3067 - accuracy: 0.3861 - val_loss: 1.3316 - val_accuracy: 0.3595\n",
      "Epoch 33/500\n",
      "135/135 [==============================] - 5s 40ms/step - loss: 1.3085 - accuracy: 0.3845 - val_loss: 1.3275 - val_accuracy: 0.3630\n",
      "Epoch 34/500\n",
      "135/135 [==============================] - 5s 39ms/step - loss: 1.3058 - accuracy: 0.3872 - val_loss: 1.3305 - val_accuracy: 0.3630\n",
      "Epoch 35/500\n",
      "135/135 [==============================] - 5s 39ms/step - loss: 1.3063 - accuracy: 0.3821 - val_loss: 1.3325 - val_accuracy: 0.3595\n",
      "Epoch 36/500\n",
      "135/135 [==============================] - 8s 56ms/step - loss: 1.3052 - accuracy: 0.3898 - val_loss: 1.3264 - val_accuracy: 0.3735\n",
      "Epoch 37/500\n",
      "124/135 [==========================>...] - ETA: 0s - loss: 1.3021 - accuracy: 0.4002"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/model_71/separable_conv2d_72/separable_conv2d/Conv2DBackpropInput defined at (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_5280\\2350383845.py\", line 75, in <module>\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1130, in train_step\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 543, in minimize\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 276, in compute_gradients\n\nOOM when allocating tensor with shape[4727,44,16] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradient_tape/model_71/separable_conv2d_72/separable_conv2d/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1181578]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[297], line 75\u001b[0m\n\u001b[0;32m     69\u001b[0m norm_test_epochs \u001b[38;5;241m=\u001b[39m (test_epochs \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_train_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnorm_test_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust as needed\u001b[39;49;00m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Collect training metrics\u001b[39;00m\n\u001b[0;32m     84\u001b[0m train_loss_epochs\u001b[38;5;241m.\u001b[39mextend(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/model_71/separable_conv2d_72/separable_conv2d/Conv2DBackpropInput defined at (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"C:\\ProgramData\\Anaconda3\\envs\\BCI_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\bijan\\AppData\\Local\\Temp\\ipykernel_5280\\2350383845.py\", line 75, in <module>\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1130, in train_step\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 543, in minimize\n\n  File \"C:\\Users\\bijan\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 276, in compute_gradients\n\nOOM when allocating tensor with shape[4727,44,16] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradient_tape/model_71/separable_conv2d_72/separable_conv2d/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1181578]"
     ]
    }
   ],
   "source": [
    "participants = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "class_numbers=4\n",
    "num_subjects = len(all_data_epochs)\n",
    "all_tests_true = []\n",
    "all_tests_pred = []\n",
    "max_epochs = 500\n",
    "learning_rate=0.0003\n",
    "\n",
    "\n",
    "\n",
    "kf_outer2 = KFold(n_splits=num_subjects, shuffle=True, random_state=2)    # Split the data into Train_CrossVal and test sets.\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf_outer2.split(all_data_epochs)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_epochs = np.concatenate([all_data_epochs[j] for j in train_index])\n",
    "    test_epochs = np.concatenate([all_data_epochs[k] for k in test_index])\n",
    "    train_labels = np.concatenate([encoded[l] for l in train_index])\n",
    "    test_labels = np.concatenate([encoded[m] for m in test_index])\n",
    "    no_encoded_train_labels = np.concatenate([no_encode[n] for n in train_index])\n",
    "    no_encoded_test_labels = np.concatenate([no_encode[o] for o in test_index])\n",
    "    train_ids_for_save = [participants[i] for i in train_index]\n",
    "    test_ids_for_save = [participants[i] for i in test_index]\n",
    "    \n",
    "    \n",
    "    print(\"Outer Loop {}\".format(i+1), \"\\n\")\n",
    "    print(\"      Train epochs' shape:                               \", train_epochs.shape)\n",
    "\n",
    "    print(\"      Test epochs' shape:                                \", test_epochs.shape)\n",
    "    print(\"      Test labels' shape:                                \", test_labels.shape)\n",
    "    print(\"      Train labels' shape (without encoding):            \", no_encoded_train_labels.shape)\n",
    "\n",
    "    print(\"      Test labels' shape (without encoding):             \", no_encoded_test_labels.shape)\n",
    "    print(\"      Train index:                                       \", train_ids_for_save)\n",
    "\n",
    "    print(\"      Test index:                                        \", test_ids_for_save)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Create the EEGNet model\n",
    "    model = EEGNet(nb_classes=4, Chans=22, Samples=176, dropoutRate=0.4, kernLength=22, F1=8, D=2, F2=16, norm_rate=0.25, dropoutType='Dropout')\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    patience = 60\n",
    "    train_loss_epochs = []\n",
    "    train_acc_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    test_acc_epochs = []\n",
    "    train_conf_mat = []\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    \n",
    "    # Normalizing the features\n",
    "    mean = train_epochs.mean(axis=(0, 1, 3), keepdims=True)\n",
    "    std = train_epochs.std(axis=(0, 1, 3), keepdims=True)\n",
    "    \n",
    "    print(mean.shape)\n",
    "    print(std.shape)\n",
    "    \n",
    "    norm_train_epochs = (train_epochs - mean) / std\n",
    "    norm_test_epochs = (test_epochs - mean) / std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        norm_train_epochs, train_labels,\n",
    "        validation_data=(norm_test_epochs, test_labels),\n",
    "        epochs=max_epochs,\n",
    "        batch_size=32,  # Adjust as needed\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # Collect training metrics\n",
    "    train_loss_epochs.extend(history.history['loss'])\n",
    "    train_acc_epochs.extend(history.history['accuracy'])\n",
    "\n",
    "    # Collect testing metrics\n",
    "    test_loss_epochs.extend(history.history['val_loss'])\n",
    "    test_acc_epochs.extend(history.history['val_accuracy'])\n",
    "    \n",
    "    epochs_range = np.arange(1, len(train_loss_epochs[:-1*patience])+1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(\"Participant {}\".format(participants[test_index[0]]))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(epochs_range, train_loss_epochs[:-1*patience])\n",
    "    plt.plot(epochs_range, test_loss_epochs[:-1*patience])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(epochs_range, train_acc_epochs[:-1*patience])\n",
    "    plt.plot(epochs_range, test_acc_epochs[:-1*patience])\n",
    "    plt.legend([\"Train\", \"Test\"])\n",
    "    plt.savefig(\"P{}.jpg\".format(participants[test_index[0]]))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b0c5ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 34, 5]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 34, 5, 6]\n",
    "print(a[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4800ac4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 4)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "07820674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 2)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "524919dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 8, 7, 7, 8, 7, 7, 8, 7, 8,\n",
       "       7, 8, 7, 8, 7, 8, 7, 8, 8, 7, 7, 8, 7, 8, 7, 8, 8, 8, 7, 7, 8, 7,\n",
       "       8, 8, 7, 7, 7, 8, 7, 8, 8, 8, 8, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 8,\n",
       "       7, 7, 8, 8, 8, 8, 8, 7, 7, 8, 7, 8, 7, 8, 8, 7, 8, 8, 8, 8, 7, 7,\n",
       "       7, 8, 7, 8, 7, 7, 8, 7, 8, 7, 7, 8, 7, 7, 7, 8, 8, 8, 7, 8, 8, 7,\n",
       "       7, 7, 7, 8, 8, 8, 8, 7, 7, 8, 8, 7, 7, 8, 7, 8, 8, 8, 7, 8, 8, 7,\n",
       "       8, 8, 7, 8, 8, 7, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7,\n",
       "       7, 7, 7, 8, 7, 7, 8, 7, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 7, 8, 8, 7,\n",
       "       7, 8, 7, 8, 7, 8, 8, 8, 7, 7, 8, 7, 8, 8, 7, 7, 7, 8, 7, 8, 8, 8,\n",
       "       8, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 8, 7, 7, 8, 8, 8, 8, 8, 7, 7, 8,\n",
       "       7, 8, 7, 8, 8, 7, 8, 8, 8, 8, 7, 7, 7, 8, 7, 8, 7, 7, 8, 7, 8, 7,\n",
       "       7, 8, 7, 7, 7, 8, 8, 8, 7, 8, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7, 8,\n",
       "       8, 7, 7, 8, 7, 8, 8, 8, 7, 8, 8, 7, 8, 8, 7, 8, 8, 7, 7, 8, 7, 7,\n",
       "       7, 7])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_encode[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715d055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
